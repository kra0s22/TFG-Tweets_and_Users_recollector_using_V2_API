{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Versión para tweepy V2\n",
    "from datetime import date\n",
    "import datetime\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "import math\n",
    "import pymongo\n",
    "from bson import ObjectId\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constant and Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "PETITIONS_PER_TIME_LAPSE = 300\n",
    "TIME_LAPSE = 20*60\n",
    "# Tiempo de espera necesario entre peticiones\n",
    "TIMER = TIME_LAPSE/PETITIONS_PER_TIME_LAPSE\n",
    "# Log cada 5 minutos\n",
    "TIMER_LOG = 5*60\n",
    "#porcentaje de tweets que nos quedamos para cada dia\n",
    "PERCENT = 0.15\n",
    "# máximo de tweets por cada petición\n",
    "PETITIONS_LIMIT = 500\n",
    "\n",
    "#VARIABLES\n",
    "iniTimerLog = 0\n",
    "finTimerLog = 0\n",
    "tiempo = TIMER_LOG\n",
    "hashtagsList = []\n",
    "hashtags = []\n",
    "entrada = \"\"\n",
    "next_token = None\n",
    "entradaizq = '' \n",
    "entradader = ''\n",
    "total = 0\n",
    "startDate = ''\n",
    "endDate = ''\n",
    "inicio = 0\n",
    "fin = 0\n",
    "hashtag_ini_log = ''\n",
    "start_log_timer = ''\n",
    "hashtag_last_log = ''\n",
    "tweet_count = 0\n",
    "url = 'https://api.twitter.com/2/tweets/search/all?'\n",
    "today = datetime.date.today()\n",
    "d1 = today.strftime(\"%d-%m-%Y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_dictionary = {\n",
    "    \"_id\"               : None,\n",
    "    \"description\"       : '',\n",
    "    \"created_at\"        : '',\n",
    "    \"verified\"          : '',\n",
    "    \"followers_count\"   : 0,\n",
    "    \"following_count\"   : 0\n",
    "}\n",
    "\n",
    "\n",
    "tweet_dictionary = {\n",
    "    \"_id\"               : None,\n",
    "    \"author_id\"         : '',\n",
    "    \"created_at\"        : '',\n",
    "    \"text\"              : '',\n",
    "    \"hashtag\"           : [],\n",
    "    \"referenced_tweets\" : [],\n",
    "    \"retweet_count\"     : 0,\n",
    "    \"reply_count\"       : 0,\n",
    "    \"reply_count\"       : 0,\n",
    "    \"like_count\"        : 0\n",
    "}\n",
    "\n",
    "\n",
    "node = {\n",
    "    \"hashtag\"           : '',\n",
    "    \"current_date\"        : '',\n",
    "    \"next_date\"        : '',\n",
    "    \"next_token\"        : '-1'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def DayMonthYearToPetition(date):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    splited = ''\n",
    "    if ('/' in date):\n",
    "        splited = date.split('/')\n",
    "    elif ('-' in date):\n",
    "        splited = date.split('-')\n",
    "        \n",
    "    return (splited[2] + '-' + splited[1] + '-' + splited[0])\n",
    "\n",
    "def DayMonthYearToPetition(date):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    splited = ''\n",
    "    if ('/' in date):\n",
    "        splited = date.split('/')\n",
    "    elif ('-' in date):\n",
    "        splited = date.split('-')\n",
    "\n",
    "    return (splited[2] + '-' + splited[1] + '-' + splited[0])\n",
    "\n",
    "def PetitionToDayMonthYear(petition):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    splited = ''\n",
    "    time = ''\n",
    "    splited = petition.split('T')\n",
    "    time = splited[1]\n",
    "    splited = splited[0].split('-')\n",
    "    return (splited[2] + '-' + splited[1] + '-' + splited[0] + 'T' + time)\n",
    "\n",
    "def make_objid(text):\n",
    "    \"\"\"Makes an ObjectId of 4 bytes\n",
    "    \n",
    "    Keyword arguments:\n",
    "    text -- string to be converted into Object ID\n",
    "    \"\"\"\n",
    "    text = str(text)\n",
    "    if not text.strip():\n",
    "        return None\n",
    "    try:\n",
    "        return ObjectId(text.rjust(24,\"0\"))\n",
    "    except Exception as ex:\n",
    "        print(text, ex)\n",
    "        return None\n",
    "\n",
    "def create_headers(bearer_token):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)}\n",
    "    return headers\n",
    "\n",
    "def connect_to_endpoint(headers, params):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    global d1\n",
    "    response = requests.request(\"GET\", \"https://api.twitter.com/2/tweets/search/all?\", headers=headers, params=params, timeout=2)\n",
    "    # Manejo de errores\n",
    "    if response.status_code != 200:\n",
    "        # datetime object containing current date and time\n",
    "        now = datetime.datetime.now()\n",
    "        # dd/mm/YY H:M:S\n",
    "        dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "        errorlog = open(\"./errorlog\" + d1 + \".txt\", \"a\")\n",
    "        errorlog.write(\"Error en respuesta: \" + str(response.status_code) + ', ' + str(response.text) + \" \" + dt_string + \"\\n\")\n",
    "        errorlog.close()\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "def TestInsertion(tweet_list, user_list):\n",
    "    global myclient\n",
    "    global myusers\n",
    "    global mytweets\n",
    "    global mydb\n",
    "    \n",
    "    aux = []\n",
    "    [aux.append(t[\"_id\"]) for t in tweet_list]\n",
    "    if len(list(mytweets.find( { \"_id\" : {\"$in\" : aux } }))) == 0:\n",
    "        print('Not working propperly')\n",
    "        sys.exit()\n",
    "    aux = []\n",
    "    [aux.append(u[\"_id\"]) for u in user_list]        \n",
    "    if len(list(myusers.find( { \"_id\" : {\"$in\" : aux } }))) == 0:\n",
    "        print('Not working propperly')\n",
    "        sys.exit()\n",
    "    \n",
    "    \n",
    "def MongoExecute(tweet_list, user_list):\n",
    "    \"\"\"\n",
    "        tweet_list: lista de tweets que se van a insertar en la base de datos\n",
    "        user_list: lista de usuarios que se van a insertar en la base de datos\n",
    "    \"\"\"\n",
    "    global myclient\n",
    "    global myusers\n",
    "    global mytweets\n",
    "    global mydb\n",
    "    \n",
    "    try:\n",
    "        print(str(mytweets.insert_many(tweet_list, ordered=False)))\n",
    "    except Exception as e:        \n",
    "        pass\n",
    "    try:\n",
    "        print(str(myusers.insert_many(user_list, ordered=False)))\n",
    "    except Exception as e:        \n",
    "        pass\n",
    "    \n",
    "    TestInsertion(tweet_list, user_list)\n",
    "\n",
    "def PrintTweetsUsers(tweets, users):\n",
    "    print(\"Tweet list\")\n",
    "    for tweet in tweets:\n",
    "        print(\" id: \" + str(tweet['_id']))\n",
    "        print(\" author_id: \" + tweet['author_id'])\n",
    "        print(\" created_at: \" + tweet['created_at'])\n",
    "        print(\" referenced_tweets: \" + str(tweet['referenced_tweets']) + '\\n')\n",
    "\n",
    "    print(\"User list\")\n",
    "    for user in users:\n",
    "        print(\" user_id: \" + str(user['_id']))\n",
    "        print(\" description: \" + user['description'])\n",
    "        print(\" created_at: \" + user['created_at'])\n",
    "        print(\" verified: \" + str(user['verified']))\n",
    "        print(\" followers_count: \" + str(user['followers_count']))\n",
    "        print(\" following_count: \" + str(user['following_count']) + '\\n')\n",
    "\n",
    "        \n",
    "def Init_Tweet_Dictionary():\n",
    "    tweet_dictionary_new = tweet_dictionary.copy()\n",
    "    tweet_dictionary_new['hashtag'] = []\n",
    "    tweet_dictionary_new['referenced_tweets'] = []\n",
    "    return tweet_dictionary_new\n",
    "\n",
    "def Tweet_to_Dictionary(tweet):\n",
    "    tweet_dictionary_new = Init_Tweet_Dictionary()\n",
    "    tweet_dictionary_new['_id'] = make_objid(str(tweet['id']))\n",
    "    tweet_dictionary_new['author_id'] = make_objid(str(tweet['author_id']))\n",
    "    tweet_dictionary_new['text'] = tweet['text']\n",
    "    tweet_dictionary_new['created_at'] = tweet['created_at']\n",
    "    tweet_dictionary_new['retweet_count'] = tweet['public_metrics']['retweet_count']\n",
    "    tweet_dictionary_new['reply_count'] = tweet['public_metrics']['reply_count']\n",
    "    tweet_dictionary_new['like_count'] = tweet['public_metrics']['like_count']\n",
    "    tweet_dictionary_new['quote_count'] = tweet['public_metrics']['quote_count']\n",
    "\n",
    "    # Inserci'on de hashtags del tweet para los casos de tweets sin referencias, quotes o respuestas\n",
    "    if \"entities\" in tweet and \"hashtags\" in tweet[\"entities\"]:\n",
    "        [tweet_dictionary_new['hashtag'].append(h['tag'].upper()) for h in tweet[\"entities\"][\"hashtags\"]]\n",
    "    return tweet_dictionary_new\n",
    "        \n",
    "def User_to_Dictionary(user_id, user):\n",
    "    # Inicializar dictionary de usuarios                \n",
    "    user_dictionary_new = user_dictionary.copy()\n",
    "    user_dictionary_new['_id'] = user_id\n",
    "    if str(make_objid(user['id'])) == str(user_dictionary_new['_id']):\n",
    "        user_dictionary_new['description'] = user['description']\n",
    "        user_dictionary_new['created_at'] = user['created_at']\n",
    "        user_dictionary_new['verified'] = user['verified']\n",
    "        user_dictionary_new['followers_count'] = int(user['public_metrics']['followers_count'])\n",
    "        user_dictionary_new['following_count'] = int(user['public_metrics']['following_count'])\n",
    "    return user_dictionary_new\n",
    "\n",
    "def IsUnknown(user_id, user_list):\n",
    "    for user in user_list:\n",
    "        if (str(user['_id']) == str(user_id)):\n",
    "            return False\n",
    "    return True\n",
    "        \n",
    "def PetitionsLessEqualPETITIONS_LIMIT(hashtag, start, end, bearer, next_token):\n",
    "    '''\n",
    "        Hashtag: nombre del hashtag que se va a buscar\n",
    "        start: fecha de inicio\n",
    "        end: fecha de respuesta\n",
    "        number: n'umero de tweets que queremos obtener\n",
    "        bearer: bearer id\n",
    "        next_token: token de la page (inicialmente string vac'ia) que quieres buscar\n",
    "        return: tupla de n'umero de respuestas y next_token\n",
    "    '''\n",
    "    global headers\n",
    "    global PETITIONS_LIMIT\n",
    "    global hashtagsList\n",
    "    global hashtags\n",
    "    global d1\n",
    "\n",
    "    startDate = DayMonthYearToPetition(start)\n",
    "    endDate = DayMonthYearToPetition(end)\n",
    "    tweet_list = []\n",
    "    user_list = []\n",
    "    total = (0, '', [], [])\n",
    "    dt_string = ''\n",
    "    tweet_dictionary_new = {}\n",
    "    user_dictionary_new = {}\n",
    "    aux = ''\n",
    "    \n",
    "    \"\"\"\n",
    "     Insertados los siguientes campos:\n",
    "        -start_time: límite inferior en búsqueda de fechas\n",
    "        -end_time: límete superior en búsqueda de fechas\n",
    "        -tweet.fields=author_id: id del autor del tweet\n",
    "        -tweet.fields=referenced_tweets: puede ser quote, retweet o replied_to junto al id al que responde, agrega además los tweets relativos al tweet al que responde\n",
    "        -tweet.fields=created_at: cu'ando se cre'o el fichero\n",
    "        -tweet.fields=context_annotations:anotaciones de contexto (no salen muchas)\n",
    "        -tweet.fields=lang: Abreviatura del idioma en el que se escribe\n",
    "        -tweet.fields=entities: referencias, hashtags usados por el usuario\n",
    "        -tweet.fields=in_reply_to_user_id: \n",
    "        -tweet.fields=conversation_id: \n",
    "        -tweet.fields=public_metrics:\n",
    "        -tweet.fields=text:\n",
    "        -tweet.fields=entities:\n",
    "        -expansions=author_id\n",
    "        -expansions=referenced_tweets.id\n",
    "        -expansions=author_id,referenced_tweets.id\n",
    "        -user.fields=created_at\n",
    "        -user.fields=entities\n",
    "        -user.fields=description\n",
    "        -user.fields=verified\n",
    "        -user.fields=public_metrics\n",
    "    \"\"\"\n",
    "    params = \"query=%23\" + hashtag + \"&start_time=\" +  startDate + \"T00%3A00%3A00Z\" + \"&end_time=\" + endDate + 'T11%3A59%3A59Z&max_results=' + str(PETITIONS_LIMIT) + \"&expansions=author_id,referenced_tweets.id&tweet.fields=created_at,conversation_id,referenced_tweets,public_metrics,text,entities&user.fields=created_at,entities,description,verified,public_metrics\"\n",
    "\n",
    "    # caso en el que -1 (primera peticion de dia) o es el next_token\n",
    "    if (next_token != ''):\n",
    "        params = params + '&next_token=' + next_token\n",
    "        \n",
    "    json_obj = ''\n",
    "    try:\n",
    "        json_obj = connect_to_endpoint(headers=headers, params=params)\n",
    "    # Caso en el que falla el conect to endpoint\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return (0, next_token, [], [])\n",
    "    \n",
    "    # Comprobar que hay respuestas para dicho hashtag\n",
    "    if ('meta' in json_obj) and (int(json_obj['meta']['result_count']) > 0):\n",
    "        # Iteraci'on lista de objetos tweets\n",
    "        for tweet in json_obj['data']:\n",
    "            # Inicializar dictionary de tweet\n",
    "            tweet_dictionary_new = Tweet_to_Dictionary(tweet)\n",
    "            # Inserci'on de los tweets referidos en la lista de tweets referedios con sus object id\n",
    "            if ('referenced_tweets' in tweet):\n",
    "                tweet_dictionary_new['referenced_tweets'] = tweet['referenced_tweets']\n",
    "                for rt in tweet_dictionary_new['referenced_tweets']:\n",
    "                    for tweetexpanse in json_obj['includes']['tweets']:\n",
    "                        if (rt['id'] == tweetexpanse['id']):\n",
    "                            rt['author_id'] = make_objid(str(tweetexpanse['author_id']))\n",
    "                            rt['id'] = make_objid(str(tweetexpanse['id']))\n",
    "                            break   \n",
    "                            \n",
    "            if (IsUnknown(tweet_dictionary_new['author_id'], user_list) == True):\n",
    "                if ('includes' in json_obj):\n",
    "                    for user in json_obj['includes']['users']:\n",
    "                        user_dictionary_new = User_to_Dictionary(tweet_dictionary_new['author_id'], user)\n",
    "                        user_list.append(user_dictionary_new)\n",
    "                        break\n",
    "                else:\n",
    "                    # datetime object containing current date and time\n",
    "                    now = datetime.datetime.now()\n",
    "                    # dd/mm/YY H:M:S\n",
    "                    dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "                    errorlog = open(\"./errorlog\" + d1 + \".txt\", \"a\")\n",
    "                    errorlog.write(\"El formato del mensaje recibido no es el correcto\" + dt_string + \"\\n\")\n",
    "                    errorlog.close()\n",
    "            \n",
    "            tweet_list.append(tweet_dictionary_new)\n",
    "\n",
    "        if ('next_token' in json_obj['meta']):\n",
    "            total = (int(json_obj['meta']['result_count']), json_obj['meta']['next_token'], tweet_list, user_list)\n",
    "        else:\n",
    "            total = (int(json_obj['meta']['result_count']), '', tweet_list, user_list)\n",
    "\n",
    "        print(\"     N'umero de peticiones enviadas: \" + str(PETITIONS_LIMIT))\n",
    "        print(\"     N'umero de peticiones recibidas: \" + str(json_obj['meta']['result_count']))\n",
    "        return total\n",
    "    # caso en el que la respuesta es vac'ia o un error.\n",
    "    else:    \n",
    "        total = (0, next_token, [], [])\n",
    "    return total\n",
    "\n",
    "def TweetList(hashtag, start, end, bearer, token):\n",
    "    '''\n",
    "        hashtag: nombre del hashtag que se va a buscar\n",
    "        start: fecha de inicio\n",
    "        end: fecha de respuesta\n",
    "        number: n'umero de tweets que queremos obtener\n",
    "        bearer: bearer id\n",
    "        return devuelve dos diccionarios (users-tweet, tweet-tweet_items)\n",
    "    '''\n",
    "    global tiempo\n",
    "    global TIMER\n",
    "    global TIMER_LOG\n",
    "    global tweet_count\n",
    "    global hashtag_ini_log\n",
    "    global hashtag_last_log\n",
    "    global start_log_timer\n",
    "    global d1\n",
    "    \n",
    "\n",
    "    #aqui deberia de hacer dos variables de incio y fin de log para saber con cual hashtag empiezo y termino y con cuantos valores totales de cada uno.QUITAR TWEETLIST\n",
    "    total = 0\n",
    "    aux = 0\n",
    "    startTime = 0\n",
    "    endTime = 0\n",
    "    response = (0, token, [], [])\n",
    "\n",
    "    startTime = time.time()\n",
    "    response =  PetitionsLessEqualPETITIONS_LIMIT(hashtag, start, end, bearer, response[1])\n",
    "        \n",
    "    total = response[0]\n",
    "    tweet_count += response[0]\n",
    "    endTime = time.time()\n",
    "\n",
    "    aux = truncate(endTime - startTime)\n",
    "    if (aux < TIMER):\n",
    "        number = TIMER - aux\n",
    "        time.sleep(number)\n",
    "        tiempo -= TIMER\n",
    "    else:\n",
    "        tiempo -= aux\n",
    "    \n",
    "    if (tiempo <= 0):\n",
    "        #aqui se imprime en el log los hashtags que se han escrito y c'uantos valores se han obtenido de estos\n",
    "        tiempo = TIMER_LOG\n",
    "        now = datetime.datetime.now()\n",
    "        # dd/mm/YY H:M:S\n",
    "        dt_string = now.strftime(\"%H:%M:%S\")\n",
    "        hashtag_last_log = hashtag\n",
    "        log = open(\"./log\" + d1 + \".txt\", \"a\")\n",
    "        log.write(hashtag_ini_log + ' ' + start_log_timer + ' ' + hashtag + ' ' + start + ' ' + dt_string + '\\n')\n",
    "        log.close()\n",
    "        start_log_timer = dt_string\n",
    "        tweet_count = 0\n",
    "        hashtag_ini_log = hashtag_last_log\n",
    "        \n",
    "    return (total, response[1], response[2], response[3])\n",
    "\n",
    "def InitHashtagsListLastToken(start_date, end_date):\n",
    "    '''\n",
    "        start_date: D'ia de inicializaci'on del algoritmo\n",
    "        end_date: D'ia de finalizaci'on del algoritmo\n",
    "        return: lista de tuplas (hashtag, next_token, current_date, next_date)\n",
    "    '''\n",
    "    global d1\n",
    "    \n",
    "    aux = []\n",
    "    \n",
    "    if os.path.exists(\"./lasttoken.txt\") and os.path.getsize(\"./lasttoken.txt\") > 0:\n",
    "        f =  open(\"./lasttoken.txt\", \"r\")\n",
    "        hashtag = ''\n",
    "        while True:\n",
    "            # read line\n",
    "            try:\n",
    "                hashtag = f.readline()\n",
    "                if (hashtag == \"\") :\n",
    "                    break\n",
    "            except:\n",
    "                # datetime object containing current date and time\n",
    "                now = datetime.datetime.now()\n",
    "                # dd/mm/YY H:M:S\n",
    "                dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "                errorlog = open(\"./errorlog\" + d1 + \".txt\", \"a\")\n",
    "                errorlog.write(\"Fallo al leer el fichero hashtags.txt \" + dt_string + \"\\n\")\n",
    "                errorlog.close()\n",
    "            hashtag = hashtag.rstrip('\\n')\n",
    "            hashtag = hashtag.split(' ')\n",
    "            node_aux = node.copy()\n",
    "            node_aux['hashtag'] = hashtag[0].upper()\n",
    "            node_aux['next_token'] = hashtag[1]\n",
    "            node_aux['current_date'] = hashtag[2]\n",
    "            node_aux[\"next_date\"] = hashtag[3]  \n",
    "            aux.append(node_aux)\n",
    "        f.close()\n",
    "\n",
    "        fd=open(\"./lasttoken.txt\",\"r\")\n",
    "        d=fd.read()\n",
    "        fd.close()\n",
    "        m=d.split(\"\\n\")\n",
    "        s=\"\\n\".join(m[:-1])\n",
    "\n",
    "        fd=open(\"./lasttoken.txt\",\"w+\")\n",
    "        for i in range(len(s)):\n",
    "            fd.write(s[i])\n",
    "        fd.close()\n",
    "        \n",
    "    else:\n",
    "        #####Uso de Hashtag\n",
    "        f =  open(\"./hashtags.txt\", \"r\")\n",
    "        d =  open(\"./lasttoken.txt\", \"w+\")\n",
    "        hashtag = None\n",
    "        writeable = ''\n",
    "        resultado = (0, '', [], [])\n",
    "        first = start_date.split('-')\n",
    "        dat = date(int(first[2]), int(first[1]), int(first[0]))\n",
    "        first_day = dat\n",
    "        dat += datetime.timedelta(days=1)\n",
    "        next_day = dat\n",
    "        str_first_day = first_day.strftime(\"%d/%m/%Y\")\n",
    "        str_next_day = next_day.strftime(\"%d/%m/%Y\")\n",
    "        while True:\n",
    "            # read line\n",
    "            try:\n",
    "                hashtag = f.readline()\n",
    "                if (hashtag == \"\") :\n",
    "                    break\n",
    "            except:\n",
    "                # datetime object containing current date and time\n",
    "                now = datetime.datetime.now()\n",
    "                # dd/mm/YY H:M:S\n",
    "                dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "                errorlog = open(\"./errorlog\" + d1 + \".txt\", \"a\")\n",
    "                errorlog.write(\"Fallo al leer el fichero hashtags.txt \" + dt_string + \"\\n\")\n",
    "                errorlog.close()\n",
    "            \n",
    "            hashtag = hashtag.rstrip('\\n')\n",
    "            hashtag = hashtag.replace('#', '')\n",
    "            \n",
    "            node_aux = node.copy()\n",
    "            node_aux[\"hashtag\"] = hashtag\n",
    "            writeable = hashtag\n",
    "\n",
    "            writeable += ' ' + node_aux['next_token']\n",
    "\n",
    "            node_aux[\"current_date\"] = str_first_day   \n",
    "            writeable += ' ' + str_first_day \n",
    "\n",
    "            node_aux[\"next_date\"] = str_next_day \n",
    "            writeable += ' ' + str_next_day + '\\n'   \n",
    "\n",
    "            aux.append(node_aux)\n",
    "            d.write(writeable)\n",
    "        d.close()\n",
    "    f.close()\n",
    "    return aux\n",
    "\n",
    "def NextDate(current_date):\n",
    "    '''\n",
    "        current_date: D'ia de entrada\n",
    "        return: Devuelve el d'ia siguiente al d'ia actual\n",
    "    '''\n",
    "    dat = datetime.datetime.strptime(current_date, \"%d/%m/%Y\")\n",
    "    dat += datetime.timedelta(days=1)\n",
    "    return dat.strftime(\"%d/%m/%Y\").split(' ')[0]\n",
    "\n",
    "def truncate(n):\n",
    "    s = str(float(n)).split('.')\n",
    "    return int(s[0])\n",
    "\n",
    "def GetTweets(start_date, end_date):\n",
    "    '''\n",
    "        start_date: D'ia de entrada\n",
    "        end_date: Devuelve el d'ia siguiente al d'ia actual\n",
    "    '''\n",
    "    global tiempo\n",
    "    global TIMER\n",
    "    global TIMER_LOG\n",
    "    global tweet_count\n",
    "    global hashtags\n",
    "    global d1\n",
    "\n",
    "    aux = end_date.split('-')\n",
    "    last_date = date(int(aux[2]), int(aux[1]), int(aux[0]))\n",
    "    last_date = last_date.strftime(\"%d/%m/%Y\")\n",
    "\n",
    "    f =  open(\"./hashtags.txt\", \"r\")\n",
    "    hashtags = f.readlines()\n",
    "    f.close()\n",
    "    \n",
    "    \n",
    "    hashtagsList = InitHashtagsListLastToken(start_date, end_date)\n",
    "        \n",
    "\n",
    "    for h in hashtagsList:\n",
    "        print(str(h))\n",
    "        \n",
    "\n",
    "    if (len(hashtagsList) != 0):\n",
    "        hashtag_ini_log = hashtagsList[0]\n",
    "        # dd/mm/YY H:M:S\n",
    "        now = datetime.datetime.now()\n",
    "        dt_string = now.strftime(\"%H:%M:%S\")\n",
    "        start_log_timer = dt_string\n",
    "        \n",
    "    else:\n",
    "        # datetime object containing current date and time\n",
    "        now = datetime.datetime.now()\n",
    "        # dd/mm/YY H:M:S\n",
    "        dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "        errorlog = open(\"./errorlog\" + d1 + \".txt\", \"a\")\n",
    "        errorlog.write(\"Error: lista de hashtags vacía\" + \" dt_string\\n\")\n",
    "        errorlog.close()\n",
    "\n",
    "    count = 0\n",
    "    temporalTokens = ''\n",
    "    tweet_list = []\n",
    "    user_list = []\n",
    "    start = 0\n",
    "    end = 0\n",
    "    \n",
    "    last = False\n",
    "    while hashtagsList[len(hashtagsList) - 1]['current_date'] != last_date:\n",
    "        for l in hashtagsList:\n",
    "            if l['current_date'] != last_date:\n",
    "                start = 0\n",
    "                end = 0\n",
    "                aux = 0\n",
    "                #bucle de obtencion de tweets para un dia concreto\n",
    "                while (l[\"next_token\"] != ''):\n",
    "                    if l[\"next_token\"] == '-1':\n",
    "                        print('Inicio hashtag: ' + l['hashtag'] + ' día: ' + l['current_date'])\n",
    "                        resultado = TweetList(l[\"hashtag\"], l[\"current_date\"], l[\"next_date\"], Bearer, '')\n",
    "                    else:\n",
    "                        resultado = TweetList(l[\"hashtag\"], l[\"current_date\"], l[\"next_date\"], Bearer, l[\"next_token\"])\n",
    "                        \n",
    "                    start = time.time()\n",
    "                    tweet_list.extend(resultado[2])\n",
    "                    user_list.extend(resultado[3])\n",
    "                    l[\"next_token\"] = resultado[1]\n",
    "                    end = time.time()\n",
    "\n",
    "                    tiempo -= truncate(start - end)\n",
    "\n",
    "                    if (tiempo <= 0):\n",
    "                        # datetime object containing current date and time\n",
    "                        tiempo = TIMER_LOG\n",
    "                        now = datetime.datetime.now()\n",
    "                        # dd/mm/YY H:M:S\n",
    "                        dt_string = now.strftime(\"%H:%M:%S\")\n",
    "                        log = open(\"./log\" + d1 + \".txt\", \"a\")\n",
    "                        log.write(hashtag_ini_log + ' ' + start_log_timer + ' ' + l['hashtag'] + ' ' + l['current_date'] + ' ' + dt_string + '\\n')\n",
    "                        log.close()\n",
    "                        hashtag_ini_log = l['hashtag']\n",
    "\n",
    "                start = time.time()\n",
    "                # Substring de % para insertar en la base de datos\n",
    "                count = 0\n",
    "                count = truncate(math.ceil(len(tweet_list) * PERCENT))\n",
    "                if len(tweet_list) > 0:\n",
    "                    if count > 0:\n",
    "                        tweet_list = tweet_list[0:count]\n",
    "                    else:\n",
    "                        tweet_list = list(tweet_list[0])\n",
    "                    aux_list = []\n",
    "                    # Ahora buscamos los users relacionados con los tweets de la lista\n",
    "                    for t in tweet_list:\n",
    "                        for u in user_list:\n",
    "                            if (str(t['author_id']) == str(u['_id'])):\n",
    "                                aux_list.append(u)\n",
    "                                break \n",
    "                    MongoExecute(tweet_list, aux_list)\n",
    "\n",
    "                #ahora cambiamos de d'ia y quitamos la lista\n",
    "                tweet_list = []\n",
    "                user_list = []\n",
    "                print('Fin hashtag: ' + l['hashtag'] + ' día: ' + l['current_date'])\n",
    "                l['current_date'] = l['next_date']\n",
    "                l['next_date'] = NextDate(l['current_date'])\n",
    "                l['next_token'] = '-1'\n",
    "                \n",
    "                #borramos la 'ultima linea de fichero de lasttoken\n",
    "                if os.path.exists(\"./lasttoken.txt\") and os.path.getsize(\"./lasttoken.txt\") > 0:\n",
    "                    d = ''\n",
    "                    f =  open(\"./lasttoken.txt\", \"r\")\n",
    "                    #remove last line from a text line in python\n",
    "                    d = f.readlines()\n",
    "                    f.close()\n",
    "\n",
    "                    for i in range(len(d)):\n",
    "                        if d[i].split()[0] == l['hashtag']:\n",
    "                            if (l['current_date'] != last_date):\n",
    "                                d[i] = l['hashtag'] + ' ' + l['next_token'] + ' ' + l['current_date'] + ' ' + l[\"next_date\"] + '\\n'\n",
    "                                break\n",
    "                            else:\n",
    "                                d[i] = ''\n",
    "                                break\n",
    "\n",
    "                    f = open(\"./lasttoken.txt\",\"w+\")\n",
    "                    f.writelines(d)\n",
    "                    f.close()\n",
    "\n",
    "                end = time.time()\n",
    "\n",
    "                tiempo -= truncate(start - end)\n",
    "                if (tiempo <= 0):\n",
    "                    # datetime object containing current date and time\n",
    "                    tiempo = TIMER_LOG\n",
    "                    now = datetime.datetime.now()\n",
    "                    # dd/mm/YY H:M:S\n",
    "                    dt_string = now.strftime(\"%H:%M:%S\")\n",
    "                    log = open(\"./log\" + d1 + \".txt\", \"a\")\n",
    "                    log.write(hashtag_ini_log + ' ' + start_log_timer + ' ' + l['hashtag'] + ' ' + l['current_date'] + ' ' + dt_string + '\\n')\n",
    "                    log.close()\n",
    "                    hashtag_ini_log = l['hashtag']\n",
    "                    \n",
    "            \n",
    "    if hashtagsList[len(hashtagsList) - 1]['current_date'] == last_date and os.path.exists(\"./lasttoken.txt\"):\n",
    "        os.remove(\"./lasttoken.txt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hashtag': 'DemocraciaOFascismo4M', 'current_date': '23/04/2021', 'next_date': '24/04/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'SosoSerioYFormal', 'current_date': '23/04/2021', 'next_date': '24/04/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'ColetasRata', 'current_date': '23/04/2021', 'next_date': '24/04/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'RataSinColeta', 'current_date': '23/04/2021', 'next_date': '24/04/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'PodemosAtacaAPodemos', 'current_date': '23/04/2021', 'next_date': '24/04/2021', 'next_token': '-1'}\n",
      "{'hashtag': '4MConPabloIglesias', 'current_date': '23/04/2021', 'next_date': '24/04/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'semarlaskalatragedia', 'current_date': '23/04/2021', 'next_date': '24/04/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'IreneMonteroDimision', 'current_date': '23/04/2021', 'next_date': '24/04/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'TeamVox', 'current_date': '23/04/2021', 'next_date': '24/04/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'SoloQuedaVox', 'current_date': '23/04/2021', 'next_date': '24/04/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'VoxLivesMatter', 'current_date': '23/04/2021', 'next_date': '24/04/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'Elecciones4M', 'current_date': '23/04/2021', 'next_date': '24/04/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'NazisYCorruptos', 'current_date': '23/04/2021', 'next_date': '24/04/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'Pucherazo', 'current_date': '23/04/2021', 'next_date': '24/04/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'RompeTuVoto', 'current_date': '23/04/2021', 'next_date': '24/04/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'IlegalizacionDeVoxYa', 'current_date': '23/04/2021', 'next_date': '24/04/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'DebateSER', 'current_date': '23/04/2021', 'next_date': '24/04/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'VotaLIBERTAD', 'current_date': '23/04/2021', 'next_date': '24/04/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'DebateTelemadrid', 'current_date': '23/04/2021', 'next_date': '24/04/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'eleccionesMadrid2021', 'current_date': '23/04/2021', 'next_date': '24/04/2021', 'next_token': '-1'}\n",
      "Inicio hashtag: DemocraciaOFascismo4M día: 23/04/2021\n",
      "     N'umero de peticiones enviadas: 500\n",
      "     N'umero de peticiones recibidas: 7\n",
      "<pymongo.results.InsertManyResult object at 0x000001C2E573A600>\n",
      "<pymongo.results.InsertManyResult object at 0x000001C2C64AD200>\n",
      "2\n",
      "Fin hashtag: DemocraciaOFascismo4M día: 23/04/2021\n",
      "Inicio hashtag: SosoSerioYFormal día: 23/04/2021\n",
      "     N'umero de peticiones enviadas: 500\n",
      "     N'umero de peticiones recibidas: 4\n",
      "<pymongo.results.InsertManyResult object at 0x000001C2E5786980>\n",
      "<pymongo.results.InsertManyResult object at 0x000001C2C65C7840>\n",
      "1\n",
      "Fin hashtag: SosoSerioYFormal día: 23/04/2021\n",
      "Inicio hashtag: ColetasRata día: 23/04/2021\n",
      "     N'umero de peticiones enviadas: 500\n",
      "     N'umero de peticiones recibidas: 487\n",
      "     N'umero de peticiones enviadas: 500\n",
      "     N'umero de peticiones recibidas: 470\n",
      "     N'umero de peticiones enviadas: 500\n",
      "     N'umero de peticiones recibidas: 487\n",
      "     N'umero de peticiones enviadas: 500\n",
      "     N'umero de peticiones recibidas: 461\n",
      "<pymongo.results.InsertManyResult object at 0x000001C2E5D87140>\n",
      "286\n",
      "Fin hashtag: ColetasRata día: 23/04/2021\n",
      "Inicio hashtag: RataSinColeta día: 23/04/2021\n",
      "Fin hashtag: RataSinColeta día: 23/04/2021\n",
      "Inicio hashtag: PodemosAtacaAPodemos día: 23/04/2021\n",
      "     N'umero de peticiones enviadas: 500\n",
      "     N'umero de peticiones recibidas: 476\n",
      "     N'umero de peticiones enviadas: 500\n",
      "     N'umero de peticiones recibidas: 16\n",
      "74\n",
      "Fin hashtag: PodemosAtacaAPodemos día: 23/04/2021\n",
      "Inicio hashtag: 4MConPabloIglesias día: 23/04/2021\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-6ea93f7fbdd3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[0mGetTweets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"23-04-2021\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"25-04-2021\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-3103cda669a9>\u001b[0m in \u001b[0;36mGetTweets\u001b[1;34m(start_date, end_date)\u001b[0m\n\u001b[0;32m    507\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"next_token\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'-1'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m                         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Inicio hashtag: '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'hashtag'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' día: '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'current_date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 509\u001b[1;33m                         \u001b[0mresultado\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTweetList\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"hashtag\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"current_date\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"next_date\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBearer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    510\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    511\u001b[0m                         \u001b[0mresultado\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTweetList\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"hashtag\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"current_date\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"next_date\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBearer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"next_token\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-3103cda669a9>\u001b[0m in \u001b[0;36mTweetList\u001b[1;34m(hashtag, start, end, bearer, token)\u001b[0m\n\u001b[0;32m    304\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m     \u001b[0mstartTime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 306\u001b[1;33m     \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mPetitionsLessEqualPETITIONS_LIMIT\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhashtag\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbearer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m     \u001b[0mtotal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-3103cda669a9>\u001b[0m in \u001b[0;36mPetitionsLessEqualPETITIONS_LIMIT\u001b[1;34m(hashtag, start, end, bearer, next_token)\u001b[0m\n\u001b[0;32m    225\u001b[0m     \u001b[0mjson_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 227\u001b[1;33m         \u001b[0mjson_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconnect_to_endpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    228\u001b[0m     \u001b[1;31m# Caso en el que falla el conect to endpoint\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-3103cda669a9>\u001b[0m in \u001b[0;36mconnect_to_endpoint\u001b[1;34m(headers, params)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \"\"\"\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mglobal\u001b[0m \u001b[0md1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m     \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"GET\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"https://api.twitter.com/2/tweets/search/all?\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m     \u001b[1;31m# Manejo de errores\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m200\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documentos\\TFG-Bots-OSN\\TFGBotsV2\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documentos\\TFG-Bots-OSN\\TFGBotsV2\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    540\u001b[0m         }\n\u001b[0;32m    541\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documentos\\TFG-Bots-OSN\\TFGBotsV2\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    653\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    654\u001b[0m         \u001b[1;31m# Send the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 655\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m         \u001b[1;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documentos\\TFG-Bots-OSN\\TFGBotsV2\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    437\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mchunked\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 439\u001b[1;33m                 resp = conn.urlopen(\n\u001b[0m\u001b[0;32m    440\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m                     \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documentos\\TFG-Bots-OSN\\TFGBotsV2\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    697\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m             \u001b[1;31m# Make the request on the httplib connection object.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m             httplib_response = self._make_request(\n\u001b[0m\u001b[0;32m    700\u001b[0m                 \u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m                 \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documentos\\TFG-Bots-OSN\\TFGBotsV2\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    380\u001b[0m         \u001b[1;31m# Trigger any extra validation we need to do.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 382\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    383\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m             \u001b[1;31m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documentos\\TFG-Bots-OSN\\TFGBotsV2\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[1;34m(self, conn)\u001b[0m\n\u001b[0;32m   1008\u001b[0m         \u001b[1;31m# Force connect early to allow us to validate the connection.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"sock\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1010\u001b[1;33m             \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1011\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1012\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_verified\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documentos\\TFG-Bots-OSN\\TFGBotsV2\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    351\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m         \u001b[1;31m# Add certificate verification\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 353\u001b[1;33m         \u001b[0mconn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    354\u001b[0m         \u001b[0mhostname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m         \u001b[0mtls_in_tls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Documentos\\TFG-Bots-OSN\\TFGBotsV2\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 169\u001b[1;33m             conn = connection.create_connection(\n\u001b[0m\u001b[0;32m    170\u001b[0m                 \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dns_host\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mextra_kw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m             )\n",
      "\u001b[1;32m~\\OneDrive\\Documentos\\TFG-Bots-OSN\\TFGBotsV2\\lib\\site-packages\\urllib3\\util\\connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     84\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0msource_address\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m                 \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m             \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msa\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Si ya se ha buscado anteriormente entonces deberías de comprobar si la búsqueda y lo que se pide de base (n_teets no se que es igual al número de tweets del hashtag)\n",
    "\n",
    "myclient = pymongo.MongoClient('localhost', 27017)\n",
    "mydb = myclient[\"mydatabase\"]\n",
    "myusers = mydb[\"users\"]\n",
    "mytweets = mydb[\"tweets\"]\n",
    "\n",
    "f = open(\"./accountV2.txt\", \"r\")\n",
    "Bearer = f.readline().rstrip('\\n')\n",
    "f.close()\n",
    "headers = create_headers(Bearer)\n",
    "\n",
    "fileObj = Path(\"./log\" + d1 + \".txt\")\n",
    "if (fileObj.is_file()):\n",
    "    os.remove(\"./log\" + d1 + \".txt\")\n",
    "\n",
    "fileObj = Path(\"./errorlog\" + d1 + \".txt\")\n",
    "if (fileObj.is_file()):\n",
    "    os.remove(\"./errorlog\" + d1 + \".txt\")\n",
    "\n",
    "log = open(\"./log\" + d1 + \".txt\", \"a\")\n",
    "log.write(\"Primer log: \")\n",
    "log.close()\n",
    "#Crear ficheros de log\n",
    "errorlog = open(\"./errorlog\" + d1 + \".txt\", \"a\")\n",
    "errorlog.close()\n",
    "\n",
    "\n",
    "GetTweets(\"23-04-2021\", \"25-04-2021\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test de comprobaci'on correlaci'on de tweets con usuarios\n",
    "global myclient\n",
    "global myusers\n",
    "global mytweets\n",
    "global mydb\n",
    "\n",
    "tweets = []\n",
    "users = []\n",
    "try:\n",
    "    tweets = list(mytweets.find())\n",
    "    users = list(myusers.find())\n",
    "except Exception as e:        \n",
    "    pass\n",
    "\n",
    "print('tweets list length: ' + str(len(tweets)))\n",
    "print('users list length: ' + str(len(users)))\n",
    "count = 0\n",
    "for t in tweets:\n",
    "    fail = True\n",
    "    for u in users: \n",
    "        if str(u['_id']) == str(t['author_id']):\n",
    "            count=count+1\n",
    "            fail = False\n",
    "            break\n",
    "    if fail == True:\n",
    "        print('Code not working propperly')\n",
    "        break\n",
    "print('Numero de pares tweet/usuario identificados: ', count)\n",
    "print('Fin test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TFGBotsV2",
   "language": "python",
   "name": "tfgbotsv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "79fc3c954d64dbcf3cc8f2394a5e83a280e126f0ab97a2117c3267677291b603"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
