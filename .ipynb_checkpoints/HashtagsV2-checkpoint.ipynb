{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Versión para tweepy V2\n",
    "from datetime import date\n",
    "import datetime\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "import math\n",
    "import pymongo\n",
    "from bson import ObjectId\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constant and Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "PETITIONS_PER_TIME_LAPSE = 300\n",
    "TIME_LAPSE = 20*60\n",
    "# Tiempo de espera necesario entre peticiones\n",
    "TIMER = TIME_LAPSE/PETITIONS_PER_TIME_LAPSE\n",
    "# Log cada 5 minutos\n",
    "TIMER_LOG = 5*60\n",
    "#porcentaje de tweets que nos quedamos para cada dia\n",
    "PERCENT = 0.15\n",
    "# máximo de tweets por cada petición\n",
    "PETITIONS_LIMIT = 500\n",
    "\n",
    "#VARIABLES\n",
    "iniTimerLog = 0\n",
    "finTimerLog = 0\n",
    "tiempo = TIMER_LOG\n",
    "hashtagsList = []\n",
    "hashtags = []\n",
    "entrada = \"\"\n",
    "next_token = None\n",
    "entradaizq = '' \n",
    "entradader = ''\n",
    "total = 0\n",
    "startDate = ''\n",
    "endDate = ''\n",
    "inicio = 0\n",
    "fin = 0\n",
    "hashtag_ini_log = ''\n",
    "start_log_timer = ''\n",
    "hashtag_last_log = ''\n",
    "tweet_count = 0\n",
    "url = 'https://api.twitter.com/2/tweets/search/all?'\n",
    "today = datetime.date.today()\n",
    "d1 = today.strftime(\"%d-%m-%Y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_dictionary = {\n",
    "    \"_id\"               : None,\n",
    "    \"description\"       : '',\n",
    "    \"created_at\"        : '',\n",
    "    \"verified\"          : '',\n",
    "    \"followers_count\"   : 0,\n",
    "    \"following_count\"   : 0\n",
    "}\n",
    "\n",
    "\n",
    "tweet_dictionary = {\n",
    "    \"_id\"               : None,\n",
    "    \"author_id\"         : '',\n",
    "    \"created_at\"        : '',\n",
    "    \"text\"              : '',\n",
    "    \"hashtag\"           : [],\n",
    "    \"referenced_tweets\" : [],\n",
    "    \"retweet_count\"     : 0,\n",
    "    \"reply_count\"       : 0,\n",
    "    \"reply_count\"       : 0,\n",
    "    \"like_count\"        : 0\n",
    "}\n",
    "\n",
    "\n",
    "node = {\n",
    "    \"hashtag\"           : '',\n",
    "    \"current_date\"        : '',\n",
    "    \"next_date\"        : '',\n",
    "    \"next_token\"        : '-1'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def DayMonthYearToPetition(date):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    splited = ''\n",
    "    if ('/' in date):\n",
    "        splited = date.split('/')\n",
    "    elif ('-' in date):\n",
    "        splited = date.split('-')\n",
    "        \n",
    "    return (splited[2] + '-' + splited[1] + '-' + splited[0])\n",
    "\n",
    "def DayMonthYearToPetition(date):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    splited = ''\n",
    "    if ('/' in date):\n",
    "        splited = date.split('/')\n",
    "    elif ('-' in date):\n",
    "        splited = date.split('-')\n",
    "\n",
    "    return (splited[2] + '-' + splited[1] + '-' + splited[0])\n",
    "\n",
    "def PetitionToDayMonthYear(petition):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    splited = ''\n",
    "    time = ''\n",
    "    splited = petition.split('T')\n",
    "    time = splited[1]\n",
    "    splited = splited[0].split('-')\n",
    "    return (splited[2] + '-' + splited[1] + '-' + splited[0] + 'T' + time)\n",
    "\n",
    "def make_objid(text):\n",
    "    \"\"\"Makes an ObjectId of 4 bytes\n",
    "    \n",
    "    Keyword arguments:\n",
    "    text -- string to be converted into Object ID\n",
    "    \"\"\"\n",
    "    text = str(text)\n",
    "    if not text.strip():\n",
    "        return None\n",
    "    try:\n",
    "        return ObjectId(text.rjust(24,\"0\"))\n",
    "    except Exception as ex:\n",
    "        print(text, ex)\n",
    "        return None\n",
    "\n",
    "def create_headers(bearer_token):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)}\n",
    "    return headers\n",
    "\n",
    "def connect_to_endpoint(headers, params):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    global d1\n",
    "    response = requests.request(\"GET\", \"https://api.twitter.com/2/tweets/search/all?\", headers=headers, params=params, timeout=2)\n",
    "    # Manejo de errores\n",
    "    if response.status_code != 200:\n",
    "        # datetime object containing current date and time\n",
    "        now = datetime.datetime.now()\n",
    "        # dd/mm/YY H:M:S\n",
    "        dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "        errorlog = open(\"./errorlog\" + d1 + \".txt\", \"a\")\n",
    "        errorlog.write(\"Error en respuesta: \" + str(response.status_code) + ', ' + str(response.text) + \" \" + dt_string + \"\\n\")\n",
    "        errorlog.close()\n",
    "    return response.json()\n",
    "\n",
    "def MongoExecute(tweet_list, user_list):\n",
    "    \"\"\"\n",
    "        tweet_list: lista de tweets que se van a insertar en la base de datos\n",
    "        user_list: lista de usuarios que se van a insertar en la base de datos\n",
    "    \"\"\"\n",
    "    global myclient\n",
    "    global myusers\n",
    "    global mytweets\n",
    "    global mydb\n",
    "    \n",
    "    try:\n",
    "        print(str(mytweets.insert_many(tweet_list, ordered=False)))\n",
    "    except Exception as e:        \n",
    "        pass\n",
    "    try:\n",
    "        print(str(myusers.insert_many(user_list, ordered=False)))\n",
    "    except Exception as e:        \n",
    "        pass\n",
    "\n",
    "def PrintTweetsUsers(tweets, users):\n",
    "    print(\"Tweet list\")\n",
    "    for tweet in tweets:\n",
    "        print(\" id: \" + str(tweet['_id']))\n",
    "        print(\" author_id: \" + tweet['author_id'])\n",
    "        print(\" created_at: \" + tweet['created_at'])\n",
    "        print(\" referenced_tweets: \" + str(tweet['referenced_tweets']) + '\\n')\n",
    "\n",
    "    print(\"User list\")\n",
    "    for user in users:\n",
    "        print(\" user_id: \" + str(user['_id']))\n",
    "        print(\" description: \" + user['description'])\n",
    "        print(\" created_at: \" + user['created_at'])\n",
    "        print(\" verified: \" + str(user['verified']))\n",
    "        print(\" followers_count: \" + str(user['followers_count']))\n",
    "        print(\" following_count: \" + str(user['following_count']) + '\\n')\n",
    "\n",
    "        \n",
    "def Init_Tweet_Dictionary():\n",
    "    tweet_dictionary_new = tweet_dictionary.copy()\n",
    "    tweet_dictionary_new['hashtag'] = []\n",
    "    tweet_dictionary_new['referenced_tweets'] = []\n",
    "    return tweet_dictionary_new\n",
    "\n",
    "def Tweet_to_Dictionary(tweet):\n",
    "    tweet_dictionary_new = Init_Tweet_Dictionary()\n",
    "    tweet_dictionary_new['_id'] = make_objid(str(tweet['id']))\n",
    "    tweet_dictionary_new['author_id'] = make_objid(str(tweet['author_id']))\n",
    "    tweet_dictionary_new['text'] = tweet['text']\n",
    "    tweet_dictionary_new['created_at'] = tweet['created_at']\n",
    "    tweet_dictionary_new['retweet_count'] = tweet['public_metrics']['retweet_count']\n",
    "    tweet_dictionary_new['reply_count'] = tweet['public_metrics']['reply_count']\n",
    "    tweet_dictionary_new['like_count'] = tweet['public_metrics']['like_count']\n",
    "    tweet_dictionary_new['quote_count'] = tweet['public_metrics']['quote_count']\n",
    "\n",
    "    # Inserci'on de hashtags del tweet para los casos de tweets sin referencias, quotes o respuestas\n",
    "    if \"entities\" in tweet and \"hashtags\" in tweet[\"entities\"]:\n",
    "        [tweet_dictionary_new['hashtag'].append(h['tag'].upper()) for h in tweet[\"entities\"][\"hashtags\"]]\n",
    "    return tweet_dictionary_new\n",
    "        \n",
    "def User_to_Dictionary(user_id, user):\n",
    "    # Inicializar dictionary de usuarios                \n",
    "    user_dictionary_new = user_dictionary.copy()\n",
    "    user_dictionary_new['_id'] = user_id\n",
    "    if str(make_objid(user['id'])) == str(user_dictionary_new['_id']):\n",
    "        user_dictionary_new['description'] = user['description']\n",
    "        user_dictionary_new['created_at'] = user['created_at']\n",
    "        user_dictionary_new['verified'] = user['verified']\n",
    "        user_dictionary_new['followers_count'] = int(user['public_metrics']['followers_count'])\n",
    "        user_dictionary_new['following_count'] = int(user['public_metrics']['following_count'])\n",
    "    return user_dictionary_new\n",
    "\n",
    "def IsUnknown(user_id, user_list):\n",
    "    for user in user_list:\n",
    "        if (str(user['_id']) == str(user_id)):\n",
    "            return False\n",
    "    return True\n",
    "        \n",
    "def PetitionsLessEqualPETITIONS_LIMIT(hashtag, start, end, bearer, next_token):\n",
    "    '''\n",
    "        Hashtag: nombre del hashtag que se va a buscar\n",
    "        start: fecha de inicio\n",
    "        end: fecha de respuesta\n",
    "        number: n'umero de tweets que queremos obtener\n",
    "        bearer: bearer id\n",
    "        next_token: token de la page (inicialmente string vac'ia) que quieres buscar\n",
    "        return: tupla de n'umero de respuestas y next_token\n",
    "    '''\n",
    "    global headers\n",
    "    global PETITIONS_LIMIT\n",
    "    global hashtagsList\n",
    "    global hashtags\n",
    "    global d1\n",
    "\n",
    "    startDate = DayMonthYearToPetition(start)\n",
    "    endDate = DayMonthYearToPetition(end)\n",
    "    tweet_list = []\n",
    "    user_list = []\n",
    "    total = (0, '', [], [])\n",
    "    dt_string = ''\n",
    "    tweet_dictionary_new = {}\n",
    "    user_dictionary_new = {}\n",
    "    aux = ''\n",
    "    \n",
    "    \"\"\"\n",
    "     Insertados los siguientes campos:\n",
    "        -start_time: límite inferior en búsqueda de fechas\n",
    "        -end_time: límete superior en búsqueda de fechas\n",
    "        -tweet.fields=author_id: id del autor del tweet\n",
    "        -tweet.fields=referenced_tweets: puede ser quote, retweet o replied_to junto al id al que responde, agrega además los tweets relativos al tweet al que responde\n",
    "        -tweet.fields=created_at: cu'ando se cre'o el fichero\n",
    "        -tweet.fields=context_annotations:anotaciones de contexto (no salen muchas)\n",
    "        -tweet.fields=lang: Abreviatura del idioma en el que se escribe\n",
    "        -tweet.fields=entities: referencias, hashtags usados por el usuario\n",
    "        -tweet.fields=in_reply_to_user_id: \n",
    "        -tweet.fields=conversation_id: \n",
    "        -tweet.fields=public_metrics:\n",
    "        -tweet.fields=text:\n",
    "        -tweet.fields=entities:\n",
    "        -expansions=author_id\n",
    "        -expansions=referenced_tweets.id\n",
    "        -expansions=author_id,referenced_tweets.id\n",
    "        -user.fields=created_at\n",
    "        -user.fields=entities\n",
    "        -user.fields=description\n",
    "        -user.fields=verified\n",
    "        -user.fields=public_metrics\n",
    "    \"\"\"\n",
    "    params = \"query=%23\" + hashtag + \"&start_time=\" +  startDate + \"T00%3A00%3A00Z\" + \"&end_time=\" + endDate + 'T11%3A59%3A59Z&max_results=' + str(PETITIONS_LIMIT) + \"&expansions=author_id,referenced_tweets.id&tweet.fields=created_at,conversation_id,referenced_tweets,public_metrics,text,entities&user.fields=created_at,entities,description,verified,public_metrics\"\n",
    "\n",
    "    # caso en el que -1 (primera peticion de dia) o es el next_token\n",
    "    if (next_token != ''):\n",
    "        params = params + '&next_token=' + next_token\n",
    "        \n",
    "    json_obj = ''\n",
    "    try:\n",
    "        json_obj = connect_to_endpoint(headers=headers, params=params)\n",
    "    # Caso en el que falla el conect to endpoint\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return (0, next_token, [], [])\n",
    "    \n",
    "    # Comprobar que hay respuestas para dicho hashtag\n",
    "    if ('meta' in json_obj) and (int(json_obj['meta']['result_count']) > 0):\n",
    "        # Iteraci'on lista de objetos tweets\n",
    "        for tweet in json_obj['data']:\n",
    "            # Inicializar dictionary de tweet\n",
    "            tweet_dictionary_new = Tweet_to_Dictionary(tweet)\n",
    "            # Inserci'on de los tweets referidos en la lista de tweets referedios con sus object id\n",
    "            if ('referenced_tweets' in tweet):\n",
    "                tweet_dictionary_new['referenced_tweets'] = tweet['referenced_tweets']\n",
    "                for rt in tweet_dictionary_new['referenced_tweets']:\n",
    "                    for tweetexpanse in json_obj['includes']['tweets']:\n",
    "                        if (rt['id'] == tweetexpanse['id']):\n",
    "                            rt['author_id'] = make_objid(str(tweetexpanse['author_id']))\n",
    "                            rt['id'] = make_objid(str(tweetexpanse['id']))\n",
    "                            break   \n",
    "                            \n",
    "            if (IsUnknown(tweet_dictionary_new['author_id'], user_list) == True):\n",
    "                if ('includes' in json_obj):\n",
    "                    for user in json_obj['includes']['users']:\n",
    "                        user_dictionary_new = User_to_Dictionary(tweet_dictionary_new['author_id'], user)\n",
    "                        user_list.append(user_dictionary_new)\n",
    "                        break\n",
    "                else:\n",
    "                    # datetime object containing current date and time\n",
    "                    now = datetime.datetime.now()\n",
    "                    # dd/mm/YY H:M:S\n",
    "                    dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "                    errorlog = open(\"./errorlog\" + d1 + \".txt\", \"a\")\n",
    "                    errorlog.write(\"El formato del mensaje recibido no es el correcto\" + dt_string + \"\\n\")\n",
    "                    errorlog.close()\n",
    "            \n",
    "            tweet_list.append(tweet_dictionary_new)\n",
    "\n",
    "        if ('next_token' in json_obj['meta']):\n",
    "            total = (int(json_obj['meta']['result_count']), json_obj['meta']['next_token'], tweet_list, user_list)\n",
    "        else:\n",
    "            total = (int(json_obj['meta']['result_count']), '', tweet_list, user_list)\n",
    "\n",
    "        print(\"     N'umero de peticiones enviadas: \" + str(PETITIONS_LIMIT))\n",
    "        print(\"     N'umero de peticiones recibidas: \" + str(json_obj['meta']['result_count']))\n",
    "        return total\n",
    "    # caso en el que la respuesta es vac'ia o un error.\n",
    "    else:    \n",
    "        total = (0, next_token, [], [])\n",
    "    return total\n",
    "\n",
    "def TweetList(hashtag, start, end, bearer, token):\n",
    "    '''\n",
    "        hashtag: nombre del hashtag que se va a buscar\n",
    "        start: fecha de inicio\n",
    "        end: fecha de respuesta\n",
    "        number: n'umero de tweets que queremos obtener\n",
    "        bearer: bearer id\n",
    "        return devuelve dos diccionarios (users-tweet, tweet-tweet_items)\n",
    "    '''\n",
    "    global tiempo\n",
    "    global TIMER\n",
    "    global TIMER_LOG\n",
    "    global tweet_count\n",
    "    global hashtag_ini_log\n",
    "    global hashtag_last_log\n",
    "    global start_log_timer\n",
    "    global d1\n",
    "    \n",
    "\n",
    "    #aqui deberia de hacer dos variables de incio y fin de log para saber con cual hashtag empiezo y termino y con cuantos valores totales de cada uno.QUITAR TWEETLIST\n",
    "    total = 0\n",
    "    aux = 0\n",
    "    startTime = 0\n",
    "    endTime = 0\n",
    "    response = (0, token, [], [])\n",
    "\n",
    "    startTime = time.time()\n",
    "    response =  PetitionsLessEqualPETITIONS_LIMIT(hashtag, start, end, bearer, response[1])\n",
    "        \n",
    "    total = response[0]\n",
    "    tweet_count += response[0]\n",
    "    endTime = time.time()\n",
    "\n",
    "    aux = truncate(endTime - startTime)\n",
    "    if (aux < TIMER):\n",
    "        number = TIMER - aux\n",
    "        time.sleep(number)\n",
    "        tiempo -= TIMER\n",
    "    else:\n",
    "        tiempo -= aux\n",
    "    \n",
    "    if (tiempo <= 0):\n",
    "        #aqui se imprime en el log los hashtags que se han escrito y c'uantos valores se han obtenido de estos\n",
    "        tiempo = TIMER_LOG\n",
    "        now = datetime.datetime.now()\n",
    "        # dd/mm/YY H:M:S\n",
    "        dt_string = now.strftime(\"%H:%M:%S\")\n",
    "        hashtag_last_log = hashtag\n",
    "        log = open(\"./log\" + d1 + \".txt\", \"a\")\n",
    "        log.write(hashtag_ini_log + ' ' + start_log_timer + ' ' + hashtag + ' ' + start + ' ' + dt_string + '\\n')\n",
    "        log.close()\n",
    "        start_log_timer = dt_string\n",
    "        tweet_count = 0\n",
    "        hashtag_ini_log = hashtag_last_log\n",
    "        \n",
    "    return (total, response[1], response[2], response[3])\n",
    "\n",
    "def InitHashtagsListLastToken(start_date, end_date):\n",
    "    '''\n",
    "        start_date: D'ia de inicializaci'on del algoritmo\n",
    "        end_date: D'ia de finalizaci'on del algoritmo\n",
    "        return: lista de tuplas (hashtag, next_token, current_date, next_date)\n",
    "    '''\n",
    "    global d1\n",
    "    \n",
    "    aux = []\n",
    "    \n",
    "    if os.path.exists(\"./lasttoken.txt\") and os.path.getsize(\"./lasttoken.txt\") > 0:\n",
    "        f =  open(\"./lasttoken.txt\", \"r\")\n",
    "        hashtag = ''\n",
    "        while True:\n",
    "            # read line\n",
    "            try:\n",
    "                hashtag = f.readline()\n",
    "                if (hashtag == \"\") :\n",
    "                    break\n",
    "            except:\n",
    "                # datetime object containing current date and time\n",
    "                now = datetime.datetime.now()\n",
    "                # dd/mm/YY H:M:S\n",
    "                dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "                errorlog = open(\"./errorlog\" + d1 + \".txt\", \"a\")\n",
    "                errorlog.write(\"Fallo al leer el fichero hashtags.txt \" + dt_string + \"\\n\")\n",
    "                errorlog.close()\n",
    "            hashtag = hashtag.rstrip('\\n')\n",
    "            hashtag = hashtag.split(' ')\n",
    "            node_aux = node.copy()\n",
    "            node_aux['hashtag'] = hashtag[0].upper()\n",
    "            node_aux['next_token'] = hashtag[1]\n",
    "            node_aux['current_date'] = hashtag[2]\n",
    "            node_aux[\"next_date\"] = hashtag[3]  \n",
    "            aux.append(node_aux)\n",
    "        f.close()\n",
    "\n",
    "        fd=open(\"./lasttoken.txt\",\"r\")\n",
    "        d=fd.read()\n",
    "        fd.close()\n",
    "        m=d.split(\"\\n\")\n",
    "        s=\"\\n\".join(m[:-1])\n",
    "\n",
    "        fd=open(\"./lasttoken.txt\",\"w+\")\n",
    "        for i in range(len(s)):\n",
    "            fd.write(s[i])\n",
    "        fd.close()\n",
    "        \n",
    "    else:\n",
    "        #####Uso de Hashtag\n",
    "        f =  open(\"./hashtags.txt\", \"r\")\n",
    "        d =  open(\"./lasttoken.txt\", \"w+\")\n",
    "        hashtag = None\n",
    "        writeable = ''\n",
    "        resultado = (0, '', [], [])\n",
    "        first = start_date.split('-')\n",
    "        dat = date(int(first[2]), int(first[1]), int(first[0]))\n",
    "        first_day = dat\n",
    "        dat += datetime.timedelta(days=1)\n",
    "        next_day = dat\n",
    "        str_first_day = first_day.strftime(\"%d/%m/%Y\")\n",
    "        str_next_day = next_day.strftime(\"%d/%m/%Y\")\n",
    "        while True:\n",
    "            # read line\n",
    "            try:\n",
    "                hashtag = f.readline()\n",
    "                if (hashtag == \"\") :\n",
    "                    break\n",
    "            except:\n",
    "                # datetime object containing current date and time\n",
    "                now = datetime.datetime.now()\n",
    "                # dd/mm/YY H:M:S\n",
    "                dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "                errorlog = open(\"./errorlog\" + d1 + \".txt\", \"a\")\n",
    "                errorlog.write(\"Fallo al leer el fichero hashtags.txt \" + dt_string + \"\\n\")\n",
    "                errorlog.close()\n",
    "            \n",
    "            hashtag = hashtag.rstrip('\\n')\n",
    "            hashtag = hashtag.replace('#', '')\n",
    "            \n",
    "            node_aux = node.copy()\n",
    "            node_aux[\"hashtag\"] = hashtag\n",
    "            writeable = hashtag\n",
    "\n",
    "            writeable += ' ' + node_aux['next_token']\n",
    "\n",
    "            node_aux[\"current_date\"] = str_first_day   \n",
    "            writeable += ' ' + str_first_day \n",
    "\n",
    "            node_aux[\"next_date\"] = str_next_day \n",
    "            writeable += ' ' + str_next_day + '\\n'   \n",
    "\n",
    "            aux.append(node_aux)\n",
    "            d.write(writeable)\n",
    "        d.close()\n",
    "    f.close()\n",
    "    return aux\n",
    "\n",
    "def NextDate(current_date):\n",
    "    '''\n",
    "        current_date: D'ia de entrada\n",
    "        return: Devuelve el d'ia siguiente al d'ia actual\n",
    "    '''\n",
    "    dat = datetime.datetime.strptime(current_date, \"%d/%m/%Y\")\n",
    "    dat += datetime.timedelta(days=1)\n",
    "    return dat.strftime(\"%d/%m/%Y\").split(' ')[0]\n",
    "\n",
    "def truncate(n):\n",
    "    s = str(float(n)).split('.')\n",
    "    return int(s[0])\n",
    "\n",
    "def GetTweets(start_date, end_date):\n",
    "    '''\n",
    "        start_date: D'ia de entrada\n",
    "        end_date: Devuelve el d'ia siguiente al d'ia actual\n",
    "    '''\n",
    "    global tiempo\n",
    "    global TIMER\n",
    "    global TIMER_LOG\n",
    "    global tweet_count\n",
    "    global hashtags\n",
    "    global d1\n",
    "\n",
    "    aux = end_date.split('-')\n",
    "    last_date = date(int(aux[2]), int(aux[1]), int(aux[0]))\n",
    "    last_date = last_date.strftime(\"%d/%m/%Y\")\n",
    "\n",
    "    f =  open(\"./hashtags.txt\", \"r\")\n",
    "    hashtags = f.readlines()\n",
    "    f.close()\n",
    "    \n",
    "    \n",
    "    hashtagsList = InitHashtagsListLastToken(start_date, end_date)\n",
    "        \n",
    "\n",
    "    for h in hashtagsList:\n",
    "        print(str(h))\n",
    "        \n",
    "\n",
    "    if (len(hashtagsList) != 0):\n",
    "        hashtag_ini_log = hashtagsList[0]\n",
    "        # dd/mm/YY H:M:S\n",
    "        now = datetime.datetime.now()\n",
    "        dt_string = now.strftime(\"%H:%M:%S\")\n",
    "        start_log_timer = dt_string\n",
    "        \n",
    "    else:\n",
    "        # datetime object containing current date and time\n",
    "        now = datetime.datetime.now()\n",
    "        # dd/mm/YY H:M:S\n",
    "        dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "        errorlog = open(\"./errorlog\" + d1 + \".txt\", \"a\")\n",
    "        errorlog.write(\"Error: lista de hashtags vacía\" + \" dt_string\\n\")\n",
    "        errorlog.close()\n",
    "\n",
    "    count = 0\n",
    "    temporalTokens = ''\n",
    "    tweet_list = []\n",
    "    user_list = []\n",
    "    start = 0\n",
    "    end = 0\n",
    "    \n",
    "    last = False\n",
    "    while hashtagsList[len(hashtagsList) - 1]['current_date'] != last_date:\n",
    "        for l in hashtagsList:\n",
    "            if l['current_date'] != last_date:\n",
    "                start = 0\n",
    "                end = 0\n",
    "                aux = 0\n",
    "                #bucle de obtencion de tweets para un dia concreto\n",
    "                while (l[\"next_token\"] != ''):\n",
    "                    if l[\"next_token\"] == '-1':\n",
    "                        print('Inicio hashtag: ' + l['hashtag'] + ' día: ' + l['current_date'])\n",
    "                        resultado = TweetList(l[\"hashtag\"], l[\"current_date\"], l[\"next_date\"], Bearer, '')\n",
    "                    else:\n",
    "                        resultado = TweetList(l[\"hashtag\"], l[\"current_date\"], l[\"next_date\"], Bearer, l[\"next_token\"])\n",
    "                        \n",
    "                    start = time.time()\n",
    "                    tweet_list.extend(resultado[2])\n",
    "                    user_list.extend(resultado[3])\n",
    "                    l[\"next_token\"] = resultado[1]\n",
    "                    end = time.time()\n",
    "\n",
    "                    tiempo -= truncate(start - end)\n",
    "\n",
    "                    if (tiempo <= 0):\n",
    "                        # datetime object containing current date and time\n",
    "                        tiempo = TIMER_LOG\n",
    "                        now = datetime.datetime.now()\n",
    "                        # dd/mm/YY H:M:S\n",
    "                        dt_string = now.strftime(\"%H:%M:%S\")\n",
    "                        log = open(\"./log\" + d1 + \".txt\", \"a\")\n",
    "                        log.write(hashtag_ini_log + ' ' + start_log_timer + ' ' + l['hashtag'] + ' ' + l['current_date'] + ' ' + dt_string + '\\n')\n",
    "                        log.close()\n",
    "                        hashtag_ini_log = l['hashtag']\n",
    "\n",
    "                start = time.time()\n",
    "                # Substring de % para insertar en la base de datos\n",
    "                count = 0\n",
    "                count = truncate(math.ceil(len(tweet_list) * PERCENT))\n",
    "                if count > 0:\n",
    "                    tweet_list = tweet_list[0:(count - 1)]\n",
    "\n",
    "                aux_list = []\n",
    "                # Ahora buscamos los users relacionados con los tweets de la lista\n",
    "                for t in tweet_list:\n",
    "                    for u in user_list:\n",
    "                        if (str(t['author_id']) == str(u['_id'])):\n",
    "                            aux_list.append(u)\n",
    "                            break \n",
    "\n",
    "                MongoExecute(tweet_list, aux_list)\n",
    "\n",
    "                #ahora cambiamos de d'ia y quitamos la lista\n",
    "                tweet_list = []\n",
    "                user_list = []\n",
    "                print('Fin hashtag: ' + l['hashtag'] + ' día: ' + l['current_date'])\n",
    "                l['current_date'] = l['next_date']\n",
    "                l['next_date'] = NextDate(l['current_date'])\n",
    "                l['next_token'] = '-1'\n",
    "                \n",
    "                #borramos la 'ultima linea de fichero de lasttoken\n",
    "                if os.path.exists(\"./lasttoken.txt\") and os.path.getsize(\"./lasttoken.txt\") > 0:\n",
    "                    d = ''\n",
    "                    f =  open(\"./lasttoken.txt\", \"r\")\n",
    "                    #remove last line from a text line in python\n",
    "                    d = f.readlines()\n",
    "                    f.close()\n",
    "\n",
    "                    for i in range(len(d)):\n",
    "                        if d[i].split()[0] == l['hashtag']:\n",
    "                            if (l['current_date'] != last_date):\n",
    "                                d[i] = l['hashtag'] + ' ' + l['next_token'] + ' ' + l['current_date'] + ' ' + l[\"next_date\"] + '\\n'\n",
    "                                break\n",
    "                            else:\n",
    "                                d[i] = ''\n",
    "                                break\n",
    "\n",
    "                    f = open(\"./lasttoken.txt\",\"w+\")\n",
    "                    f.writelines(d)\n",
    "                    f.close()\n",
    "\n",
    "                end = time.time()\n",
    "\n",
    "                tiempo -= truncate(start - end)\n",
    "                if (tiempo <= 0):\n",
    "                    # datetime object containing current date and time\n",
    "                    tiempo = TIMER_LOG\n",
    "                    now = datetime.datetime.now()\n",
    "                    # dd/mm/YY H:M:S\n",
    "                    dt_string = now.strftime(\"%H:%M:%S\")\n",
    "                    log = open(\"./log\" + d1 + \".txt\", \"a\")\n",
    "                    log.write(hashtag_ini_log + ' ' + start_log_timer + ' ' + l['hashtag'] + ' ' + l['current_date'] + ' ' + dt_string + '\\n')\n",
    "                    log.close()\n",
    "                    hashtag_ini_log = l['hashtag']\n",
    "                    \n",
    "            \n",
    "    if hashtagsList[len(hashtagsList) - 1]['current_date'] == last_date and os.path.exists(\"./lasttoken.txt\"):\n",
    "        os.remove(\"./lasttoken.txt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hashtag': 'DemocraciaOFascismo4M', 'current_date': '23/04/2021', 'next_date': '24/04/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'SosoSerioYFormal', 'current_date': '23/04/2021', 'next_date': '24/04/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'ColetasRata', 'current_date': '23/04/2021', 'next_date': '24/04/2021', 'next_token': '-1'}\n",
      "Inicio hashtag: DemocraciaOFascismo4M día: 23/04/2021\n",
      "     N'umero de peticiones enviadas: 500\n",
      "     N'umero de peticiones recibidas: 7\n",
      "<pymongo.results.InsertManyResult object at 0x0000017515A5AF00>\n",
      "<pymongo.results.InsertManyResult object at 0x0000017515627600>\n",
      "Fin hashtag: DemocraciaOFascismo4M día: 23/04/2021\n",
      "Inicio hashtag: SosoSerioYFormal día: 23/04/2021\n",
      "     N'umero de peticiones enviadas: 500\n",
      "     N'umero de peticiones recibidas: 4\n",
      "Fin hashtag: SosoSerioYFormal día: 23/04/2021\n",
      "Inicio hashtag: ColetasRata día: 23/04/2021\n",
      "     N'umero de peticiones enviadas: 500\n",
      "     N'umero de peticiones recibidas: 487\n",
      "HTTPSConnectionPool(host='api.twitter.com', port=443): Read timed out. (read timeout=2)\n",
      "     N'umero de peticiones enviadas: 500\n",
      "     N'umero de peticiones recibidas: 467\n",
      "     N'umero de peticiones enviadas: 500\n",
      "     N'umero de peticiones recibidas: 487\n",
      "     N'umero de peticiones enviadas: 500\n",
      "     N'umero de peticiones recibidas: 454\n",
      "<pymongo.results.InsertManyResult object at 0x0000017534B7AB40>\n",
      "Fin hashtag: ColetasRata día: 23/04/2021\n",
      "Inicio hashtag: DemocraciaOFascismo4M día: 24/04/2021\n",
      "     N'umero de peticiones enviadas: 500\n",
      "     N'umero de peticiones recibidas: 393\n",
      "     N'umero de peticiones enviadas: 500\n",
      "     N'umero de peticiones recibidas: 368\n",
      "     N'umero de peticiones enviadas: 500\n",
      "     N'umero de peticiones recibidas: 379\n",
      "     N'umero de peticiones enviadas: 500\n",
      "     N'umero de peticiones recibidas: 365\n",
      "     N'umero de peticiones enviadas: 500\n",
      "     N'umero de peticiones recibidas: 418\n",
      "     N'umero de peticiones enviadas: 500\n",
      "     N'umero de peticiones recibidas: 389\n",
      "     N'umero de peticiones enviadas: 500\n",
      "     N'umero de peticiones recibidas: 403\n",
      "     N'umero de peticiones enviadas: 500\n",
      "     N'umero de peticiones recibidas: 371\n",
      "     N'umero de peticiones enviadas: 500\n",
      "     N'umero de peticiones recibidas: 341\n",
      "     N'umero de peticiones enviadas: 500\n",
      "     N'umero de peticiones recibidas: 348\n",
      "     N'umero de peticiones enviadas: 500\n",
      "     N'umero de peticiones recibidas: 358\n",
      "     N'umero de peticiones enviadas: 500\n",
      "     N'umero de peticiones recibidas: 332\n",
      "     N'umero de peticiones enviadas: 500\n",
      "     N'umero de peticiones recibidas: 284\n",
      "<pymongo.results.InsertManyResult object at 0x0000017534E1B400>\n",
      "Fin hashtag: DemocraciaOFascismo4M día: 24/04/2021\n",
      "Inicio hashtag: SosoSerioYFormal día: 24/04/2021\n",
      "     N'umero de peticiones enviadas: 500\n",
      "     N'umero de peticiones recibidas: 21\n",
      "<pymongo.results.InsertManyResult object at 0x0000017534F0D3C0>\n",
      "<pymongo.results.InsertManyResult object at 0x0000017534F0D5C0>\n",
      "Fin hashtag: SosoSerioYFormal día: 24/04/2021\n",
      "Inicio hashtag: ColetasRata día: 24/04/2021\n",
      "     N'umero de peticiones enviadas: 500\n",
      "     N'umero de peticiones recibidas: 443\n",
      "     N'umero de peticiones enviadas: 500\n",
      "     N'umero de peticiones recibidas: 341\n",
      "     N'umero de peticiones enviadas: 500\n",
      "     N'umero de peticiones recibidas: 328\n",
      "     N'umero de peticiones enviadas: 500\n",
      "     N'umero de peticiones recibidas: 50\n",
      "<pymongo.results.InsertManyResult object at 0x00000175348C0600>\n",
      "Fin hashtag: ColetasRata día: 24/04/2021\n"
     ]
    }
   ],
   "source": [
    "# Si ya se ha buscado anteriormente entonces deberías de comprobar si la búsqueda y lo que se pide de base (n_teets no se que es igual al número de tweets del hashtag)\n",
    "\n",
    "myclient = pymongo.MongoClient('localhost', 27017)\n",
    "mydb = myclient[\"mydatabase\"]\n",
    "myusers = mydb[\"users\"]\n",
    "mytweets = mydb[\"tweets\"]\n",
    "\n",
    "f = open(\"./accountV2.txt\", \"r\")\n",
    "Bearer = f.readline().rstrip('\\n')\n",
    "f.close()\n",
    "headers = create_headers(Bearer)\n",
    "\n",
    "fileObj = Path(\"./log\" + d1 + \".txt\")\n",
    "if (fileObj.is_file()):\n",
    "    os.remove(\"./log\" + d1 + \".txt\")\n",
    "\n",
    "fileObj = Path(\"./errorlog\" + d1 + \".txt\")\n",
    "if (fileObj.is_file()):\n",
    "    os.remove(\"./errorlog\" + d1 + \".txt\")\n",
    "\n",
    "log = open(\"./log\" + d1 + \".txt\", \"a\")\n",
    "log.write(\"Primer log: \")\n",
    "log.close()\n",
    "#Crear ficheros de log\n",
    "errorlog = open(\"./errorlog\" + d1 + \".txt\", \"a\")\n",
    "errorlog.close()\n",
    "\n",
    "\n",
    "GetTweets(\"23-04-2021\", \"25-04-2021\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweets list length: 1174\n",
      "users list length: 842\n",
      "Numero de pares tweet/usuario identificados:  1174\n",
      "Fin test\n"
     ]
    }
   ],
   "source": [
    "# test de comprobaci'on correlaci'on de tweets con usuarios\n",
    "global myclient\n",
    "global myusers\n",
    "global mytweets\n",
    "global mydb\n",
    "\n",
    "tweets = []\n",
    "users = []\n",
    "try:\n",
    "    tweets = list(mytweets.find())\n",
    "    users = list(myusers.find())\n",
    "except Exception as e:        \n",
    "    pass\n",
    "\n",
    "print('tweets list length: ' + str(len(tweets)))\n",
    "print('users list length: ' + str(len(users)))\n",
    "count = 0\n",
    "for t in tweets:\n",
    "    fail = True\n",
    "    for u in users: \n",
    "        if str(u['_id']) == str(t['author_id']):\n",
    "            count=count+1\n",
    "            fail = False\n",
    "            break\n",
    "    if fail == True:\n",
    "        print('Code not working propperly')\n",
    "        break\n",
    "print('Numero de pares tweet/usuario identificados: ', count)\n",
    "print('Fin test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TFGBotsV2",
   "language": "python",
   "name": "tfgbotsv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "79fc3c954d64dbcf3cc8f2394a5e83a280e126f0ab97a2117c3267677291b603"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
