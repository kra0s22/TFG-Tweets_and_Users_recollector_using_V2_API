{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "pythonjvsc74a57bd079fc3c954d64dbcf3cc8f2394a5e83a280e126f0ab97a2117c3267677291b603",
   "display_name": "Python 3.9.2  ('TFGBotsV2': venv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "79fc3c954d64dbcf3cc8f2394a5e83a280e126f0ab97a2117c3267677291b603"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Imports "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Versión para tweepy V2\n",
    "from datetime import date\n",
    "import datetime\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "import math\n",
    "import pymongo\n",
    "from bson import ObjectId\n",
    "import numpy as np\n",
    "from datetime import date\n"
   ]
  },
  {
   "source": [
    "## Constant and Variables"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "\n",
    "PETITIONS_PER_TIME_LAPSE = 300\n",
    "TIME_LAPSE = 20*60\n",
    "# Tiempo de espera necesario entre peticiones\n",
    "TIMER = TIME_LAPSE/PETITIONS_PER_TIME_LAPSE\n",
    "# Log cada 2 minutos\n",
    "TIMER_LOG = 2*60\n",
    "\n",
    "#porcentaje de tweets que nos quedamos para cada dia\n",
    "PERCENT = 0.15\n",
    "# máximo de tweets por cada petición\n",
    "PETITIONS_LIMIT = 500\n",
    "\n",
    "#VARIABLES\n",
    "iniTimerLog = 0\n",
    "finTimerLog = 0\n",
    "tiempo = TIMER_LOG\n",
    "hashtagsList = []\n",
    "hashtags = []\n",
    "entrada = \"\"\n",
    "next_token = None\n",
    "entradaizq = '' \n",
    "entradader = ''\n",
    "total = 0\n",
    "startDate = ''\n",
    "endDate = ''\n",
    "inicio = 0\n",
    "fin = 0\n",
    "\n",
    "hashtag_ini_log = ''\n",
    "start_log_timer = ''\n",
    "hashtag_last_log = ''\n",
    "tweet_count = 0\n",
    "\n",
    "url = 'https://api.twitter.com/2/tweets/search/all?'\n",
    "today = datetime.date.today()\n",
    "d1 = today.strftime(\"%d-%m-%Y\")\n",
    "\n"
   ]
  },
  {
   "source": [
    "## Support functions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-3-316f1c766b8e>, line 116)",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-316f1c766b8e>\"\u001b[1;36m, line \u001b[1;32m116\u001b[0m\n\u001b[1;33m    repetido = False\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "user_dictionary = {\n",
    "    \"_id\"               : None,\n",
    "    \"description\"       : '',\n",
    "    \"created_at\"        : '',\n",
    "    \"verified\"          : '',\n",
    "    \"followers_count\"   : 0,\n",
    "    \"following_count\"   : 0\n",
    "}\n",
    "\n",
    "\n",
    "tweet_dictionary = {\n",
    "    \"_id\"               : None,\n",
    "    \"author_id\"         : '',\n",
    "    \"created_at\"        : '',\n",
    "    \"text\"              : '',\n",
    "    \"hashtag\"           : [],\n",
    "    \"referenced_tweets\" : [],\n",
    "    \"retweet_count\"     : 0,\n",
    "    \"reply_count\"       : 0,\n",
    "    \"reply_count\"       : 0,\n",
    "    \"like_count\"        : 0\n",
    "}\n",
    "\n",
    "\n",
    "node = {\n",
    "    \"hashtag\"           : '',\n",
    "    \"current_date\"        : '',\n",
    "    \"next_date\"        : '',\n",
    "    \"next_token\"        : '-1'\n",
    "}\n",
    "\n",
    "\n",
    "def DayMonthYearToPetition(date):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    splited = ''\n",
    "    if ('/' in date):\n",
    "        splited = date.split('/')\n",
    "    elif ('-' in date):\n",
    "        splited = date.split('-')\n",
    "\n",
    "    return (splited[2] + '-' + splited[1] + '-' + splited[0])\n",
    "\n",
    "def DayMonthYearToPetition(date):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    splited = ''\n",
    "    if ('/' in date):\n",
    "        splited = date.split('/')\n",
    "    elif ('-' in date):\n",
    "        splited = date.split('-')\n",
    "\n",
    "    return (splited[2] + '-' + splited[1] + '-' + splited[0])\n",
    "\n",
    "def PetitionToDayMonthYear(petition):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    splited = ''\n",
    "    time = ''\n",
    "    splited = petition.split('T')\n",
    "    time = splited[1]\n",
    "    splited = splited[0].split('-')\n",
    "    return (splited[2] + '-' + splited[1] + '-' + splited[0] + 'T' + time)\n",
    "\n",
    "def make_objid(text):\n",
    "    \"\"\"Makes an ObjectId of 4 bytes\n",
    "    \n",
    "    Keyword arguments:\n",
    "    text -- string to be converted into Object ID\n",
    "    \"\"\"\n",
    "    text = str(text)\n",
    "    if not text.strip():\n",
    "        return None\n",
    "    try:\n",
    "        return ObjectId(text.rjust(24,\"0\"))\n",
    "    except Exception as ex:\n",
    "        #print(len(text))\n",
    "        print(text, ex)\n",
    "        return None\n",
    "\n",
    "def create_headers(bearer_token):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)}\n",
    "    return headers\n",
    "\n",
    "def connect_to_endpoint(headers, params):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    response = requests.request(\"GET\", \"https://api.twitter.com/2/tweets/search/all?\", headers=headers, params=params)\n",
    "    #print(response.status_code)\n",
    "    # Manejo de errores\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.status_code, response.text)\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "def MongoExecute(tweet_list, user_list):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    global myclient\n",
    "    global myusers\n",
    "    global mytweets\n",
    "    global mydb\n",
    "    try:\n",
    "        print(str(mytweets.insert_many(tweet_list, ordered=False)))\n",
    "        print(str(myusers.insert_many(user_list, ordered=False)))\n",
    "    except Exception as e:        \n",
    "        item = None\n",
    "        for tweet in e.details[\"writeErrors\"]:\n",
    "            try:\n",
    "                item = list(mytweets.find({'_id' : tweet['op']['_id']}))[0]\n",
    "                \n",
    "            except Exception as ea:\n",
    "            \n",
    "            repetido = False\n",
    "            print(str(item))\n",
    "            print(str(tweet))\n",
    "            #for hashtag in item['hashtag']:\n",
    "                #if hastag == tweet['hashtag']:\n",
    "                    #repetido = True\n",
    "                    #break\n",
    "            #if repetido == False:\n",
    "                #item[0]['hashtag'].append(tweet['hashtag'])\n",
    "                #try:\n",
    "                    #mytweets.replace_one({'_id' : tweet['op']['_id']}, item)\n",
    "                #except Exception as eaa:\n",
    "                    #pass\n",
    "\n",
    "        pass\n",
    "\n",
    "def PrintTweetsUsers(tweets, users):\n",
    "    print(\"Tweet list\")\n",
    "    for tweet in tweets:\n",
    "        print(\" id: \" + str(tweet['_id']))\n",
    "        print(\" author_id: \" + tweet['author_id'])\n",
    "        print(\" created_at: \" + tweet['created_at'])\n",
    "        print(\" referenced_tweets: \" + str(tweet['referenced_tweets']) + '\\n')\n",
    "\n",
    "    print(\"User list\")\n",
    "    for user in users:\n",
    "        print(\" user_id: \" + str(user['_id']))\n",
    "        print(\" description: \" + user['description'])\n",
    "        print(\" created_at: \" + user['created_at'])\n",
    "        print(\" verified: \" + str(user['verified']))\n",
    "        print(\" followers_count: \" + str(user['followers_count']))\n",
    "        print(\" following_count: \" + str(user['following_count']) + '\\n')\n",
    "\n",
    "#Terminar de insertas los campos del petitionslessequals100\n",
    "    # Insertados los siguientes campos:\n",
    "    #   -start_time: límite inferior en búsqueda de fechas\n",
    "    #   -end_time: límete superior en búsqueda de fechas\n",
    "    #   -tweet.fields=author_id: id del autor del tweet\n",
    "    #   -tweet.fields=referenced_tweets: puede ser quote, retweet o replied_to junto al id al que responde, agrega además los tweets relativos al tweet al que responde\n",
    "    #   -tweet.fields=created_at: cu'ando se cre'o el fichero\n",
    "    #   -tweet.fields=context_annotations:anotaciones de contexto (no salen muchas)\n",
    "    #   -tweet.fields=lang: Abreviatura del idioma en el que se escribe\n",
    "    #   -tweet.fields=entities: referencias, hashtags usados por el usuario\n",
    "    #   -tweet.fields=in_reply_to_user_id: \n",
    "    #   -    in_reply_to_user_id\n",
    "\n",
    "# Hashtag: nombre del hashtag que se va a buscar\n",
    "# start: fecha de inicio\n",
    "# end: fecha de respuesta\n",
    "# number: n'umero de tweets que queremos obtener\n",
    "# bearer: bearer id\n",
    "# next_token: token de la page (inicialmente string vac'ia) que quieres buscar\n",
    "# return tupla de n'umero de respuestas y next_token\n",
    "def PetitionsLessEqualPETITIONS_LIMIT(hashtag, start, end, bearer, next_token):\n",
    "\n",
    "    global log\n",
    "    global errorlog\n",
    "    global headers\n",
    "    global PETITIONS_LIMIT\n",
    "    global hashtagsList\n",
    "    global hashtags\n",
    "\n",
    "    startDate = DayMonthYearToPetition(start)\n",
    "    endDate = DayMonthYearToPetition(end)\n",
    "    tweet_list = []\n",
    "    user_list = []\n",
    "    total = (0, '', [], [])\n",
    "    dt_string = ''\n",
    "    tweet_dictionary_new = {}\n",
    "    user_dictionary_new = {}\n",
    "    aux = ''\n",
    "\n",
    "    \n",
    "\n",
    "    params = \"query=%23\" + hashtag + \"&start_time=\" +  startDate + \"T00%3A00%3A00Z\" + \"&end_time=\" + endDate + 'T11%3A59%3A59Z&max_results=' + str(PETITIONS_LIMIT) + '&expansions=author_id,referenced_tweets.id&tweet.fields=created_at,conversation_id,referenced_tweets,public_metrics&user.fields=created_at,entities,description,verified,public_metrics'\n",
    "    # caso en el que -1 (primera peticion de dia) o es el next_token\n",
    "    if (next_token != ''):\n",
    "        params = params + '&next_token=' + next_token\n",
    "\n",
    "    # primera petici'on del hashtag\n",
    "    json_obj = ''\n",
    "    try:\n",
    "        json_obj = connect_to_endpoint(headers=headers, params=params)\n",
    "        #print(json.dumps(json_obj, indent=4, sort_keys=True))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return (0, next_token, [], [])\n",
    "    \n",
    "\n",
    "    # Comprobar que hay respuestas para dicho hashtag\n",
    "    if ('meta' in json_obj) and (int(json_obj['meta']['result_count']) > 0):\n",
    "        for tweet in json_obj['data']:\n",
    "            tweet_dictionary_new = tweet_dictionary.copy()\n",
    "            tweet_dictionary_new['hashtag'] = []\n",
    "            tweet_dictionary_new['referenced_tweets'] = []\n",
    "            user_dictionary_new = user_dictionary.copy()\n",
    "            \n",
    "            tweet_dictionary_new['_id'] = make_objid(str(tweet['id']))\n",
    "            tweet_dictionary_new['author_id'] = make_objid(str(tweet['author_id']))\n",
    "            tweet_dictionary_new['text'] = tweet['text']\n",
    "            tweet_dictionary_new['hashtag'].append(hashtag.lower())\n",
    "\n",
    "            tweet_dictionary_new['created_at'] = tweet['created_at']\n",
    "            tweet_dictionary_new['retweet_count'] = tweet['public_metrics']['retweet_count']\n",
    "            tweet_dictionary_new['reply_count'] = tweet['public_metrics']['reply_count']\n",
    "            tweet_dictionary_new['like_count'] = tweet['public_metrics']['like_count']\n",
    "            tweet_dictionary_new['quote_count'] = tweet['public_metrics']['quote_count']\n",
    "\n",
    "            if ('referenced_tweets' in tweet):\n",
    "                tweet_dictionary_new['referenced_tweets'] = tweet['referenced_tweets']\n",
    "                for rt in tweet_dictionary_new['referenced_tweets']:\n",
    "                    for tweetexpanse in json_obj['includes']['tweets']:\n",
    "                        if (rt['id'] == tweetexpanse['id']):\n",
    "                            rt['author_id'] = make_objid(str(tweetexpanse['author_id']))\n",
    "                            rt['id'] = make_objid(str(tweetexpanse['id']))\n",
    "                            break\n",
    "\n",
    "            unknown = True\n",
    "            for user in user_list:\n",
    "                if (str(user['_id']) == tweet_dictionary_new['author_id']):\n",
    "                    unknown = False\n",
    "                    break\n",
    "\n",
    "            if (unknown == True):\n",
    "                user_dictionary_new['_id'] = make_objid(str(tweet['author_id']))\n",
    "                if ('includes' in json_obj):\n",
    "                    for user in json_obj['includes']['users']:\n",
    "                        if (str(user['id']) == tweet['author_id']):\n",
    "                            user_dictionary_new['description'] = user['description']\n",
    "                            user_dictionary_new['created_at'] = user['created_at']\n",
    "                            user_dictionary_new['verified'] = user['verified']\n",
    "                            user_dictionary_new['followers_count'] = int(user['public_metrics']['followers_count'])\n",
    "                            user_dictionary_new['following_count'] = int(user['public_metrics']['following_count'])\n",
    "                            break\n",
    "                #aqui otro manejo de errores\n",
    "                else:\n",
    "                    print ('otro error')\n",
    "                user_list.append(user_dictionary_new)\n",
    "\n",
    "            tweet_list.append(tweet_dictionary_new)\n",
    "\n",
    "        if ('next_token' in json_obj['meta']):\n",
    "            total = (int(json_obj['meta']['result_count']), json_obj['meta']['next_token'], tweet_list, user_list)\n",
    "\n",
    "        else:\n",
    "            total = (int(json_obj['meta']['result_count']), '', tweet_list, user_list)\n",
    "\n",
    "        print(\"     N'umero de peticiones enviadas: \" + str(PETITIONS_LIMIT))\n",
    "        print(\"     N'umero de peticiones recibidas: \" + str(json_obj['meta']['result_count']))\n",
    "        print(\"     \" + str(total[1]))\n",
    "        return total\n",
    "    # Caso en el que la respuesta es un error y hay que manejarlo\n",
    "    else:\n",
    "        strerror = '    '\n",
    "        #print(\"Error en la petición: \")\n",
    "        strerror = strerror + str(params)\n",
    "        #print(entrada.split(' -H')[0])\n",
    "        strerror = strerror + \"Error en la petición: \"\n",
    "        # si el error es por cuestión de peticiones esperar para hacer la siguiente peticion\n",
    "        if ('title' in json_obj):\n",
    "            #print(\"  Título del error: \" + str(json_obj['title']))\n",
    "            strerror = strerror + \"  Título del error: \" + str(json_obj['title'])\n",
    "            if ('status' in json_obj):\n",
    "                strerror = strerror + \" Código de error: \" + str(json_obj['status'])\n",
    "                #print(\"  Código de error: \" + str(json_obj['status']))\n",
    "            if ('detail' in json_obj):\n",
    "                strerror = strerror + \"  Descripción del error: \" + str(json_obj['detail'])\n",
    "                #print(\"  Descripción del error: \" + str(json_obj['detail']))\n",
    "                \n",
    "        errorlog.write(strerror + \" \" + dt_string + '\\n')\n",
    "        total = (0, next_token, [], [])\n",
    "    return total\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Hashtag: nombre del hashtag que se va a buscar\n",
    "# start: fecha de inicio\n",
    "# end: fecha de respuesta\n",
    "# number: n'umero de tweets que queremos obtener\n",
    "# bearer: bearer id\n",
    "# return devuelve dos diccionarios (users-tweet, tweet-tweet_items)\n",
    "def TweetList(hashtag, start, end, bearer, token):\n",
    "    global tiempo\n",
    "    global TIMER\n",
    "    global TIMER_LOG\n",
    "    global tweet_count\n",
    "    global hashtag_ini_log\n",
    "    global hashtag_last_log\n",
    "    global start_log_timer\n",
    "    \n",
    "\n",
    "    #aqui deberia de hacer dos variables de incio y fin de log para saber con cual hashtag empiezo y termino y con cuantos valores totales de cada uno.QUITAR TWEETLIST\n",
    "    user_list = []\n",
    "    tweet_list = []\n",
    "    total = 0\n",
    "    aux = 0\n",
    "    startTime = 0\n",
    "    endTime = 0\n",
    "    response = (0, token, [], [])\n",
    "\n",
    "    startTime = time.time()\n",
    "\n",
    "    response =  PetitionsLessEqualPETITIONS_LIMIT(hashtag, start, end, bearer, response[1])\n",
    "\n",
    "    user_list.extend(response[3])\n",
    "    #inserci'on de tweets nuevos a la lista de tweets\n",
    "    tweet_list.extend(response[2])\n",
    "    total = response[0]\n",
    "    tweet_count += response[0]\n",
    "    #tweet_list.extend(total[2])\n",
    "\n",
    "    endTime = time.time()\n",
    "\n",
    "    aux = round(math.floor(endTime - startTime))\n",
    "    if (aux < TIMER):\n",
    "        number = TIMER - aux\n",
    "        time.sleep(number)\n",
    "        print('     sleep number: ' + str(number) + ', aux: ' + str(aux), flush=True)\n",
    "        tiempo -= TIMER\n",
    "    else:\n",
    "        tiempo -= aux\n",
    "        print('     aux: ' + str(aux), flush=True)\n",
    "    \n",
    "    if (tiempo <= 0):\n",
    "        #aqui se imprime en el log los hashtags que se han escrito y c'uantos valores se han obtenido de estos\n",
    "        tiempo = TIMER_LOG\n",
    "        # datetime object containing current date and time\n",
    "        now = datetime.datetime.now()\n",
    "        # dd/mm/YY H:M:S\n",
    "        dt_string = now.strftime(\"%H:%M:%S\")\n",
    "        hashtag_last_log = hashtag\n",
    "        log.write(hashtag_ini_log + ' ' + start_log_timer + ' ' + hashtag + ' ' + start + ' ' + dt_string + '\\n')\n",
    "        start_log_timer = dt_string\n",
    "        tweet_count = 0\n",
    "        hashtag_ini_log = hashtag_last_log\n",
    "    \n",
    "    print (\"    Tweets totales: \" + str(total) + '\\n')\n",
    "\n",
    "    return (total, response[1], tweet_list, user_list)\n",
    "\n",
    "\n",
    "def GetTweets(start_date, end_date):\n",
    "\n",
    "\n",
    "    global tiempo\n",
    "    global TIMER\n",
    "    global TIMER_LOG\n",
    "    global tweet_count\n",
    "    global hashtags\n",
    "\n",
    "    aux = end_date.split('-')\n",
    "    last_date = date(int(aux[2]), int(aux[1]), int(aux[0]))\n",
    "    last_date = last_date.strftime(\"%d/%m/%Y\")\n",
    "\n",
    "    f =  open(\"./hashtags.txt\", \"r\")\n",
    "    hashtags = f.readlines()\n",
    "    f.close()\n",
    "    \n",
    "    if os.path.exists(\"./lasttoken.txt\") and os.path.getsize(\"./lasttoken.txt\") > 0:\n",
    "        f =  open(\"./lasttoken.txt\", \"r\")\n",
    "        while True:\n",
    "            # read line\n",
    "            try:\n",
    "                hashtag = f.readline()\n",
    "                if (hashtag == \"\") :\n",
    "                    break\n",
    "            except:\n",
    "                # datetime object containing current date and time\n",
    "                now = datetime.datetime.now()\n",
    "                # dd/mm/YY H:M:S\n",
    "                dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "                errorlog.write(\"Fallo al leer el fichero hashtags.txt \" + dt_string + \"\\n\")\n",
    "\n",
    "            hashtag = hashtag.rstrip('\\n')\n",
    "            hashtag = hashtag.split(' ')\n",
    "            node_aux = node.copy()\n",
    "            node_aux['hashtag'] = hashtag[0]\n",
    "            node_aux['next_token'] = hashtag[1]\n",
    "            node_aux['current_date'] = hashtag[2]\n",
    "            node_aux[\"next_date\"] = hashtag[3]  \n",
    "            hashtagsList.append(node_aux)\n",
    "        f.close()\n",
    "\n",
    "        fd=open(\"./lasttoken.txt\",\"r\")\n",
    "        d=fd.read()\n",
    "        fd.close()\n",
    "        m=d.split(\"\\n\")\n",
    "        s=\"\\n\".join(m[:-1])\n",
    "\n",
    "        fd=open(\"./lasttoken.txt\",\"w+\")\n",
    "        for i in range(len(s)):\n",
    "            fd.write(s[i])\n",
    "        fd.close()\n",
    "        \n",
    "    else:\n",
    "        #####Uso de Hashtag\n",
    "        f =  open(\"./hashtags.txt\", \"r\")\n",
    "        d =  open(\"./lasttoken.txt\", \"w+\")\n",
    "        \n",
    "        writeable = ''\n",
    "        hashtag = None\n",
    "        resultado = (0, '', [], [])\n",
    "        aux = start_date.split('-')\n",
    "        dat = date(int(aux[2]), int(aux[1]), int(aux[0]))\n",
    "        first_day = dat\n",
    "        dat += datetime.timedelta(days=1)\n",
    "        next_day = dat\n",
    "        str_first_day = first_day.strftime(\"%d/%m/%Y\")\n",
    "        str_next_day = next_day.strftime(\"%d/%m/%Y\")\n",
    "        while True:\n",
    "            # read line\n",
    "            try:\n",
    "                hashtag = f.readline()\n",
    "                if (hashtag == \"\") :\n",
    "                    break\n",
    "            except:\n",
    "                # datetime object containing current date and time\n",
    "                now = datetime.datetime.now()\n",
    "                # dd/mm/YY H:M:S\n",
    "                dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "                errorlog.write(\"    Fallo al leer el fichero hashtags.txt \" + dt_string + \"\\n\")\n",
    "            \n",
    "            hashtag = hashtag.rstrip('\\n')\n",
    "            hashtag = hashtag.replace('#', '')\n",
    "            \n",
    "            node_aux = node.copy()\n",
    "            node_aux[\"hashtag\"] = hashtag\n",
    "            writeable = hashtag\n",
    "\n",
    "            writeable += ' ' + node_aux['next_token']\n",
    "\n",
    "            node_aux[\"current_date\"] = str_first_day   \n",
    "            writeable += ' ' + str_first_day \n",
    "\n",
    "            node_aux[\"next_date\"] = str_next_day \n",
    "            writeable += ' ' + str_next_day + '\\n'   \n",
    "\n",
    "            hashtagsList.append(node_aux)\n",
    "            d.write(writeable)\n",
    "            # check if line is not empty\n",
    "        d.close()\n",
    "        f.close()\n",
    "\n",
    "        \n",
    "\n",
    "    for h in hashtagsList:\n",
    "        print(str(h))\n",
    "        \n",
    "\n",
    "\n",
    "    if (len(hashtagsList) != 0):\n",
    "        hashtag_ini_log = hashtagsList[0]\n",
    "        # dd/mm/YY H:M:S\n",
    "        now = datetime.datetime.now()\n",
    "        dt_string = now.strftime(\"%H:%M:%S\")\n",
    "        start_log_timer = dt_string\n",
    "        \n",
    "    else:\n",
    "        # datetime object containing current date and time\n",
    "        now = datetime.datetime.now()\n",
    "        # dd/mm/YY H:M:S\n",
    "        dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "        errorlog.write(\"    Error: lista de hashtags vacía\" + \" dt_string\\n\")\n",
    "\n",
    "    count = 0\n",
    "    temporalTokens = ''\n",
    "    tweet_list = []\n",
    "    user_list = []\n",
    "    start = 0\n",
    "    end = 0\n",
    "    \n",
    "    last = False\n",
    "    while last == False:\n",
    "        for l in hashtagsList:\n",
    "            start = 0\n",
    "            end = 0\n",
    "            aux = 0\n",
    "            #bucle de obtencion de tweets para un dia concreto\n",
    "            while (l[\"next_token\"] != ''):\n",
    "                if l[\"next_token\"] == '-1':\n",
    "                    print('Inicio hashtag: ' + l['hashtag'] + ' día: ' + l['current_date'])\n",
    "                    resultado = TweetList(l[\"hashtag\"], l[\"current_date\"], l[\"next_date\"], Bearer, '')\n",
    "                else:\n",
    "                    resultado = TweetList(l[\"hashtag\"], l[\"current_date\"], l[\"next_date\"], Bearer, l[\"next_token\"])\n",
    "                start = time.time()\n",
    "                tweet_list.extend(resultado[2])\n",
    "                user_list.extend(resultado[3])\n",
    "                l[\"next_token\"] = resultado[1]\n",
    "\n",
    "                end = time.time()\n",
    "                tiempo -= round(math.floor(start - end))\n",
    "                if (tiempo <= 0):\n",
    "                    # datetime object containing current date and time\n",
    "                    tiempo = TIMER_LOG\n",
    "                    now = datetime.datetime.now()\n",
    "                    # dd/mm/YY H:M:S\n",
    "                    dt_string = now.strftime(\"%H:%M:%S\")\n",
    "                    log.write(hashtag_ini_log + ' ' + start_log_timer + ' ' + l['hashtag'] + ' ' + l['current_date'] + ' ' + dt_string + '\\n')\n",
    "                    hashtag_ini_log = l['hashtag']\n",
    "\n",
    "            start = time.time()\n",
    "            # Substring de % para insertar en la base de datos\n",
    "            count = 0\n",
    "            count = round(math.ceil(len(tweet_list) * PERCENT))\n",
    "            #primero comprobamos si no hemos insertado inicialmente en la base de datos tantos tweets como pone en count\n",
    "            search = list(mytweets.find( {\"hashtag\" : l[\"hashtag\"]} ))\n",
    "            count -= len(search)\n",
    "            if count > 0:\n",
    "                #buscamos los tweets que estan en la base  de datos y los borramos de nuestra lista de tweets\n",
    "                for t in search:\n",
    "                    if t in tweet_list:\n",
    "                        tweet_list.remove(t)\n",
    "                # caso en el que count es menor de lo que podemos insertar\n",
    "                if count < len(tweet_list):\n",
    "                    tweet_list = tweet_list[0:(count - 1)]\n",
    "\n",
    "                aux_list = []\n",
    "                # Ahora buscamos los users relacionados con los tweets de la lista\n",
    "                for u in user_list:\n",
    "                    for t in tweet_list:\n",
    "                        if str(t['author_id']) == str(u['_id']):\n",
    "                            aux_list.append(u)\n",
    "                            break\n",
    "                #Aqui se inserta en la base de datos\n",
    "                #alomejor aqui ponemos la cantidad de valores que se insertan en la lista, para los casos en los que los tweets coinciden con otros tweets\n",
    "                print(\"Total tweets insertados: \" + str(len(tweet_list)) + \", Total usuarios insertados: \" + str(len(aux_list)))\n",
    "                MongoExecute(tweet_list, aux_list)\n",
    "            \n",
    "            #ahora cambiamos de d'ia y quitamos la lista\n",
    "            tweet_list = []\n",
    "            user_list = []\n",
    "            print('     Cambio de día ' + l['current_date'] + '\\n')\n",
    "            l['current_date'] = l['next_date']\n",
    "            dat = datetime.datetime.strptime(l['current_date'], \"%d/%m/%Y\")\n",
    "            dat += datetime.timedelta(days=1)\n",
    "            l['next_date'] = dat.strftime(\"%d/%m/%Y\").split(' ')[0]\n",
    "            l['next_token'] = '-1'\n",
    "            #borramos la 'ultima linea de fichero de lasttoken\n",
    "            if os.path.exists(\"./lasttoken.txt\") and os.path.getsize(\"./lasttoken.txt\") > 0:\n",
    "                d = ''\n",
    "                f =  open(\"./lasttoken.txt\", \"r\")\n",
    "                #remove last line from a text line in python\n",
    "                d = f.readlines()\n",
    "                f.close()\n",
    "                \n",
    "                for i in range(len(d)):\n",
    "                    if d[i].split()[0] == l['hashtag']:\n",
    "                        d[i] = l['hashtag'] + ' ' + l['next_token'] + ' ' + l['current_date'] + ' ' + l[\"next_date\"] + '\\n'\n",
    "\n",
    "                f = open(\"./lasttoken.txt\",\"w+\")\n",
    "                f.writelines(d)\n",
    "                f.close()\n",
    "\n",
    "            if (l[\"current_date\"] == last_date):\n",
    "                last = True\n",
    "\n",
    "            end = time.time()\n",
    "                \n",
    "            tiempo -= round(math.floor(start - end))\n",
    "            if (tiempo <= 0):\n",
    "                # datetime object containing current date and time\n",
    "                tiempo = TIMER_LOG\n",
    "                now = datetime.datetime.now()\n",
    "                # dd/mm/YY H:M:S\n",
    "                dt_string = now.strftime(\"%H:%M:%S\")\n",
    "                log.write(hashtag_ini_log + ' ' + start_log_timer + ' ' + l['hashtag'] + ' ' + l['current_date'] + ' ' + dt_string + '\\n')\n",
    "                hashtag_ini_log = l['hashtag']\n",
    "\n",
    "            print(\"Fin Hashtag: \" + str(l['hashtag']) + \"\\n\\n\")        \n",
    "\n",
    "    log.close()\n",
    "    errorlog.close()\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "source": [
    "## Main code"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Si ya se ha buscado anteriormente entonces deberías de comprobar si la búsqueda y lo que se pide de base (n_teets no se que es igual al número de tweets del hashtag)\n",
    "\n",
    "myclient = pymongo.MongoClient('localhost', 27017)\n",
    "mydb = myclient[\"mydatabase\"]\n",
    "myusers = mydb[\"users\"]\n",
    "mytweets = mydb[\"tweets\"]\n",
    "\n",
    "f = open(\"./accountV2.txt\", \"r\")\n",
    "Bearer = f.readline().rstrip('\\n')\n",
    "f.close()\n",
    "headers = create_headers(Bearer)\n",
    "\n",
    "fileObj = Path(\"./log\" + d1 + \".txt\")\n",
    "if (fileObj.is_file()):\n",
    "    os.remove(\"./log\" + d1 + \".txt\")\n",
    "\n",
    "fileObj = Path(\"./errorlog\" + d1 + \".txt\")\n",
    "if (fileObj.is_file()):\n",
    "    os.remove(\"./errorlog\" + d1 + \".txt\")\n",
    "\n",
    "log = open(\"./log\" + d1 + \".txt\", \"a\")\n",
    "log.write(\"Primer log\\n\")\n",
    "#Crear ficheros de log\n",
    "errorlog = open(\"./errorlog\" + d1 + \".txt\", \"a\")\n",
    "\n",
    "\n",
    "GetTweets(\"18-03-2021\", \"04-05-2021\")\n"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'hashtag': 'DemocraciaOFascismo4M', 'current_date': '18/03/2021', 'next_date': '19/03/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'SosoSerioYFormal', 'current_date': '18/03/2021', 'next_date': '19/03/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'ColetasRata', 'current_date': '18/03/2021', 'next_date': '19/03/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'RataSinColeta', 'current_date': '18/03/2021', 'next_date': '19/03/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'PodemosAtacaAPodemos', 'current_date': '18/03/2021', 'next_date': '19/03/2021', 'next_token': '-1'}\n",
      "{'hashtag': '4MConPabloIglesias', 'current_date': '18/03/2021', 'next_date': '19/03/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'semarlaskalatragedia', 'current_date': '18/03/2021', 'next_date': '19/03/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'IreneMonteroDimision', 'current_date': '18/03/2021', 'next_date': '19/03/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'TeamVox', 'current_date': '18/03/2021', 'next_date': '19/03/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'SoloQuedaVox', 'current_date': '18/03/2021', 'next_date': '19/03/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'VoxLivesMatter', 'current_date': '18/03/2021', 'next_date': '19/03/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'Elecciones4M', 'current_date': '18/03/2021', 'next_date': '19/03/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'NazisYCorruptos', 'current_date': '18/03/2021', 'next_date': '19/03/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'Pucherazo', 'current_date': '18/03/2021', 'next_date': '19/03/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'RompeTuVoto', 'current_date': '18/03/2021', 'next_date': '19/03/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'IlegalizacionDeVoxYa', 'current_date': '18/03/2021', 'next_date': '19/03/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'DebateSER', 'current_date': '18/03/2021', 'next_date': '19/03/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'VotaLIBERTAD', 'current_date': '18/03/2021', 'next_date': '19/03/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'DebateTelemadrid', 'current_date': '18/03/2021', 'next_date': '19/03/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'eleccionesMadrid2021', 'current_date': '18/03/2021', 'next_date': '19/03/2021', 'next_token': '-1'}\n",
      "Inicio hashtag: DemocraciaOFascismo4M día: 18/03/2021\n",
      "     sleep number: 4.0, aux: 0\n",
      "    Tweets totales: 0\n",
      "\n",
      "     Cambio de día 18/03/2021\n",
      "\n",
      "Fin Hashtag: DemocraciaOFascismo4M\n",
      "\n",
      "\n",
      "Inicio hashtag: SosoSerioYFormal día: 18/03/2021\n",
      "     sleep number: 4.0, aux: 0\n",
      "    Tweets totales: 0\n",
      "\n",
      "     Cambio de día 18/03/2021\n",
      "\n",
      "Fin Hashtag: SosoSerioYFormal\n",
      "\n",
      "\n",
      "Inicio hashtag: ColetasRata día: 18/03/2021\n",
      "     N'umero de peticiones enviadas: 500\n",
      "     N'umero de peticiones recibidas: 158\n",
      "     \n",
      "     sleep number: 3.0, aux: 1\n",
      "    Tweets totales: 158\n",
      "\n",
      "Total tweets insertados: 23, Total usuarios insertados: 28\n",
      "{'_id': ObjectId('000001372867595653812227'), 'author_id': ObjectId('000000000000000490687887'), 'created_at': '2021-03-19T11:08:36.000Z', 'text': 'RT @munozmalpartida: @PabloIglesias Es una irresponsabilidad mayúscula que siendo candidato continúes con el mismo lenguaje guerracivilista…', 'hashtag': ['coletasrata'], 'referenced_tweets': [{'type': 'retweeted', 'id': ObjectId('000001372864470779854849'), 'author_id': ObjectId('000001069713567824388096')}], 'retweet_count': 3, 'reply_count': 0, 'like_count': 0, 'quote_count': 0}\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'hastag' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBulkWriteError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-ae05a85e54a9>\u001b[0m in \u001b[0;36mMongoExecute\u001b[1;34m(tweet_list, user_list)\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmytweets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert_many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mordered\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmyusers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert_many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mordered\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\joseg\\OneDrive\\Documentos\\TFG-Bots-OSN\\TFGBotsV2\\lib\\site-packages\\pymongo\\collection.py\u001b[0m in \u001b[0;36minsert_many\u001b[1;34m(self, documents, ordered, bypass_document_validation, session)\u001b[0m\n\u001b[0;32m    760\u001b[0m         \u001b[0mblk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdoc\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 761\u001b[1;33m         \u001b[0mblk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrite_concern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    762\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mInsertManyResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minserted_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrite_concern\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macknowledged\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\joseg\\OneDrive\\Documentos\\TFG-Bots-OSN\\TFGBotsV2\\lib\\site-packages\\pymongo\\bulk.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, write_concern, session)\u001b[0m\n\u001b[0;32m    527\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 528\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrite_concern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    529\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\joseg\\OneDrive\\Documentos\\TFG-Bots-OSN\\TFGBotsV2\\lib\\site-packages\\pymongo\\bulk.py\u001b[0m in \u001b[0;36mexecute_command\u001b[1;34m(self, generator, write_concern, session)\u001b[0m\n\u001b[0;32m    362\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfull_result\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"writeErrors\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfull_result\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"writeConcernErrors\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m             \u001b[0m_raise_bulk_write_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfull_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\joseg\\OneDrive\\Documentos\\TFG-Bots-OSN\\TFGBotsV2\\lib\\site-packages\\pymongo\\bulk.py\u001b[0m in \u001b[0;36m_raise_bulk_write_error\u001b[1;34m(full_result)\u001b[0m\n\u001b[0;32m    139\u001b[0m             key=lambda error: error[\"index\"])\n\u001b[1;32m--> 140\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mBulkWriteError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mBulkWriteError\u001b[0m: batch op errors occurred, full error: {'writeErrors': [{'index': 0, 'code': 11000, 'keyPattern': {'_id': 1}, 'keyValue': {'_id': ObjectId('000001372867595653812227')}, 'errmsg': \"E11000 duplicate key error collection: mydatabase.tweets index: _id_ dup key: { _id: ObjectId('000001372867595653812227') }\", 'op': {'_id': ObjectId('000001372867595653812227'), 'author_id': ObjectId('000000000000000490687887'), 'created_at': '2021-03-19T11:08:36.000Z', 'text': 'RT @munozmalpartida: @PabloIglesias Es una irresponsabilidad mayúscula que siendo candidato continúes con el mismo lenguaje guerracivilista…', 'hashtag': ['coletasrata'], 'referenced_tweets': [{'type': 'retweeted', 'id': ObjectId('000001372864470779854849'), 'author_id': ObjectId('000001069713567824388096')}], 'retweet_count': 3, 'reply_count': 0, 'like_count': 0, 'quote_count': 0}}, {'index': 1, 'code': 11000, 'keyPattern': {'_id': 1}, 'keyValue': {'_id': ObjectId('000001372866932060327941')}, 'errmsg': \"E11000 duplicate key error collection: mydatabase.tweets index: _id_ dup key: { _id: ObjectId('000001372866932060327941') }\", 'op': {'_id': ObjectId('000001372866932060327941'), 'author_id': ObjectId('000001369971348626415617'), 'created_at': '2021-03-19T11:05:57.000Z', 'text': '@PODEMOS @PabloIglesias @JesusCintora Madrid será la tumba del coletas.\\n#ColetasRata\\n#IglesiasCierraAlSalir', 'hashtag': ['coletasrata'], 'referenced_tweets': [{'type': 'replied_to', 'id': ObjectId('000001372865684422619139'), 'author_id': ObjectId('000000000000002288138575')}], 'retweet_count': 0, 'reply_count': 0, 'like_count': 1, 'quote_count': 0}}, {'index': 2, 'code': 11000, 'keyPattern': {'_id': 1}, 'keyValue': {'_id': ObjectId('000001372864470779854849')}, 'errmsg': \"E11000 duplicate key error collection: mydatabase.tweets index: _id_ dup key: { _id: ObjectId('000001372864470779854849') }\", 'op': {'_id': ObjectId('000001372864470779854849'), 'author_id': ObjectId('000001069713567824388096'), 'created_at': '2021-03-19T10:56:11.000Z', 'text': '@PabloIglesias Es una irresponsabilidad mayúscula que siendo candidato continúes con el mismo lenguaje guerracivilista y el discurso del odio que siempre te ha caracterizado \\n\\nEn Madrid no te queremos \\n\\nEl comunismo y el foro de Sao Paulo no pasarán. Te quedarás con las ganas \\n\\n#COLETASRATA', 'hashtag': ['coletasrata'], 'referenced_tweets': [{'type': 'replied_to', 'id': ObjectId('000001372641099257421830'), 'author_id': ObjectId('000000000000000158342368')}], 'retweet_count': 3, 'reply_count': 0, 'like_count': 19, 'quote_count': 0}}, {'index': 3, 'code': 11000, 'keyPattern': {'_id': 1}, 'keyValue': {'_id': ObjectId('000001372862874855612417')}, 'errmsg': \"E11000 duplicate key error collection: mydatabase.tweets index: _id_ dup key: { _id: ObjectId('000001372862874855612417') }\", 'op': {'_id': ObjectId('000001372862874855612417'), 'author_id': ObjectId('000000000000002306121657'), 'created_at': '2021-03-19T10:49:50.000Z', 'text': '@PabloEchenique Como os jode no poder manipular a la gente, ya sea en los colegios, universidades, o por la tele. Sois escoria. Menos mal que los padres pueden elegir que se les dice y que no a sus hijos en Murcia. Ojalá llegue a todo el país. \\n#ColetasRata', 'hashtag': ['coletasrata'], 'referenced_tweets': [{'type': 'replied_to', 'id': ObjectId('000001372834810960437248'), 'author_id': ObjectId('000000000000000025555639')}], 'retweet_count': 0, 'reply_count': 0, 'like_count': 0, 'quote_count': 0}}, {'index': 4, 'code': 11000, 'keyPattern': {'_id': 1}, 'keyValue': {'_id': ObjectId('000001372862131020959744')}, 'errmsg': \"E11000 duplicate key error collection: mydatabase.tweets index: _id_ dup key: { _id: ObjectId('000001372862131020959744') }\", 'op': {'_id': ObjectId('000001372862131020959744'), 'author_id': ObjectId('000000000000002306121657'), 'created_at': '2021-03-19T10:46:53.000Z', 'text': '@menos_drama Es que las posturas de esta pájara para llegar donde ha llegado acaban pasando factura. #ColetasRata', 'hashtag': ['coletasrata'], 'referenced_tweets': [{'type': 'replied_to', 'id': ObjectId('000001372844640387366915'), 'author_id': ObjectId('000000965498082245971968')}], 'retweet_count': 0, 'reply_count': 0, 'like_count': 0, 'quote_count': 0}}, {'index': 5, 'code': 11000, 'keyPattern': {'_id': 1}, 'keyValue': {'_id': ObjectId('000001372856346224291840')}, 'errmsg': \"E11000 duplicate key error collection: mydatabase.tweets index: _id_ dup key: { _id: ObjectId('000001372856346224291840') }\", 'op': {'_id': ObjectId('000001372856346224291840'), 'author_id': ObjectId('000000000000000485010765'), 'created_at': '2021-03-19T10:23:54.000Z', 'text': '@laSextaTV #COLETASRATA', 'hashtag': ['coletasrata'], 'referenced_tweets': [{'type': 'replied_to', 'id': ObjectId('000001372840272296607744'), 'author_id': ObjectId('000000000000000022954354')}], 'retweet_count': 0, 'reply_count': 0, 'like_count': 0, 'quote_count': 0}}, {'index': 6, 'code': 11000, 'keyPattern': {'_id': 1}, 'keyValue': {'_id': ObjectId('000001372850912314720256')}, 'errmsg': \"E11000 duplicate key error collection: mydatabase.tweets index: _id_ dup key: { _id: ObjectId('000001372850912314720256') }\", 'op': {'_id': ObjectId('000001372850912314720256'), 'author_id': ObjectId('000001362410749042307076'), 'created_at': '2021-03-19T10:02:18.000Z', 'text': 'El regalo de La marquesa a la #ColetasRata \\n#diadelpadre https://t.co/kSAUUWJUar', 'hashtag': ['coletasrata'], 'referenced_tweets': [], 'retweet_count': 0, 'reply_count': 0, 'like_count': 2, 'quote_count': 0}}, {'index': 7, 'code': 11000, 'keyPattern': {'_id': 1}, 'keyValue': {'_id': ObjectId('000001372845268790562818')}, 'errmsg': \"E11000 duplicate key error collection: mydatabase.tweets index: _id_ dup key: { _id: ObjectId('000001372845268790562818') }\", 'op': {'_id': ObjectId('000001372845268790562818'), 'author_id': ObjectId('000000000000000238544952'), 'created_at': '2021-03-19T09:39:52.000Z', 'text': 'RT @SrPigdemont: En Madrid @PabloIglesias merece tantos diputados como visitas realizó a las Residencias de Ancianos mientras fue el respon…', 'hashtag': ['coletasrata'], 'referenced_tweets': [{'type': 'retweeted', 'id': ObjectId('000001371760190287192065'), 'author_id': ObjectId('000001364329203328569346')}], 'retweet_count': 1076, 'reply_count': 0, 'like_count': 0, 'quote_count': 0}}, {'index': 8, 'code': 11000, 'keyPattern': {'_id': 1}, 'keyValue': {'_id': ObjectId('000001372839732544147458')}, 'errmsg': \"E11000 duplicate key error collection: mydatabase.tweets index: _id_ dup key: { _id: ObjectId('000001372839732544147458') }\", 'op': {'_id': ObjectId('000001372839732544147458'), 'author_id': ObjectId('000000000000000187476630'), 'created_at': '2021-03-19T09:17:53.000Z', 'text': \"Sóc a recuperació. Hi ha un #ColetasRata de les antigues colònies intentant lligar-se a una d'aquestes de la #BarcelonaWorkation, ella amb castelladre trencat i tots els tòpics del colauisme sociata: la bici, el vòlei platja, la Barceloneta, el viure a Sant Antoni... MORIU-VOS.\", 'hashtag': ['coletasrata'], 'referenced_tweets': [], 'retweet_count': 0, 'reply_count': 1, 'like_count': 4, 'quote_count': 0}}, {'index': 9, 'code': 11000, 'keyPattern': {'_id': 1}, 'keyValue': {'_id': ObjectId('000001372831271055921153')}, 'errmsg': \"E11000 duplicate key error collection: mydatabase.tweets index: _id_ dup key: { _id: ObjectId('000001372831271055921153') }\", 'op': {'_id': ObjectId('000001372831271055921153'), 'author_id': ObjectId('000001112299155882426368'), 'created_at': '2021-03-19T08:44:15.000Z', 'text': '@eduardoinda Tranquilos que ya le echará la culpa - si es menester- al empedrado.\\n#ColetasRata', 'hashtag': ['coletasrata'], 'referenced_tweets': [{'type': 'replied_to', 'id': ObjectId('000001372824010002722816'), 'author_id': ObjectId('000000698104968105095170')}], 'retweet_count': 0, 'reply_count': 0, 'like_count': 0, 'quote_count': 0}}, {'index': 10, 'code': 11000, 'keyPattern': {'_id': 1}, 'keyValue': {'_id': ObjectId('000001372830694884380672')}, 'errmsg': \"E11000 duplicate key error collection: mydatabase.tweets index: _id_ dup key: { _id: ObjectId('000001372830694884380672') }\", 'op': {'_id': ObjectId('000001372830694884380672'), 'author_id': ObjectId('000000000000000525811784'), 'created_at': '2021-03-19T08:41:58.000Z', 'text': '@PabloIglesias No pasarán 🤣🤣🤣🤣\\nHace 80 años que pasaron subcampeón\\n#ColetasRata', 'hashtag': ['coletasrata'], 'referenced_tweets': [{'type': 'replied_to', 'id': ObjectId('000001372641099257421830'), 'author_id': ObjectId('000000000000000158342368')}], 'retweet_count': 0, 'reply_count': 0, 'like_count': 0, 'quote_count': 0}}, {'index': 11, 'code': 11000, 'keyPattern': {'_id': 1}, 'keyValue': {'_id': ObjectId('000001372829549067649032')}, 'errmsg': \"E11000 duplicate key error collection: mydatabase.tweets index: _id_ dup key: { _id: ObjectId('000001372829549067649032') }\", 'op': {'_id': ObjectId('000001372829549067649032'), 'author_id': ObjectId('000001154775506375643137'), 'created_at': '2021-03-19T08:37:25.000Z', 'text': '@PabloIglesias Ayuso for PRESIDENT! #ColetasRata', 'hashtag': ['coletasrata'], 'referenced_tweets': [{'type': 'replied_to', 'id': ObjectId('000001372810793578864642'), 'author_id': ObjectId('000000000000000158342368')}], 'retweet_count': 1, 'reply_count': 1, 'like_count': 1, 'quote_count': 0}}, {'index': 12, 'code': 11000, 'keyPattern': {'_id': 1}, 'keyValue': {'_id': ObjectId('000001372827699287298053')}, 'errmsg': \"E11000 duplicate key error collection: mydatabase.tweets index: _id_ dup key: { _id: ObjectId('000001372827699287298053') }\", 'op': {'_id': ObjectId('000001372827699287298053'), 'author_id': ObjectId('000001120815873919520768'), 'created_at': '2021-03-19T08:30:04.000Z', 'text': '@El_Intermedio El sueño húmedo de Iglesias.\\nVacuna rusa para #ColetasRata ya!', 'hashtag': ['coletasrata'], 'referenced_tweets': [{'type': 'replied_to', 'id': ObjectId('000001372825688126988289'), 'author_id': ObjectId('000000000000000016080129')}], 'retweet_count': 0, 'reply_count': 0, 'like_count': 0, 'quote_count': 0}}, {'index': 13, 'code': 11000, 'keyPattern': {'_id': 1}, 'keyValue': {'_id': ObjectId('000001372823984518074370')}, 'errmsg': \"E11000 duplicate key error collection: mydatabase.tweets index: _id_ dup key: { _id: ObjectId('000001372823984518074370') }\", 'op': {'_id': ObjectId('000001372823984518074370'), 'author_id': ObjectId('000001307875497943150593'), 'created_at': '2021-03-19T08:15:18.000Z', 'text': 'RT @david_segura: En Madrid #ColetasRata https://t.co/pvAOpWiNmd', 'hashtag': ['coletasrata'], 'referenced_tweets': [{'type': 'retweeted', 'id': ObjectId('000001372601660959252484'), 'author_id': ObjectId('000000000000000065602229')}], 'retweet_count': 18, 'reply_count': 0, 'like_count': 0, 'quote_count': 0}}, {'index': 14, 'code': 11000, 'keyPattern': {'_id': 1}, 'keyValue': {'_id': ObjectId('000001372822130283401216')}, 'errmsg': \"E11000 duplicate key error collection: mydatabase.tweets index: _id_ dup key: { _id: ObjectId('000001372822130283401216') }\", 'op': {'_id': ObjectId('000001372822130283401216'), 'author_id': ObjectId('000000968189330970771456'), 'created_at': '2021-03-19T08:07:56.000Z', 'text': 'Esto es un sin vivir 😬😬 quien saldrá... \\nLos candidatos son:\\n- #ColetasRata \\n- #MoñoRata\\n- #Garrapata\\n- #ElChepas \\n- #MachoAlfa \\n- #VuelveElHombre \\n- #IglesiasCierraAlSalir https://t.co/JViLOUzlN6', 'hashtag': ['coletasrata'], 'referenced_tweets': [], 'retweet_count': 0, 'reply_count': 0, 'like_count': 1, 'quote_count': 0}}, {'index': 15, 'code': 11000, 'keyPattern': {'_id': 1}, 'keyValue': {'_id': ObjectId('000001372821392920608772')}, 'errmsg': \"E11000 duplicate key error collection: mydatabase.tweets index: _id_ dup key: { _id: ObjectId('000001372821392920608772') }\", 'op': {'_id': ObjectId('000001372821392920608772'), 'author_id': ObjectId('000000000000000237765349'), 'created_at': '2021-03-19T08:05:00.000Z', 'text': '@valerynut @Tamara_Falco_ @PODEMOS Es este el hilo para decir #ColetasRata ?', 'hashtag': ['coletasrata'], 'referenced_tweets': [{'type': 'replied_to', 'id': '1372820940711682049'}], 'retweet_count': 0, 'reply_count': 0, 'like_count': 1, 'quote_count': 0}}, {'index': 16, 'code': 11000, 'keyPattern': {'_id': 1}, 'keyValue': {'_id': ObjectId('000001372816657937268736')}, 'errmsg': \"E11000 duplicate key error collection: mydatabase.tweets index: _id_ dup key: { _id: ObjectId('000001372816657937268736') }\", 'op': {'_id': ObjectId('000001372816657937268736'), 'author_id': ObjectId('000000000000001125304440'), 'created_at': '2021-03-19T07:46:11.000Z', 'text': '#ColetasRata ahora es FARRUQUITO https://t.co/1N7eC1uIPX', 'hashtag': ['coletasrata'], 'referenced_tweets': [], 'retweet_count': 0, 'reply_count': 0, 'like_count': 0, 'quote_count': 0}}, {'index': 17, 'code': 11000, 'keyPattern': {'_id': 1}, 'keyValue': {'_id': ObjectId('000001372813882000035842')}, 'errmsg': \"E11000 duplicate key error collection: mydatabase.tweets index: _id_ dup key: { _id: ObjectId('000001372813882000035842') }\", 'op': {'_id': ObjectId('000001372813882000035842'), 'author_id': ObjectId('000000000000000322493132'), 'created_at': '2021-03-19T07:35:09.000Z', 'text': 'RT @david_segura: En Madrid #ColetasRata https://t.co/pvAOpWiNmd', 'hashtag': ['coletasrata'], 'referenced_tweets': [{'type': 'retweeted', 'id': ObjectId('000001372601660959252484'), 'author_id': ObjectId('000000000000000065602229')}], 'retweet_count': 18, 'reply_count': 0, 'like_count': 0, 'quote_count': 0}}, {'index': 18, 'code': 11000, 'keyPattern': {'_id': 1}, 'keyValue': {'_id': ObjectId('000001372813618799054849')}, 'errmsg': \"E11000 duplicate key error collection: mydatabase.tweets index: _id_ dup key: { _id: ObjectId('000001372813618799054849') }\", 'op': {'_id': ObjectId('000001372813618799054849'), 'author_id': ObjectId('000000000000002337603142'), 'created_at': '2021-03-19T07:34:07.000Z', 'text': 'RT @david_segura: En Madrid #ColetasRata https://t.co/pvAOpWiNmd', 'hashtag': ['coletasrata'], 'referenced_tweets': [{'type': 'retweeted', 'id': ObjectId('000001372601660959252484'), 'author_id': ObjectId('000000000000000065602229')}], 'retweet_count': 18, 'reply_count': 0, 'like_count': 0, 'quote_count': 0}}, {'index': 19, 'code': 11000, 'keyPattern': {'_id': 1}, 'keyValue': {'_id': ObjectId('000001372811928725258240')}, 'errmsg': \"E11000 duplicate key error collection: mydatabase.tweets index: _id_ dup key: { _id: ObjectId('000001372811928725258240') }\", 'op': {'_id': ObjectId('000001372811928725258240'), 'author_id': ObjectId('000001322840736413437954'), 'created_at': '2021-03-19T07:27:24.000Z', 'text': '@TabarniaB Pobre #ColetasRata 😂😂😂', 'hashtag': ['coletasrata'], 'referenced_tweets': [{'type': 'replied_to', 'id': ObjectId('000001372788392908386306'), 'author_id': ObjectId('000001364909426952568832')}], 'retweet_count': 0, 'reply_count': 0, 'like_count': 1, 'quote_count': 0}}, {'index': 20, 'code': 11000, 'keyPattern': {'_id': 1}, 'keyValue': {'_id': ObjectId('000001372810645679308804')}, 'errmsg': \"E11000 duplicate key error collection: mydatabase.tweets index: _id_ dup key: { _id: ObjectId('000001372810645679308804') }\", 'op': {'_id': ObjectId('000001372810645679308804'), 'author_id': ObjectId('000000000000002828042222'), 'created_at': '2021-03-19T07:22:18.000Z', 'text': '@Miss_Bennet7 ya quisiera el #ColetasRata tener ese dominio de las caderas https://t.co/HFNZyx4yLP', 'hashtag': ['coletasrata'], 'referenced_tweets': [{'type': 'replied_to', 'id': ObjectId('000001372808347993378817'), 'author_id': ObjectId('000001238153755478102021')}], 'retweet_count': 0, 'reply_count': 1, 'like_count': 1, 'quote_count': 0}}, {'index': 21, 'code': 11000, 'keyPattern': {'_id': 1}, 'keyValue': {'_id': ObjectId('000001372804756209500161')}, 'errmsg': \"E11000 duplicate key error collection: mydatabase.tweets index: _id_ dup key: { _id: ObjectId('000001372804756209500161') }\", 'op': {'_id': ObjectId('000001372804756209500161'), 'author_id': ObjectId('000000000000000437786946'), 'created_at': '2021-03-19T06:58:54.000Z', 'text': 'RT @SrPigdemont: En Madrid @PabloIglesias merece tantos diputados como visitas realizó a las Residencias de Ancianos mientras fue el respon…', 'hashtag': ['coletasrata'], 'referenced_tweets': [{'type': 'retweeted', 'id': ObjectId('000001371760190287192065'), 'author_id': ObjectId('000001364329203328569346')}], 'retweet_count': 1076, 'reply_count': 0, 'like_count': 0, 'quote_count': 0}}, {'index': 22, 'code': 11000, 'keyPattern': {'_id': 1}, 'keyValue': {'_id': ObjectId('000001372793138884964354')}, 'errmsg': \"E11000 duplicate key error collection: mydatabase.tweets index: _id_ dup key: { _id: ObjectId('000001372793138884964354') }\", 'op': {'_id': ObjectId('000001372793138884964354'), 'author_id': ObjectId('000001238527928222261250'), 'created_at': '2021-03-19T06:12:44.000Z', 'text': 'RT @SrPigdemont: En Madrid @PabloIglesias merece tantos diputados como visitas realizó a las Residencias de Ancianos mientras fue el respon…', 'hashtag': ['coletasrata'], 'referenced_tweets': [{'type': 'retweeted', 'id': ObjectId('000001371760190287192065'), 'author_id': ObjectId('000001364329203328569346')}], 'retweet_count': 1076, 'reply_count': 0, 'like_count': 0, 'quote_count': 0}}], 'writeConcernErrors': [], 'nInserted': 0, 'nUpserted': 0, 'nMatched': 0, 'nModified': 0, 'nRemoved': 0, 'upserted': []}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-5ed5472b3f5e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[0mGetTweets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"18-03-2021\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"04-05-2021\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-ae05a85e54a9>\u001b[0m in \u001b[0;36mGetTweets\u001b[1;34m(start_date, end_date)\u001b[0m\n\u001b[0;32m    542\u001b[0m                 \u001b[1;31m#alomejor aqui ponemos la cantidad de valores que se insertan en la lista, para los casos en los que los tweets coinciden con otros tweets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Total tweets insertados: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\", Total usuarios insertados: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maux_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 544\u001b[1;33m                 \u001b[0mMongoExecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maux_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    545\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m             \u001b[1;31m#ahora cambiamos de d'ia y quitamos la lista\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-ae05a85e54a9>\u001b[0m in \u001b[0;36mMongoExecute\u001b[1;34m(tweet_list, user_list)\u001b[0m\n\u001b[0;32m    118\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mhashtag\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'hashtag'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[0mhastag\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtweet\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'hashtag'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m                     \u001b[0mrepetido\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'hastag' is not defined"
     ]
    }
   ]
  }
 ]
}