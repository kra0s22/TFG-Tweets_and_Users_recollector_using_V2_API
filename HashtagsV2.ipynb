{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "pythonjvsc74a57bd079fc3c954d64dbcf3cc8f2394a5e83a280e126f0ab97a2117c3267677291b603",
   "display_name": "Python 3.9.2  ('TFGBotsV2': venv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "79fc3c954d64dbcf3cc8f2394a5e83a280e126f0ab97a2117c3267677291b603"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Imports "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Versi√≥n para tweepy V2\n",
    "from datetime import date\n",
    "import datetime\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "import math\n",
    "import pymongo\n",
    "from bson import ObjectId\n",
    "import numpy as np\n",
    "from datetime import date\n"
   ]
  },
  {
   "source": [
    "## Constant and Variables"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "\n",
    "PETITIONS_PER_TIME_LAPSE = 300\n",
    "TIME_LAPSE = 20*60\n",
    "# Tiempo de espera necesario entre peticiones\n",
    "TIMER = TIME_LAPSE/PETITIONS_PER_TIME_LAPSE\n",
    "# Log cada 2 minutos\n",
    "TIMER_LOG = 2*60\n",
    "\n",
    "#porcentaje de tweets que nos quedamos para cada dia\n",
    "PERCENT = 0.15\n",
    "# m√°ximo de tweets por cada petici√≥n\n",
    "PETITIONS_LIMIT = 500\n",
    "\n",
    "#VARIABLES\n",
    "iniTimerLog = 0\n",
    "finTimerLog = 0\n",
    "tiempo = TIMER_LOG\n",
    "hashtagsList = []\n",
    "hashtags = []\n",
    "entrada = \"\"\n",
    "next_token = None\n",
    "entradaizq = '' \n",
    "entradader = ''\n",
    "total = 0\n",
    "startDate = ''\n",
    "endDate = ''\n",
    "inicio = 0\n",
    "fin = 0\n",
    "\n",
    "hashtag_ini_log = ''\n",
    "start_log_timer = ''\n",
    "hashtag_last_log = ''\n",
    "tweet_count = 0\n",
    "\n",
    "url = 'https://api.twitter.com/2/tweets/search/all?'\n",
    "today = datetime.date.today()\n",
    "d1 = today.strftime(\"%d-%m-%Y\")\n",
    "\n"
   ]
  },
  {
   "source": [
    "## Support functions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-3-316f1c766b8e>, line 116)",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-316f1c766b8e>\"\u001b[1;36m, line \u001b[1;32m116\u001b[0m\n\u001b[1;33m    repetido = False\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "user_dictionary = {\n",
    "    \"_id\"               : None,\n",
    "    \"description\"       : '',\n",
    "    \"created_at\"        : '',\n",
    "    \"verified\"          : '',\n",
    "    \"followers_count\"   : 0,\n",
    "    \"following_count\"   : 0\n",
    "}\n",
    "\n",
    "\n",
    "tweet_dictionary = {\n",
    "    \"_id\"               : None,\n",
    "    \"author_id\"         : '',\n",
    "    \"created_at\"        : '',\n",
    "    \"text\"              : '',\n",
    "    \"hashtag\"           : [],\n",
    "    \"referenced_tweets\" : [],\n",
    "    \"retweet_count\"     : 0,\n",
    "    \"reply_count\"       : 0,\n",
    "    \"reply_count\"       : 0,\n",
    "    \"like_count\"        : 0\n",
    "}\n",
    "\n",
    "\n",
    "node = {\n",
    "    \"hashtag\"           : '',\n",
    "    \"current_date\"        : '',\n",
    "    \"next_date\"        : '',\n",
    "    \"next_token\"        : '-1'\n",
    "}\n",
    "\n",
    "\n",
    "def DayMonthYearToPetition(date):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    splited = ''\n",
    "    if ('/' in date):\n",
    "        splited = date.split('/')\n",
    "    elif ('-' in date):\n",
    "        splited = date.split('-')\n",
    "\n",
    "    return (splited[2] + '-' + splited[1] + '-' + splited[0])\n",
    "\n",
    "def DayMonthYearToPetition(date):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    splited = ''\n",
    "    if ('/' in date):\n",
    "        splited = date.split('/')\n",
    "    elif ('-' in date):\n",
    "        splited = date.split('-')\n",
    "\n",
    "    return (splited[2] + '-' + splited[1] + '-' + splited[0])\n",
    "\n",
    "def PetitionToDayMonthYear(petition):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    splited = ''\n",
    "    time = ''\n",
    "    splited = petition.split('T')\n",
    "    time = splited[1]\n",
    "    splited = splited[0].split('-')\n",
    "    return (splited[2] + '-' + splited[1] + '-' + splited[0] + 'T' + time)\n",
    "\n",
    "def make_objid(text):\n",
    "    \"\"\"Makes an ObjectId of 4 bytes\n",
    "    \n",
    "    Keyword arguments:\n",
    "    text -- string to be converted into Object ID\n",
    "    \"\"\"\n",
    "    text = str(text)\n",
    "    if not text.strip():\n",
    "        return None\n",
    "    try:\n",
    "        return ObjectId(text.rjust(24,\"0\"))\n",
    "    except Exception as ex:\n",
    "        #print(len(text))\n",
    "        print(text, ex)\n",
    "        return None\n",
    "\n",
    "def create_headers(bearer_token):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)}\n",
    "    return headers\n",
    "\n",
    "def connect_to_endpoint(headers, params):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    response = requests.request(\"GET\", \"https://api.twitter.com/2/tweets/search/all?\", headers=headers, params=params)\n",
    "    #print(response.status_code)\n",
    "    # Manejo de errores\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.status_code, response.text)\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "def MongoExecute(tweet_list, user_list):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    global myclient\n",
    "    global myusers\n",
    "    global mytweets\n",
    "    global mydb\n",
    "    try:\n",
    "        print(str(mytweets.insert_many(tweet_list, ordered=False)))\n",
    "        print(str(myusers.insert_many(user_list, ordered=False)))\n",
    "    except Exception as e:        \n",
    "        item = None\n",
    "        for tweet in e.details[\"writeErrors\"]:\n",
    "            try:\n",
    "                item = list(mytweets.find({'_id' : tweet['op']['_id']}))[0]\n",
    "                \n",
    "            except Exception as ea:\n",
    "            \n",
    "            repetido = False\n",
    "            print(str(item))\n",
    "            print(str(tweet))\n",
    "            #for hashtag in item['hashtag']:\n",
    "                #if hastag == tweet['hashtag']:\n",
    "                    #repetido = True\n",
    "                    #break\n",
    "            #if repetido == False:\n",
    "                #item[0]['hashtag'].append(tweet['hashtag'])\n",
    "                #try:\n",
    "                    #mytweets.replace_one({'_id' : tweet['op']['_id']}, item)\n",
    "                #except Exception as eaa:\n",
    "                    #pass\n",
    "\n",
    "        pass\n",
    "\n",
    "def PrintTweetsUsers(tweets, users):\n",
    "    print(\"Tweet list\")\n",
    "    for tweet in tweets:\n",
    "        print(\" id: \" + str(tweet['_id']))\n",
    "        print(\" author_id: \" + tweet['author_id'])\n",
    "        print(\" created_at: \" + tweet['created_at'])\n",
    "        print(\" referenced_tweets: \" + str(tweet['referenced_tweets']) + '\\n')\n",
    "\n",
    "    print(\"User list\")\n",
    "    for user in users:\n",
    "        print(\" user_id: \" + str(user['_id']))\n",
    "        print(\" description: \" + user['description'])\n",
    "        print(\" created_at: \" + user['created_at'])\n",
    "        print(\" verified: \" + str(user['verified']))\n",
    "        print(\" followers_count: \" + str(user['followers_count']))\n",
    "        print(\" following_count: \" + str(user['following_count']) + '\\n')\n",
    "\n",
    "#Terminar de insertas los campos del petitionslessequals100\n",
    "    # Insertados los siguientes campos:\n",
    "    #   -start_time: l√≠mite inferior en b√∫squeda de fechas\n",
    "    #   -end_time: l√≠mete superior en b√∫squeda de fechas\n",
    "    #   -tweet.fields=author_id: id del autor del tweet\n",
    "    #   -tweet.fields=referenced_tweets: puede ser quote, retweet o replied_to junto al id al que responde, agrega adem√°s los tweets relativos al tweet al que responde\n",
    "    #   -tweet.fields=created_at: cu'ando se cre'o el fichero\n",
    "    #   -tweet.fields=context_annotations:anotaciones de contexto (no salen muchas)\n",
    "    #   -tweet.fields=lang: Abreviatura del idioma en el que se escribe\n",
    "    #   -tweet.fields=entities: referencias, hashtags usados por el usuario\n",
    "    #   -tweet.fields=in_reply_to_user_id: \n",
    "    #   -    in_reply_to_user_id\n",
    "\n",
    "# Hashtag: nombre del hashtag que se va a buscar\n",
    "# start: fecha de inicio\n",
    "# end: fecha de respuesta\n",
    "# number: n'umero de tweets que queremos obtener\n",
    "# bearer: bearer id\n",
    "# next_token: token de la page (inicialmente string vac'ia) que quieres buscar\n",
    "# return tupla de n'umero de respuestas y next_token\n",
    "def PetitionsLessEqualPETITIONS_LIMIT(hashtag, start, end, bearer, next_token):\n",
    "\n",
    "    global log\n",
    "    global errorlog\n",
    "    global headers\n",
    "    global PETITIONS_LIMIT\n",
    "    global hashtagsList\n",
    "    global hashtags\n",
    "\n",
    "    startDate = DayMonthYearToPetition(start)\n",
    "    endDate = DayMonthYearToPetition(end)\n",
    "    tweet_list = []\n",
    "    user_list = []\n",
    "    total = (0, '', [], [])\n",
    "    dt_string = ''\n",
    "    tweet_dictionary_new = {}\n",
    "    user_dictionary_new = {}\n",
    "    aux = ''\n",
    "\n",
    "    \n",
    "\n",
    "    params = \"query=%23\" + hashtag + \"&start_time=\" +  startDate + \"T00%3A00%3A00Z\" + \"&end_time=\" + endDate + 'T11%3A59%3A59Z&max_results=' + str(PETITIONS_LIMIT) + '&expansions=author_id,referenced_tweets.id&tweet.fields=created_at,conversation_id,referenced_tweets,public_metrics&user.fields=created_at,entities,description,verified,public_metrics'\n",
    "    # caso en el que -1 (primera peticion de dia) o es el next_token\n",
    "    if (next_token != ''):\n",
    "        params = params + '&next_token=' + next_token\n",
    "\n",
    "    # primera petici'on del hashtag\n",
    "    json_obj = ''\n",
    "    try:\n",
    "        json_obj = connect_to_endpoint(headers=headers, params=params)\n",
    "        #print(json.dumps(json_obj, indent=4, sort_keys=True))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return (0, next_token, [], [])\n",
    "    \n",
    "\n",
    "    # Comprobar que hay respuestas para dicho hashtag\n",
    "    if ('meta' in json_obj) and (int(json_obj['meta']['result_count']) > 0):\n",
    "        for tweet in json_obj['data']:\n",
    "            tweet_dictionary_new = tweet_dictionary.copy()\n",
    "            tweet_dictionary_new['hashtag'] = []\n",
    "            tweet_dictionary_new['referenced_tweets'] = []\n",
    "            user_dictionary_new = user_dictionary.copy()\n",
    "            \n",
    "            tweet_dictionary_new['_id'] = make_objid(str(tweet['id']))\n",
    "            tweet_dictionary_new['author_id'] = make_objid(str(tweet['author_id']))\n",
    "            tweet_dictionary_new['text'] = tweet['text']\n",
    "            tweet_dictionary_new['hashtag'].append(hashtag.lower())\n",
    "\n",
    "            tweet_dictionary_new['created_at'] = tweet['created_at']\n",
    "            tweet_dictionary_new['retweet_count'] = tweet['public_metrics']['retweet_count']\n",
    "            tweet_dictionary_new['reply_count'] = tweet['public_metrics']['reply_count']\n",
    "            tweet_dictionary_new['like_count'] = tweet['public_metrics']['like_count']\n",
    "            tweet_dictionary_new['quote_count'] = tweet['public_metrics']['quote_count']\n",
    "\n",
    "            if ('referenced_tweets' in tweet):\n",
    "                tweet_dictionary_new['referenced_tweets'] = tweet['referenced_tweets']\n",
    "                for rt in tweet_dictionary_new['referenced_tweets']:\n",
    "                    for tweetexpanse in json_obj['includes']['tweets']:\n",
    "                        if (rt['id'] == tweetexpanse['id']):\n",
    "                            rt['author_id'] = make_objid(str(tweetexpanse['author_id']))\n",
    "                            rt['id'] = make_objid(str(tweetexpanse['id']))\n",
    "                            break\n",
    "\n",
    "            unknown = True\n",
    "            for user in user_list:\n",
    "                if (str(user['_id']) == tweet_dictionary_new['author_id']):\n",
    "                    unknown = False\n",
    "                    break\n",
    "\n",
    "            if (unknown == True):\n",
    "                user_dictionary_new['_id'] = make_objid(str(tweet['author_id']))\n",
    "                if ('includes' in json_obj):\n",
    "                    for user in json_obj['includes']['users']:\n",
    "                        if (str(user['id']) == tweet['author_id']):\n",
    "                            user_dictionary_new['description'] = user['description']\n",
    "                            user_dictionary_new['created_at'] = user['created_at']\n",
    "                            user_dictionary_new['verified'] = user['verified']\n",
    "                            user_dictionary_new['followers_count'] = int(user['public_metrics']['followers_count'])\n",
    "                            user_dictionary_new['following_count'] = int(user['public_metrics']['following_count'])\n",
    "                            break\n",
    "                #aqui otro manejo de errores\n",
    "                else:\n",
    "                    print ('otro error')\n",
    "                user_list.append(user_dictionary_new)\n",
    "\n",
    "            tweet_list.append(tweet_dictionary_new)\n",
    "\n",
    "        if ('next_token' in json_obj['meta']):\n",
    "            total = (int(json_obj['meta']['result_count']), json_obj['meta']['next_token'], tweet_list, user_list)\n",
    "\n",
    "        else:\n",
    "            total = (int(json_obj['meta']['result_count']), '', tweet_list, user_list)\n",
    "\n",
    "        print(\"     N'umero de peticiones enviadas: \" + str(PETITIONS_LIMIT))\n",
    "        print(\"     N'umero de peticiones recibidas: \" + str(json_obj['meta']['result_count']))\n",
    "        print(\"     \" + str(total[1]))\n",
    "        return total\n",
    "    # Caso en el que la respuesta es un error y hay que manejarlo\n",
    "    else:\n",
    "        strerror = '    '\n",
    "        #print(\"Error en la petici√≥n: \")\n",
    "        strerror = strerror + str(params)\n",
    "        #print(entrada.split(' -H')[0])\n",
    "        strerror = strerror + \"Error en la petici√≥n: \"\n",
    "        # si el error es por cuesti√≥n de peticiones esperar para hacer la siguiente peticion\n",
    "        if ('title' in json_obj):\n",
    "            #print(\"  T√≠tulo del error: \" + str(json_obj['title']))\n",
    "            strerror = strerror + \"  T√≠tulo del error: \" + str(json_obj['title'])\n",
    "            if ('status' in json_obj):\n",
    "                strerror = strerror + \" C√≥digo de error: \" + str(json_obj['status'])\n",
    "                #print(\"  C√≥digo de error: \" + str(json_obj['status']))\n",
    "            if ('detail' in json_obj):\n",
    "                strerror = strerror + \"  Descripci√≥n del error: \" + str(json_obj['detail'])\n",
    "                #print(\"  Descripci√≥n del error: \" + str(json_obj['detail']))\n",
    "                \n",
    "        errorlog.write(strerror + \" \" + dt_string + '\\n')\n",
    "        total = (0, next_token, [], [])\n",
    "    return total\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Hashtag: nombre del hashtag que se va a buscar\n",
    "# start: fecha de inicio\n",
    "# end: fecha de respuesta\n",
    "# number: n'umero de tweets que queremos obtener\n",
    "# bearer: bearer id\n",
    "# return devuelve dos diccionarios (users-tweet, tweet-tweet_items)\n",
    "def TweetList(hashtag, start, end, bearer, token):\n",
    "    global tiempo\n",
    "    global TIMER\n",
    "    global TIMER_LOG\n",
    "    global tweet_count\n",
    "    global hashtag_ini_log\n",
    "    global hashtag_last_log\n",
    "    global start_log_timer\n",
    "    \n",
    "\n",
    "    #aqui deberia de hacer dos variables de incio y fin de log para saber con cual hashtag empiezo y termino y con cuantos valores totales de cada uno.QUITAR TWEETLIST\n",
    "    user_list = []\n",
    "    tweet_list = []\n",
    "    total = 0\n",
    "    aux = 0\n",
    "    startTime = 0\n",
    "    endTime = 0\n",
    "    response = (0, token, [], [])\n",
    "\n",
    "    startTime = time.time()\n",
    "\n",
    "    response =  PetitionsLessEqualPETITIONS_LIMIT(hashtag, start, end, bearer, response[1])\n",
    "\n",
    "    user_list.extend(response[3])\n",
    "    #inserci'on de tweets nuevos a la lista de tweets\n",
    "    tweet_list.extend(response[2])\n",
    "    total = response[0]\n",
    "    tweet_count += response[0]\n",
    "    #tweet_list.extend(total[2])\n",
    "\n",
    "    endTime = time.time()\n",
    "\n",
    "    aux = round(math.floor(endTime - startTime))\n",
    "    if (aux < TIMER):\n",
    "        number = TIMER - aux\n",
    "        time.sleep(number)\n",
    "        print('     sleep number: ' + str(number) + ', aux: ' + str(aux), flush=True)\n",
    "        tiempo -= TIMER\n",
    "    else:\n",
    "        tiempo -= aux\n",
    "        print('     aux: ' + str(aux), flush=True)\n",
    "    \n",
    "    if (tiempo <= 0):\n",
    "        #aqui se imprime en el log los hashtags que se han escrito y c'uantos valores se han obtenido de estos\n",
    "        tiempo = TIMER_LOG\n",
    "        # datetime object containing current date and time\n",
    "        now = datetime.datetime.now()\n",
    "        # dd/mm/YY H:M:S\n",
    "        dt_string = now.strftime(\"%H:%M:%S\")\n",
    "        hashtag_last_log = hashtag\n",
    "        log.write(hashtag_ini_log + ' ' + start_log_timer + ' ' + hashtag + ' ' + start + ' ' + dt_string + '\\n')\n",
    "        start_log_timer = dt_string\n",
    "        tweet_count = 0\n",
    "        hashtag_ini_log = hashtag_last_log\n",
    "    \n",
    "    print (\"    Tweets totales: \" + str(total) + '\\n')\n",
    "\n",
    "    return (total, response[1], tweet_list, user_list)\n",
    "\n",
    "\n",
    "def GetTweets(start_date, end_date):\n",
    "\n",
    "\n",
    "    global tiempo\n",
    "    global TIMER\n",
    "    global TIMER_LOG\n",
    "    global tweet_count\n",
    "    global hashtags\n",
    "\n",
    "    aux = end_date.split('-')\n",
    "    last_date = date(int(aux[2]), int(aux[1]), int(aux[0]))\n",
    "    last_date = last_date.strftime(\"%d/%m/%Y\")\n",
    "\n",
    "    f =  open(\"./hashtags.txt\", \"r\")\n",
    "    hashtags = f.readlines()\n",
    "    f.close()\n",
    "    \n",
    "    if os.path.exists(\"./lasttoken.txt\") and os.path.getsize(\"./lasttoken.txt\") > 0:\n",
    "        f =  open(\"./lasttoken.txt\", \"r\")\n",
    "        while True:\n",
    "            # read line\n",
    "            try:\n",
    "                hashtag = f.readline()\n",
    "                if (hashtag == \"\") :\n",
    "                    break\n",
    "            except:\n",
    "                # datetime object containing current date and time\n",
    "                now = datetime.datetime.now()\n",
    "                # dd/mm/YY H:M:S\n",
    "                dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "                errorlog.write(\"Fallo al leer el fichero hashtags.txt \" + dt_string + \"\\n\")\n",
    "\n",
    "            hashtag = hashtag.rstrip('\\n')\n",
    "            hashtag = hashtag.split(' ')\n",
    "            node_aux = node.copy()\n",
    "            node_aux['hashtag'] = hashtag[0]\n",
    "            node_aux['next_token'] = hashtag[1]\n",
    "            node_aux['current_date'] = hashtag[2]\n",
    "            node_aux[\"next_date\"] = hashtag[3]  \n",
    "            hashtagsList.append(node_aux)\n",
    "        f.close()\n",
    "\n",
    "        fd=open(\"./lasttoken.txt\",\"r\")\n",
    "        d=fd.read()\n",
    "        fd.close()\n",
    "        m=d.split(\"\\n\")\n",
    "        s=\"\\n\".join(m[:-1])\n",
    "\n",
    "        fd=open(\"./lasttoken.txt\",\"w+\")\n",
    "        for i in range(len(s)):\n",
    "            fd.write(s[i])\n",
    "        fd.close()\n",
    "        \n",
    "    else:\n",
    "        #####Uso de Hashtag\n",
    "        f =  open(\"./hashtags.txt\", \"r\")\n",
    "        d =  open(\"./lasttoken.txt\", \"w+\")\n",
    "        \n",
    "        writeable = ''\n",
    "        hashtag = None\n",
    "        resultado = (0, '', [], [])\n",
    "        aux = start_date.split('-')\n",
    "        dat = date(int(aux[2]), int(aux[1]), int(aux[0]))\n",
    "        first_day = dat\n",
    "        dat += datetime.timedelta(days=1)\n",
    "        next_day = dat\n",
    "        str_first_day = first_day.strftime(\"%d/%m/%Y\")\n",
    "        str_next_day = next_day.strftime(\"%d/%m/%Y\")\n",
    "        while True:\n",
    "            # read line\n",
    "            try:\n",
    "                hashtag = f.readline()\n",
    "                if (hashtag == \"\") :\n",
    "                    break\n",
    "            except:\n",
    "                # datetime object containing current date and time\n",
    "                now = datetime.datetime.now()\n",
    "                # dd/mm/YY H:M:S\n",
    "                dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "                errorlog.write(\"    Fallo al leer el fichero hashtags.txt \" + dt_string + \"\\n\")\n",
    "            \n",
    "            hashtag = hashtag.rstrip('\\n')\n",
    "            hashtag = hashtag.replace('#', '')\n",
    "            \n",
    "            node_aux = node.copy()\n",
    "            node_aux[\"hashtag\"] = hashtag\n",
    "            writeable = hashtag\n",
    "\n",
    "            writeable += ' ' + node_aux['next_token']\n",
    "\n",
    "            node_aux[\"current_date\"] = str_first_day   \n",
    "            writeable += ' ' + str_first_day \n",
    "\n",
    "            node_aux[\"next_date\"] = str_next_day \n",
    "            writeable += ' ' + str_next_day + '\\n'   \n",
    "\n",
    "            hashtagsList.append(node_aux)\n",
    "            d.write(writeable)\n",
    "            # check if line is not empty\n",
    "        d.close()\n",
    "        f.close()\n",
    "\n",
    "        \n",
    "\n",
    "    for h in hashtagsList:\n",
    "        print(str(h))\n",
    "        \n",
    "\n",
    "\n",
    "    if (len(hashtagsList) != 0):\n",
    "        hashtag_ini_log = hashtagsList[0]\n",
    "        # dd/mm/YY H:M:S\n",
    "        now = datetime.datetime.now()\n",
    "        dt_string = now.strftime(\"%H:%M:%S\")\n",
    "        start_log_timer = dt_string\n",
    "        \n",
    "    else:\n",
    "        # datetime object containing current date and time\n",
    "        now = datetime.datetime.now()\n",
    "        # dd/mm/YY H:M:S\n",
    "        dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "        errorlog.write(\"    Error: lista de hashtags vac√≠a\" + \" dt_string\\n\")\n",
    "\n",
    "    count = 0\n",
    "    temporalTokens = ''\n",
    "    tweet_list = []\n",
    "    user_list = []\n",
    "    start = 0\n",
    "    end = 0\n",
    "    \n",
    "    last = False\n",
    "    while last == False:\n",
    "        for l in hashtagsList:\n",
    "            start = 0\n",
    "            end = 0\n",
    "            aux = 0\n",
    "            #bucle de obtencion de tweets para un dia concreto\n",
    "            while (l[\"next_token\"] != ''):\n",
    "                if l[\"next_token\"] == '-1':\n",
    "                    print('Inicio hashtag: ' + l['hashtag'] + ' d√≠a: ' + l['current_date'])\n",
    "                    resultado = TweetList(l[\"hashtag\"], l[\"current_date\"], l[\"next_date\"], Bearer, '')\n",
    "                else:\n",
    "                    resultado = TweetList(l[\"hashtag\"], l[\"current_date\"], l[\"next_date\"], Bearer, l[\"next_token\"])\n",
    "                start = time.time()\n",
    "                tweet_list.extend(resultado[2])\n",
    "                user_list.extend(resultado[3])\n",
    "                l[\"next_token\"] = resultado[1]\n",
    "\n",
    "                end = time.time()\n",
    "                tiempo -= round(math.floor(start - end))\n",
    "                if (tiempo <= 0):\n",
    "                    # datetime object containing current date and time\n",
    "                    tiempo = TIMER_LOG\n",
    "                    now = datetime.datetime.now()\n",
    "                    # dd/mm/YY H:M:S\n",
    "                    dt_string = now.strftime(\"%H:%M:%S\")\n",
    "                    log.write(hashtag_ini_log + ' ' + start_log_timer + ' ' + l['hashtag'] + ' ' + l['current_date'] + ' ' + dt_string + '\\n')\n",
    "                    hashtag_ini_log = l['hashtag']\n",
    "\n",
    "            start = time.time()\n",
    "            # Substring de % para insertar en la base de datos\n",
    "            count = 0\n",
    "            count = round(math.ceil(len(tweet_list) * PERCENT))\n",
    "            #primero comprobamos si no hemos insertado inicialmente en la base de datos tantos tweets como pone en count\n",
    "            search = list(mytweets.find( {\"hashtag\" : l[\"hashtag\"]} ))\n",
    "            count -= len(search)\n",
    "            if count > 0:\n",
    "                #buscamos los tweets que estan en la base  de datos y los borramos de nuestra lista de tweets\n",
    "                for t in search:\n",
    "                    if t in tweet_list:\n",
    "                        tweet_list.remove(t)\n",
    "                # caso en el que count es menor de lo que podemos insertar\n",
    "                if count < len(tweet_list):\n",
    "                    tweet_list = tweet_list[0:(count - 1)]\n",
    "\n",
    "                aux_list = []\n",
    "                # Ahora buscamos los users relacionados con los tweets de la lista\n",
    "                for u in user_list:\n",
    "                    for t in tweet_list:\n",
    "                        if str(t['author_id']) == str(u['_id']):\n",
    "                            aux_list.append(u)\n",
    "                            break\n",
    "                #Aqui se inserta en la base de datos\n",
    "                #alomejor aqui ponemos la cantidad de valores que se insertan en la lista, para los casos en los que los tweets coinciden con otros tweets\n",
    "                print(\"Total tweets insertados: \" + str(len(tweet_list)) + \", Total usuarios insertados: \" + str(len(aux_list)))\n",
    "                MongoExecute(tweet_list, aux_list)\n",
    "            \n",
    "            #ahora cambiamos de d'ia y quitamos la lista\n",
    "            tweet_list = []\n",
    "            user_list = []\n",
    "            print('     Cambio de d√≠a ' + l['current_date'] + '\\n')\n",
    "            l['current_date'] = l['next_date']\n",
    "            dat = datetime.datetime.strptime(l['current_date'], \"%d/%m/%Y\")\n",
    "            dat += datetime.timedelta(days=1)\n",
    "            l['next_date'] = dat.strftime(\"%d/%m/%Y\").split(' ')[0]\n",
    "            l['next_token'] = '-1'\n",
    "            #borramos la 'ultima linea de fichero de lasttoken\n",
    "            if os.path.exists(\"./lasttoken.txt\") and os.path.getsize(\"./lasttoken.txt\") > 0:\n",
    "                d = ''\n",
    "                f =  open(\"./lasttoken.txt\", \"r\")\n",
    "                #remove last line from a text line in python\n",
    "                d = f.readlines()\n",
    "                f.close()\n",
    "                \n",
    "                for i in range(len(d)):\n",
    "                    if d[i].split()[0] == l['hashtag']:\n",
    "                        d[i] = l['hashtag'] + ' ' + l['next_token'] + ' ' + l['current_date'] + ' ' + l[\"next_date\"] + '\\n'\n",
    "\n",
    "                f = open(\"./lasttoken.txt\",\"w+\")\n",
    "                f.writelines(d)\n",
    "                f.close()\n",
    "\n",
    "            if (l[\"current_date\"] == last_date):\n",
    "                last = True\n",
    "\n",
    "            end = time.time()\n",
    "                \n",
    "            tiempo -= round(math.floor(start - end))\n",
    "            if (tiempo <= 0):\n",
    "                # datetime object containing current date and time\n",
    "                tiempo = TIMER_LOG\n",
    "                now = datetime.datetime.now()\n",
    "                # dd/mm/YY H:M:S\n",
    "                dt_string = now.strftime(\"%H:%M:%S\")\n",
    "                log.write(hashtag_ini_log + ' ' + start_log_timer + ' ' + l['hashtag'] + ' ' + l['current_date'] + ' ' + dt_string + '\\n')\n",
    "                hashtag_ini_log = l['hashtag']\n",
    "\n",
    "            print(\"Fin Hashtag: \" + str(l['hashtag']) + \"\\n\\n\")        \n",
    "\n",
    "    log.close()\n",
    "    errorlog.close()\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "source": [
    "## Main code"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Si ya se ha buscado anteriormente entonces deber√≠as de comprobar si la b√∫squeda y lo que se pide de base (n_teets no se que es igual al n√∫mero de tweets del hashtag)\n",
    "\n",
    "myclient = pymongo.MongoClient('localhost', 27017)\n",
    "mydb = myclient[\"mydatabase\"]\n",
    "myusers = mydb[\"users\"]\n",
    "mytweets = mydb[\"tweets\"]\n",
    "\n",
    "f = open(\"./accountV2.txt\", \"r\")\n",
    "Bearer = f.readline().rstrip('\\n')\n",
    "f.close()\n",
    "headers = create_headers(Bearer)\n",
    "\n",
    "fileObj = Path(\"./log\" + d1 + \".txt\")\n",
    "if (fileObj.is_file()):\n",
    "    os.remove(\"./log\" + d1 + \".txt\")\n",
    "\n",
    "fileObj = Path(\"./errorlog\" + d1 + \".txt\")\n",
    "if (fileObj.is_file()):\n",
    "    os.remove(\"./errorlog\" + d1 + \".txt\")\n",
    "\n",
    "log = open(\"./log\" + d1 + \".txt\", \"a\")\n",
    "log.write(\"Primer log\\n\")\n",
    "#Crear ficheros de log\n",
    "errorlog = open(\"./errorlog\" + d1 + \".txt\", \"a\")\n",
    "\n",
    "\n",
    "GetTweets(\"18-03-2021\", \"04-05-2021\")\n"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'hashtag': 'DemocraciaOFascismo4M', 'current_date': '18/03/2021', 'next_date': '19/03/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'SosoSerioYFormal', 'current_date': '18/03/2021', 'next_date': '19/03/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'ColetasRata', 'current_date': '18/03/2021', 'next_date': '19/03/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'RataSinColeta', 'current_date': '18/03/2021', 'next_date': '19/03/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'PodemosAtacaAPodemos', 'current_date': '18/03/2021', 'next_date': '19/03/2021', 'next_token': '-1'}\n",
      "{'hashtag': '4MConPabloIglesias', 'current_date': '18/03/2021', 'next_date': '19/03/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'semarlaskalatragedia', 'current_date': '18/03/2021', 'next_date': '19/03/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'IreneMonteroDimision', 'current_date': '18/03/2021', 'next_date': '19/03/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'TeamVox', 'current_date': '18/03/2021', 'next_date': '19/03/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'SoloQuedaVox', 'current_date': '18/03/2021', 'next_date': '19/03/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'VoxLivesMatter', 'current_date': '18/03/2021', 'next_date': '19/03/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'Elecciones4M', 'current_date': '18/03/2021', 'next_date': '19/03/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'NazisYCorruptos', 'current_date': '18/03/2021', 'next_date': '19/03/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'Pucherazo', 'current_date': '18/03/2021', 'next_date': '19/03/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'RompeTuVoto', 'current_date': '18/03/2021', 'next_date': '19/03/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'IlegalizacionDeVoxYa', 'current_date': '18/03/2021', 'next_date': '19/03/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'DebateSER', 'current_date': '18/03/2021', 'next_date': '19/03/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'VotaLIBERTAD', 'current_date': '18/03/2021', 'next_date': '19/03/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'DebateTelemadrid', 'current_date': '18/03/2021', 'next_date': '19/03/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'eleccionesMadrid2021', 'current_date': '18/03/2021', 'next_date': '19/03/2021', 'next_token': '-1'}\n",
      "Inicio hashtag: DemocraciaOFascismo4M d√≠a: 18/03/2021\n",
      "     sleep number: 4.0, aux: 0\n",
      "    Tweets totales: 0\n",
      "\n",
      "     Cambio de d√≠a 18/03/2021\n",
      "\n",
      "Fin Hashtag: DemocraciaOFascismo4M\n",
      "\n",
      "\n",
      "Inicio hashtag: SosoSerioYFormal d√≠a: 18/03/2021\n",
      "     sleep number: 4.0, aux: 0\n",
      "    Tweets totales: 0\n",
      "\n",
      "     Cambio de d√≠a 18/03/2021\n",
      "\n",
      "Fin Hashtag: SosoSerioYFormal\n",
      "\n",
      "\n",
      "Inicio hashtag: ColetasRata d√≠a: 18/03/2021\n",
      "     N'umero de peticiones enviadas: 500\n",
      "     N'umero de peticiones recibidas: 158\n",
      "     \n",
      "     sleep number: 3.0, aux: 1\n",
      "    Tweets totales: 158\n",
      "\n",
      "Total tweets insertados: 23, Total usuarios insertados: 28\n",
      "{'_id': ObjectId('000001372867595653812227'), 'author_id': ObjectId('000000000000000490687887'), 'created_at': '2021-03-19T11:08:36.000Z', 'text': 'RT @munozmalpartida: @PabloIglesias Es una irresponsabilidad may√∫scula que siendo candidato contin√∫es con el mismo lenguaje guerracivilista‚Ä¶', 'hashtag': ['coletasrata'], 'referenced_tweets': [{'type': 'retweeted', 'id': ObjectId('000001372864470779854849'), 'author_id': ObjectId('000001069713567824388096')}], 'retweet_count': 3, 'reply_count': 0, 'like_count': 0, 'quote_count': 0}\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'hastag' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBulkWriteError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-ae05a85e54a9>\u001b[0m in \u001b[0;36mMongoExecute\u001b[1;34m(tweet_list, user_list)\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmytweets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert_many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mordered\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmyusers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert_many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muser_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mordered\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\joseg\\OneDrive\\Documentos\\TFG-Bots-OSN\\TFGBotsV2\\lib\\site-packages\\pymongo\\collection.py\u001b[0m in \u001b[0;36minsert_many\u001b[1;34m(self, documents, ordered, bypass_document_validation, session)\u001b[0m\n\u001b[0;32m    760\u001b[0m         \u001b[0mblk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdoc\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 761\u001b[1;33m         \u001b[0mblk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrite_concern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    762\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mInsertManyResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minserted_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrite_concern\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macknowledged\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\joseg\\OneDrive\\Documentos\\TFG-Bots-OSN\\TFGBotsV2\\lib\\site-packages\\pymongo\\bulk.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, write_concern, session)\u001b[0m\n\u001b[0;32m    527\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 528\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrite_concern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    529\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\joseg\\OneDrive\\Documentos\\TFG-Bots-OSN\\TFGBotsV2\\lib\\site-packages\\pymongo\\bulk.py\u001b[0m in \u001b[0;36mexecute_command\u001b[1;34m(self, generator, write_concern, session)\u001b[0m\n\u001b[0;32m    362\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfull_result\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"writeErrors\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfull_result\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"writeConcernErrors\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m             \u001b[0m_raise_bulk_write_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfull_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\joseg\\OneDrive\\Documentos\\TFG-Bots-OSN\\TFGBotsV2\\lib\\site-packages\\pymongo\\bulk.py\u001b[0m in \u001b[0;36m_raise_bulk_write_error\u001b[1;34m(full_result)\u001b[0m\n\u001b[0;32m    139\u001b[0m             key=lambda error: error[\"index\"])\n\u001b[1;32m--> 140\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mBulkWriteError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_result\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mBulkWriteError\u001b[0m: batch op errors occurred, full error: {'writeErrors': [{'index': 0, 'code': 11000, 'keyPattern': {'_id': 1}, 'keyValue': {'_id': ObjectId('000001372867595653812227')}, 'errmsg': \"E11000 duplicate key error collection: mydatabase.tweets index: _id_ dup key: { _id: ObjectId('000001372867595653812227') }\", 'op': {'_id': ObjectId('000001372867595653812227'), 'author_id': ObjectId('000000000000000490687887'), 'created_at': '2021-03-19T11:08:36.000Z', 'text': 'RT @munozmalpartida: @PabloIglesias Es una irresponsabilidad may√∫scula que siendo candidato contin√∫es con el mismo lenguaje guerracivilista‚Ä¶', 'hashtag': ['coletasrata'], 'referenced_tweets': [{'type': 'retweeted', 'id': ObjectId('000001372864470779854849'), 'author_id': ObjectId('000001069713567824388096')}], 'retweet_count': 3, 'reply_count': 0, 'like_count': 0, 'quote_count': 0}}, {'index': 1, 'code': 11000, 'keyPattern': {'_id': 1}, 'keyValue': {'_id': ObjectId('000001372866932060327941')}, 'errmsg': \"E11000 duplicate key error collection: mydatabase.tweets index: _id_ dup key: { _id: ObjectId('000001372866932060327941') }\", 'op': {'_id': ObjectId('000001372866932060327941'), 'author_id': ObjectId('000001369971348626415617'), 'created_at': '2021-03-19T11:05:57.000Z', 'text': '@PODEMOS @PabloIglesias @JesusCintora Madrid ser√° la tumba del coletas.\\n#ColetasRata\\n#IglesiasCierraAlSalir', 'hashtag': ['coletasrata'], 'referenced_tweets': [{'type': 'replied_to', 'id': ObjectId('000001372865684422619139'), 'author_id': ObjectId('000000000000002288138575')}], 'retweet_count': 0, 'reply_count': 0, 'like_count': 1, 'quote_count': 0}}, {'index': 2, 'code': 11000, 'keyPattern': {'_id': 1}, 'keyValue': {'_id': ObjectId('000001372864470779854849')}, 'errmsg': \"E11000 duplicate key error collection: mydatabase.tweets index: _id_ dup key: { _id: ObjectId('000001372864470779854849') }\", 'op': {'_id': ObjectId('000001372864470779854849'), 'author_id': ObjectId('000001069713567824388096'), 'created_at': '2021-03-19T10:56:11.000Z', 'text': '@PabloIglesias Es una irresponsabilidad may√∫scula que siendo candidato contin√∫es con el mismo lenguaje guerracivilista y el discurso del odio que siempre te ha caracterizado \\n\\nEn Madrid no te queremos \\n\\nEl comunismo y el foro de Sao Paulo no pasar√°n. Te quedar√°s con las ganas \\n\\n#COLETASRATA', 'hashtag': ['coletasrata'], 'referenced_tweets': [{'type': 'replied_to', 'id': ObjectId('000001372641099257421830'), 'author_id': ObjectId('000000000000000158342368')}], 'retweet_count': 3, 'reply_count': 0, 'like_count': 19, 'quote_count': 0}}, {'index': 3, 'code': 11000, 'keyPattern': {'_id': 1}, 'keyValue': {'_id': ObjectId('000001372862874855612417')}, 'errmsg': \"E11000 duplicate key error collection: mydatabase.tweets index: _id_ dup key: { _id: ObjectId('000001372862874855612417') }\", 'op': {'_id': ObjectId('000001372862874855612417'), 'author_id': ObjectId('000000000000002306121657'), 'created_at': '2021-03-19T10:49:50.000Z', 'text': '@PabloEchenique Como os jode no poder manipular a la gente, ya sea en los colegios, universidades, o por la tele. Sois escoria. Menos mal que los padres pueden elegir que se les dice y que no a sus hijos en Murcia. Ojal√° llegue a todo el pa√≠s. \\n#ColetasRata', 'hashtag': ['coletasrata'], 'referenced_tweets': [{'type': 'replied_to', 'id': ObjectId('000001372834810960437248'), 'author_id': ObjectId('000000000000000025555639')}], 'retweet_count': 0, 'reply_count': 0, 'like_count': 0, 'quote_count': 0}}, {'index': 4, 'code': 11000, 'keyPattern': {'_id': 1}, 'keyValue': {'_id': ObjectId('000001372862131020959744')}, 'errmsg': \"E11000 duplicate key error collection: mydatabase.tweets index: _id_ dup key: { _id: ObjectId('000001372862131020959744') }\", 'op': {'_id': ObjectId('000001372862131020959744'), 'author_id': ObjectId('000000000000002306121657'), 'created_at': '2021-03-19T10:46:53.000Z', 'text': '@menos_drama Es que las posturas de esta p√°jara para llegar donde ha llegado acaban pasando factura. #ColetasRata', 'hashtag': ['coletasrata'], 'referenced_tweets': [{'type': 'replied_to', 'id': ObjectId('000001372844640387366915'), 'author_id': ObjectId('000000965498082245971968')}], 'retweet_count': 0, 'reply_count': 0, 'like_count': 0, 'quote_count': 0}}, {'index': 5, 'code': 11000, 'keyPattern': {'_id': 1}, 'keyValue': {'_id': ObjectId('000001372856346224291840')}, 'errmsg': \"E11000 duplicate key error collection: mydatabase.tweets index: _id_ dup key: { _id: ObjectId('000001372856346224291840') }\", 'op': {'_id': ObjectId('000001372856346224291840'), 'author_id': ObjectId('000000000000000485010765'), 'created_at': '2021-03-19T10:23:54.000Z', 'text': '@laSextaTV #COLETASRATA', 'hashtag': ['coletasrata'], 'referenced_tweets': [{'type': 'replied_to', 'id': ObjectId('000001372840272296607744'), 'author_id': ObjectId('000000000000000022954354')}], 'retweet_count': 0, 'reply_count': 0, 'like_count': 0, 'quote_count': 0}}, {'index': 6, 'code': 11000, 'keyPattern': {'_id': 1}, 'keyValue': {'_id': ObjectId('000001372850912314720256')}, 'errmsg': \"E11000 duplicate key error collection: mydatabase.tweets index: _id_ dup key: { _id: ObjectId('000001372850912314720256') }\", 'op': {'_id': ObjectId('000001372850912314720256'), 'author_id': ObjectId('000001362410749042307076'), 'created_at': '2021-03-19T10:02:18.000Z', 'text': 'El regalo de La marquesa a la #ColetasRata \\n#diadelpadre https://t.co/kSAUUWJUar', 'hashtag': ['coletasrata'], 'referenced_tweets': [], 'retweet_count': 0, 'reply_count': 0, 'like_count': 2, 'quote_count': 0}}, {'index': 7, 'code': 11000, 'keyPattern': {'_id': 1}, 'keyValue': {'_id': ObjectId('000001372845268790562818')}, 'errmsg': \"E11000 duplicate key error collection: mydatabase.tweets index: _id_ dup key: { _id: ObjectId('000001372845268790562818') }\", 'op': {'_id': ObjectId('000001372845268790562818'), 'author_id': ObjectId('000000000000000238544952'), 'created_at': '2021-03-19T09:39:52.000Z', 'text': 'RT @SrPigdemont: En Madrid @PabloIglesias merece tantos diputados como visitas realiz√≥ a las Residencias de Ancianos mientras fue el respon‚Ä¶', 'hashtag': ['coletasrata'], 'referenced_tweets': [{'type': 'retweeted', 'id': ObjectId('000001371760190287192065'), 'author_id': ObjectId('000001364329203328569346')}], 'retweet_count': 1076, 'reply_count': 0, 'like_count': 0, 'quote_count': 0}}, {'index': 8, 'code': 11000, 'keyPattern': {'_id': 1}, 'keyValue': {'_id': ObjectId('000001372839732544147458')}, 'errmsg': \"E11000 duplicate key error collection: mydatabase.tweets index: _id_ dup key: { _id: ObjectId('000001372839732544147458') }\", 'op': {'_id': ObjectId('000001372839732544147458'), 'author_id': ObjectId('000000000000000187476630'), 'created_at': '2021-03-19T09:17:53.000Z', 'text': \"S√≥c a recuperaci√≥. Hi ha un #ColetasRata de les antigues col√≤nies intentant lligar-se a una d'aquestes de la #BarcelonaWorkation, ella amb castelladre trencat i tots els t√≤pics del colauisme sociata: la bici, el v√≤lei platja, la Barceloneta, el viure a Sant Antoni... MORIU-VOS.\", 'hashtag': ['coletasrata'], 'referenced_tweets': [], 'retweet_count': 0, 'reply_count': 1, 'like_count': 4, 'quote_count': 0}}, {'index': 9, 'code': 11000, 'keyPattern': {'_id': 1}, 'keyValue': {'_id': ObjectId('000001372831271055921153')}, 'errmsg': \"E11000 duplicate key error collection: mydatabase.tweets index: _id_ dup key: { _id: ObjectId('000001372831271055921153') }\", 'op': {'_id': ObjectId('000001372831271055921153'), 'author_id': ObjectId('000001112299155882426368'), 'created_at': '2021-03-19T08:44:15.000Z', 'text': '@eduardoinda Tranquilos que ya le echar√° la culpa - si es menester- al empedrado.\\n#ColetasRata', 'hashtag': ['coletasrata'], 'referenced_tweets': [{'type': 'replied_to', 'id': ObjectId('000001372824010002722816'), 'author_id': ObjectId('000000698104968105095170')}], 'retweet_count': 0, 'reply_count': 0, 'like_count': 0, 'quote_count': 0}}, {'index': 10, 'code': 11000, 'keyPattern': {'_id': 1}, 'keyValue': {'_id': ObjectId('000001372830694884380672')}, 'errmsg': \"E11000 duplicate key error collection: mydatabase.tweets index: _id_ dup key: { _id: ObjectId('000001372830694884380672') }\", 'op': {'_id': ObjectId('000001372830694884380672'), 'author_id': ObjectId('000000000000000525811784'), 'created_at': '2021-03-19T08:41:58.000Z', 'text': '@PabloIglesias No pasar√°n ü§£ü§£ü§£ü§£\\nHace 80 a√±os que pasaron subcampe√≥n\\n#ColetasRata', 'hashtag': ['coletasrata'], 'referenced_tweets': [{'type': 'replied_to', 'id': ObjectId('000001372641099257421830'), 'author_id': ObjectId('000000000000000158342368')}], 'retweet_count': 0, 'reply_count': 0, 'like_count': 0, 'quote_count': 0}}, {'index': 11, 'code': 11000, 'keyPattern': {'_id': 1}, 'keyValue': {'_id': ObjectId('000001372829549067649032')}, 'errmsg': \"E11000 duplicate key error collection: mydatabase.tweets index: _id_ dup key: { _id: ObjectId('000001372829549067649032') }\", 'op': {'_id': ObjectId('000001372829549067649032'), 'author_id': ObjectId('000001154775506375643137'), 'created_at': '2021-03-19T08:37:25.000Z', 'text': '@PabloIglesias Ayuso for PRESIDENT! #ColetasRata', 'hashtag': ['coletasrata'], 'referenced_tweets': [{'type': 'replied_to', 'id': ObjectId('000001372810793578864642'), 'author_id': ObjectId('000000000000000158342368')}], 'retweet_count': 1, 'reply_count': 1, 'like_count': 1, 'quote_count': 0}}, {'index': 12, 'code': 11000, 'keyPattern': {'_id': 1}, 'keyValue': {'_id': ObjectId('000001372827699287298053')}, 'errmsg': \"E11000 duplicate key error collection: mydatabase.tweets index: _id_ dup key: { _id: ObjectId('000001372827699287298053') }\", 'op': {'_id': ObjectId('000001372827699287298053'), 'author_id': ObjectId('000001120815873919520768'), 'created_at': '2021-03-19T08:30:04.000Z', 'text': '@El_Intermedio El sue√±o h√∫medo de Iglesias.\\nVacuna rusa para #ColetasRata ya!', 'hashtag': ['coletasrata'], 'referenced_tweets': [{'type': 'replied_to', 'id': ObjectId('000001372825688126988289'), 'author_id': ObjectId('000000000000000016080129')}], 'retweet_count': 0, 'reply_count': 0, 'like_count': 0, 'quote_count': 0}}, {'index': 13, 'code': 11000, 'keyPattern': {'_id': 1}, 'keyValue': {'_id': ObjectId('000001372823984518074370')}, 'errmsg': \"E11000 duplicate key error collection: mydatabase.tweets index: _id_ dup key: { _id: ObjectId('000001372823984518074370') }\", 'op': {'_id': ObjectId('000001372823984518074370'), 'author_id': ObjectId('000001307875497943150593'), 'created_at': '2021-03-19T08:15:18.000Z', 'text': 'RT @david_segura: En Madrid #ColetasRata https://t.co/pvAOpWiNmd', 'hashtag': ['coletasrata'], 'referenced_tweets': [{'type': 'retweeted', 'id': ObjectId('000001372601660959252484'), 'author_id': ObjectId('000000000000000065602229')}], 'retweet_count': 18, 'reply_count': 0, 'like_count': 0, 'quote_count': 0}}, {'index': 14, 'code': 11000, 'keyPattern': {'_id': 1}, 'keyValue': {'_id': ObjectId('000001372822130283401216')}, 'errmsg': \"E11000 duplicate key error collection: mydatabase.tweets index: _id_ dup key: { _id: ObjectId('000001372822130283401216') }\", 'op': {'_id': ObjectId('000001372822130283401216'), 'author_id': ObjectId('000000968189330970771456'), 'created_at': '2021-03-19T08:07:56.000Z', 'text': 'Esto es un sin vivir üò¨üò¨ quien saldr√°... \\nLos candidatos son:\\n- #ColetasRata \\n- #Mo√±oRata\\n- #Garrapata\\n- #ElChepas \\n- #MachoAlfa \\n- #VuelveElHombre \\n- #IglesiasCierraAlSalir https://t.co/JViLOUzlN6', 'hashtag': ['coletasrata'], 'referenced_tweets': [], 'retweet_count': 0, 'reply_count': 0, 'like_count': 1, 'quote_count': 0}}, {'index': 15, 'code': 11000, 'keyPattern': {'_id': 1}, 'keyValue': {'_id': ObjectId('000001372821392920608772')}, 'errmsg': \"E11000 duplicate key error collection: mydatabase.tweets index: _id_ dup key: { _id: ObjectId('000001372821392920608772') }\", 'op': {'_id': ObjectId('000001372821392920608772'), 'author_id': ObjectId('000000000000000237765349'), 'created_at': '2021-03-19T08:05:00.000Z', 'text': '@valerynut @Tamara_Falco_ @PODEMOS Es este el hilo para decir #ColetasRata ?', 'hashtag': ['coletasrata'], 'referenced_tweets': [{'type': 'replied_to', 'id': '1372820940711682049'}], 'retweet_count': 0, 'reply_count': 0, 'like_count': 1, 'quote_count': 0}}, {'index': 16, 'code': 11000, 'keyPattern': {'_id': 1}, 'keyValue': {'_id': ObjectId('000001372816657937268736')}, 'errmsg': \"E11000 duplicate key error collection: mydatabase.tweets index: _id_ dup key: { _id: ObjectId('000001372816657937268736') }\", 'op': {'_id': ObjectId('000001372816657937268736'), 'author_id': ObjectId('000000000000001125304440'), 'created_at': '2021-03-19T07:46:11.000Z', 'text': '#ColetasRata ahora es FARRUQUITO https://t.co/1N7eC1uIPX', 'hashtag': ['coletasrata'], 'referenced_tweets': [], 'retweet_count': 0, 'reply_count': 0, 'like_count': 0, 'quote_count': 0}}, {'index': 17, 'code': 11000, 'keyPattern': {'_id': 1}, 'keyValue': {'_id': ObjectId('000001372813882000035842')}, 'errmsg': \"E11000 duplicate key error collection: mydatabase.tweets index: _id_ dup key: { _id: ObjectId('000001372813882000035842') }\", 'op': {'_id': ObjectId('000001372813882000035842'), 'author_id': ObjectId('000000000000000322493132'), 'created_at': '2021-03-19T07:35:09.000Z', 'text': 'RT @david_segura: En Madrid #ColetasRata https://t.co/pvAOpWiNmd', 'hashtag': ['coletasrata'], 'referenced_tweets': [{'type': 'retweeted', 'id': ObjectId('000001372601660959252484'), 'author_id': ObjectId('000000000000000065602229')}], 'retweet_count': 18, 'reply_count': 0, 'like_count': 0, 'quote_count': 0}}, {'index': 18, 'code': 11000, 'keyPattern': {'_id': 1}, 'keyValue': {'_id': ObjectId('000001372813618799054849')}, 'errmsg': \"E11000 duplicate key error collection: mydatabase.tweets index: _id_ dup key: { _id: ObjectId('000001372813618799054849') }\", 'op': {'_id': ObjectId('000001372813618799054849'), 'author_id': ObjectId('000000000000002337603142'), 'created_at': '2021-03-19T07:34:07.000Z', 'text': 'RT @david_segura: En Madrid #ColetasRata https://t.co/pvAOpWiNmd', 'hashtag': ['coletasrata'], 'referenced_tweets': [{'type': 'retweeted', 'id': ObjectId('000001372601660959252484'), 'author_id': ObjectId('000000000000000065602229')}], 'retweet_count': 18, 'reply_count': 0, 'like_count': 0, 'quote_count': 0}}, {'index': 19, 'code': 11000, 'keyPattern': {'_id': 1}, 'keyValue': {'_id': ObjectId('000001372811928725258240')}, 'errmsg': \"E11000 duplicate key error collection: mydatabase.tweets index: _id_ dup key: { _id: ObjectId('000001372811928725258240') }\", 'op': {'_id': ObjectId('000001372811928725258240'), 'author_id': ObjectId('000001322840736413437954'), 'created_at': '2021-03-19T07:27:24.000Z', 'text': '@TabarniaB Pobre #ColetasRata üòÇüòÇüòÇ', 'hashtag': ['coletasrata'], 'referenced_tweets': [{'type': 'replied_to', 'id': ObjectId('000001372788392908386306'), 'author_id': ObjectId('000001364909426952568832')}], 'retweet_count': 0, 'reply_count': 0, 'like_count': 1, 'quote_count': 0}}, {'index': 20, 'code': 11000, 'keyPattern': {'_id': 1}, 'keyValue': {'_id': ObjectId('000001372810645679308804')}, 'errmsg': \"E11000 duplicate key error collection: mydatabase.tweets index: _id_ dup key: { _id: ObjectId('000001372810645679308804') }\", 'op': {'_id': ObjectId('000001372810645679308804'), 'author_id': ObjectId('000000000000002828042222'), 'created_at': '2021-03-19T07:22:18.000Z', 'text': '@Miss_Bennet7 ya quisiera el #ColetasRata tener ese dominio de las caderas https://t.co/HFNZyx4yLP', 'hashtag': ['coletasrata'], 'referenced_tweets': [{'type': 'replied_to', 'id': ObjectId('000001372808347993378817'), 'author_id': ObjectId('000001238153755478102021')}], 'retweet_count': 0, 'reply_count': 1, 'like_count': 1, 'quote_count': 0}}, {'index': 21, 'code': 11000, 'keyPattern': {'_id': 1}, 'keyValue': {'_id': ObjectId('000001372804756209500161')}, 'errmsg': \"E11000 duplicate key error collection: mydatabase.tweets index: _id_ dup key: { _id: ObjectId('000001372804756209500161') }\", 'op': {'_id': ObjectId('000001372804756209500161'), 'author_id': ObjectId('000000000000000437786946'), 'created_at': '2021-03-19T06:58:54.000Z', 'text': 'RT @SrPigdemont: En Madrid @PabloIglesias merece tantos diputados como visitas realiz√≥ a las Residencias de Ancianos mientras fue el respon‚Ä¶', 'hashtag': ['coletasrata'], 'referenced_tweets': [{'type': 'retweeted', 'id': ObjectId('000001371760190287192065'), 'author_id': ObjectId('000001364329203328569346')}], 'retweet_count': 1076, 'reply_count': 0, 'like_count': 0, 'quote_count': 0}}, {'index': 22, 'code': 11000, 'keyPattern': {'_id': 1}, 'keyValue': {'_id': ObjectId('000001372793138884964354')}, 'errmsg': \"E11000 duplicate key error collection: mydatabase.tweets index: _id_ dup key: { _id: ObjectId('000001372793138884964354') }\", 'op': {'_id': ObjectId('000001372793138884964354'), 'author_id': ObjectId('000001238527928222261250'), 'created_at': '2021-03-19T06:12:44.000Z', 'text': 'RT @SrPigdemont: En Madrid @PabloIglesias merece tantos diputados como visitas realiz√≥ a las Residencias de Ancianos mientras fue el respon‚Ä¶', 'hashtag': ['coletasrata'], 'referenced_tweets': [{'type': 'retweeted', 'id': ObjectId('000001371760190287192065'), 'author_id': ObjectId('000001364329203328569346')}], 'retweet_count': 1076, 'reply_count': 0, 'like_count': 0, 'quote_count': 0}}], 'writeConcernErrors': [], 'nInserted': 0, 'nUpserted': 0, 'nMatched': 0, 'nModified': 0, 'nRemoved': 0, 'upserted': []}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-5ed5472b3f5e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[0mGetTweets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"18-03-2021\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"04-05-2021\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-ae05a85e54a9>\u001b[0m in \u001b[0;36mGetTweets\u001b[1;34m(start_date, end_date)\u001b[0m\n\u001b[0;32m    542\u001b[0m                 \u001b[1;31m#alomejor aqui ponemos la cantidad de valores que se insertan en la lista, para los casos en los que los tweets coinciden con otros tweets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Total tweets insertados: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\", Total usuarios insertados: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maux_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 544\u001b[1;33m                 \u001b[0mMongoExecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maux_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    545\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m             \u001b[1;31m#ahora cambiamos de d'ia y quitamos la lista\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-ae05a85e54a9>\u001b[0m in \u001b[0;36mMongoExecute\u001b[1;34m(tweet_list, user_list)\u001b[0m\n\u001b[0;32m    118\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mhashtag\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'hashtag'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[0mhastag\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtweet\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'hashtag'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m                     \u001b[0mrepetido\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'hastag' is not defined"
     ]
    }
   ]
  }
 ]
}