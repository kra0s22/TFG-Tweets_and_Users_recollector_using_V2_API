{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python395jvsc74a57bd079fc3c954d64dbcf3cc8f2394a5e83a280e126f0ab97a2117c3267677291b603",
   "display_name": "Python 3.9.2  ('TFGBotsV2': venv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "79fc3c954d64dbcf3cc8f2394a5e83a280e126f0ab97a2117c3267677291b603"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Imports "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Versión para tweepy V2\n",
    "from datetime import date\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "import math\n",
    "import pymongo\n",
    "from bson import ObjectId\n",
    "import numpy as np\n",
    "import subprocess as sp\n",
    "from datetime import date\n"
   ]
  },
  {
   "source": [
    "## Constant and Variables"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONSTANTS\n",
    "PETITIONS_PER_TIME_LAPSE = 300\n",
    "TIME_LAPSE = 20*60\n",
    "TIMER = TIME_LAPSE/PETITIONS_PER_TIME_LAPSE\n",
    "TIMER_LOG = 2*60\n",
    "\n",
    "#porcentaje de tweets que nos quedamos para cada dia\n",
    "PERCENT = 0.15\n",
    "\n",
    "PETITIONS_LIMIT = 500\n",
    "\n",
    "#VARIABLES\n",
    "iniTimerLog = 0\n",
    "finTimerLog = 0\n",
    "tiempo = TIMER_LOG\n",
    "entrada = \"\"\n",
    "next_token = None\n",
    "entradaizq = '' \n",
    "entradader = ''\n",
    "hashtags = ''\n",
    "total = 0\n",
    "startDate = ''\n",
    "endDate = ''\n",
    "inicio = 0\n",
    "fin = 0\n",
    "\n",
    "hashtag_ini_log = ''\n",
    "start_log_timer = ''\n",
    "hashtag_last_log = ''\n",
    "tweet_count = 0\n",
    "\n",
    "url = 'https://api.twitter.com/2/tweets/search/all?'\n",
    "today = datetime.date.today()\n",
    "d1 = today.strftime(\"%d-%m-%Y\")\n",
    "\n"
   ]
  },
  {
   "source": [
    "## Support functions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_dictionary = {\n",
    "    \"_id\"               : None,\n",
    "    \"description\"       : '',\n",
    "    \"created_at\"        : '',\n",
    "    \"verified\"          : '',\n",
    "    \"followers_count\"   : 0,\n",
    "    \"following_count\"   : 0\n",
    "}\n",
    "\n",
    "\n",
    "tweet_dictionary = {\n",
    "    \"_id\"               : None,\n",
    "    \"author_id\"         : '',\n",
    "    \"created_at\"        : '',\n",
    "    \"text\"              : '',\n",
    "    \"hashtag\"           : '',\n",
    "    \"referenced_tweets\" : [],\n",
    "    \"retweet_count\"     : 0,\n",
    "    \"reply_count\"       : 0,\n",
    "    \"reply_count\"       : 0,\n",
    "    \"like_count\"        : 0\n",
    "}\n",
    "\n",
    "\n",
    "node = {\n",
    "    \"hashtag\"           : '',\n",
    "    \"current_date\"        : '',\n",
    "    \"next_date\"        : '',\n",
    "    \"next_token\"        : '-1'\n",
    "}\n",
    "\n",
    "\n",
    "def DayMonthYearToPetition(date):\n",
    "    splited = ''\n",
    "    if ('/' in date):\n",
    "        splited = date.split('/')\n",
    "    elif ('-' in date):\n",
    "        splited = date.split('-')\n",
    "\n",
    "    return (splited[2] + '-' + splited[1] + '-' + splited[0])\n",
    "\n",
    "def DayMonthYearToPetition(date):\n",
    "    splited = ''\n",
    "    if ('/' in date):\n",
    "        splited = date.split('/')\n",
    "    elif ('-' in date):\n",
    "        splited = date.split('-')\n",
    "\n",
    "    return (splited[2] + '-' + splited[1] + '-' + splited[0])\n",
    "\n",
    "def PetitionToDayMonthYear(petition):\n",
    "    splited = ''\n",
    "    time = ''\n",
    "    splited = petition.split('T')\n",
    "    time = splited[1]\n",
    "    splited = splited[0].split('-')\n",
    "    return (splited[2] + '-' + splited[1] + '-' + splited[0] + 'T' + time)\n",
    "\n",
    "def make_objid(text):\n",
    "    \"\"\"Makes an ObjectId of 4 bytes\n",
    "    \n",
    "    Keyword arguments:\n",
    "    text -- string to be converted into Object ID\n",
    "    \"\"\"\n",
    "    text = str(text)\n",
    "    if not text.strip():\n",
    "        return None\n",
    "    try:\n",
    "        return ObjectId(text.rjust(24,\"0\"))\n",
    "    except Exception as ex:\n",
    "        #print(len(text))\n",
    "        print(text, ex)\n",
    "        return None\n",
    "\n",
    "def create_headers(bearer_token):\n",
    "    headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)}\n",
    "    return headers\n",
    "\n",
    "\n",
    "def connect_to_endpoint(headers, params):\n",
    "    response = requests.request(\"GET\", \"https://api.twitter.com/2/tweets/search/all?\", headers=headers, params=params)\n",
    "    #print(response.status_code)\n",
    "    # Manejo de errores\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.status_code, response.text)\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "def MongoExecute(tweet_list, user_list):\n",
    "    global myclient\n",
    "    global myusers\n",
    "    global mytweets\n",
    "    global mydb\n",
    "\n",
    "    try:\n",
    "        print(str(mytweets.insert_many(tweet_list, ordered=False)))\n",
    "        print(str(myusers.insert_many(user_list, ordered=False)))\n",
    "    except Exception as e:\n",
    "        #print(e)\n",
    "        pass\n",
    "        #cuando sepa hacerlo aquí haría una búsqueda con comprobación de que el usuario está en la lista y si está vacía completar los valores que le faltan.\n",
    "\n",
    "def PrintTweetsUsers(tweets, users):\n",
    "    print(\"Tweet list\")\n",
    "    for tweet in tweets:\n",
    "        print(\" id: \" + str(tweet['_id']))\n",
    "        print(\" author_id: \" + tweet['author_id'])\n",
    "        print(\" created_at: \" + tweet['created_at'])\n",
    "        print(\" referenced_tweets: \" + str(tweet['referenced_tweets']) + '\\n')\n",
    "\n",
    "    print(\"User list\")\n",
    "    for user in users:\n",
    "        print(\" user_id: \" + str(user['_id']))\n",
    "        print(\" description: \" + user['description'])\n",
    "        print(\" created_at: \" + user['created_at'])\n",
    "        print(\" verified: \" + str(user['verified']))\n",
    "        print(\" followers_count: \" + str(user['followers_count']))\n",
    "        print(\" following_count: \" + str(user['following_count']) + '\\n')\n",
    "\n",
    "#Terminar de insertas los campos del petitionslessequals100\n",
    "    # Insertados los siguientes campos:\n",
    "    #   -start_time: límite inferior en búsqueda de fechas\n",
    "    #   -end_time: límete superior en búsqueda de fechas\n",
    "    #   -tweet.fields=author_id: id del autor del tweet\n",
    "    #   -tweet.fields=referenced_tweets: puede ser quote, retweet o replied_to junto al id al que responde, agrega además los tweets relativos al tweet al que responde\n",
    "    #   -tweet.fields=created_at: cu'ando se cre'o el fichero\n",
    "    #   -tweet.fields=context_annotations:anotaciones de contexto (no salen muchas)\n",
    "    #   -tweet.fields=lang: Abreviatura del idioma en el que se escribe\n",
    "    #   -tweet.fields=entities: referencias, hashtags usados por el usuario\n",
    "    #   -tweet.fields=in_reply_to_user_id: \n",
    "    #   -    in_reply_to_user_id\n",
    "\n",
    "# Hashtag: nombre del hashtag que se va a buscar\n",
    "# start: fecha de inicio\n",
    "# end: fecha de respuesta\n",
    "# number: n'umero de tweets que queremos obtener\n",
    "# bearer: bearer id\n",
    "# next_token: token de la page (inicialmente string vac'ia) que quieres buscar\n",
    "# return tupla de n'umero de respuestas y next_token\n",
    "def PetitionsLessEqualPETITIONS_LIMIT(hashtag, start, end, bearer, next_token):\n",
    "\n",
    "    global log\n",
    "    global errorlog\n",
    "    global headers\n",
    "    global PETITIONS_LIMIT\n",
    "\n",
    "    startDate = DayMonthYearToPetition(start)\n",
    "    endDate = DayMonthYearToPetition(end)\n",
    "    tweet_list = []\n",
    "    user_list = []\n",
    "    total = (0, '', [], [])\n",
    "    dt_string = ''\n",
    "    tweet_dictionary_new = {}\n",
    "    user_dictionary_new = {}\n",
    "\n",
    "    params = \"query=%23\" + hashtag + \"&start_time=\" +  startDate + \"T00%3A00%3A00Z\" + \"&end_time=\" + endDate + 'T11%3A59%3A59Z&max_results=' + str(PETITIONS_LIMIT) + '&expansions=author_id,referenced_tweets.id&tweet.fields=created_at,conversation_id,referenced_tweets,public_metrics&user.fields=created_at,entities,description,verified,public_metrics'\n",
    "    # caso en el que -1 (primera peticion de dia) o es el next_token\n",
    "    if (next_token != ''):\n",
    "        params = params + '&next_token=' + next_token\n",
    "\n",
    "    # primera petici'on del hashtag\n",
    "    json_obj = ''\n",
    "    try:\n",
    "        json_obj = connect_to_endpoint(headers=headers, params=params)\n",
    "        #print(json.dumps(json_obj, indent=4, sort_keys=True))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return (0, next_token, [], [])\n",
    "    \n",
    "\n",
    "    # Comprobar que hay respuestas para dicho hashtag\n",
    "    if ('meta' in json_obj) and (int(json_obj['meta']['result_count']) > 0):\n",
    "        for tweet in json_obj['data']:\n",
    "            tweet_dictionary_new = tweet_dictionary.copy()\n",
    "            tweet_dictionary_new['referenced_tweets'] = []\n",
    "            user_dictionary_new = user_dictionary.copy()\n",
    "            \n",
    "            tweet_dictionary_new['_id'] = make_objid(str(tweet['id']))\n",
    "            tweet_dictionary_new['author_id'] = make_objid(str(tweet['author_id']))\n",
    "            tweet_dictionary_new['text'] = tweet['text']\n",
    "            tweet_dictionary_new['hashtag'] = hashtag\n",
    "            tweet_dictionary_new['created_at'] = tweet['created_at']\n",
    "            tweet_dictionary_new['retweet_count'] = tweet['public_metrics']['retweet_count']\n",
    "            tweet_dictionary_new['reply_count'] = tweet['public_metrics']['reply_count']\n",
    "            tweet_dictionary_new['like_count'] = tweet['public_metrics']['like_count']\n",
    "            tweet_dictionary_new['quote_count'] = tweet['public_metrics']['quote_count']\n",
    "\n",
    "            if ('referenced_tweets' in tweet):\n",
    "                tweet_dictionary_new['referenced_tweets'] = tweet['referenced_tweets']\n",
    "                for rt in tweet_dictionary_new['referenced_tweets']:\n",
    "                    for tweetexpanse in json_obj['includes']['tweets']:\n",
    "                        if (rt['id'] == tweetexpanse['id']):\n",
    "                            rt['author_id'] = make_objid(str(tweetexpanse['author_id']))\n",
    "                            rt['id'] = make_objid(str(tweetexpanse['id']))\n",
    "                            break\n",
    "\n",
    "            unknown = True\n",
    "            for user in user_list:\n",
    "                if (str(user['_id']) == tweet_dictionary_new['author_id']):\n",
    "                    unknown = False\n",
    "                    break\n",
    "\n",
    "            if (unknown == True):\n",
    "                user_dictionary_new['_id'] = make_objid(str(tweet['author_id']))\n",
    "                if ('includes' in json_obj):\n",
    "                    for user in json_obj['includes']['users']:\n",
    "                        if (str(user['id']) == tweet['author_id']):\n",
    "                            user_dictionary_new['description'] = user['description']\n",
    "                            user_dictionary_new['created_at'] = user['created_at']\n",
    "                            user_dictionary_new['verified'] = user['verified']\n",
    "                            user_dictionary_new['followers_count'] = int(user['public_metrics']['followers_count'])\n",
    "                            user_dictionary_new['following_count'] = int(user['public_metrics']['following_count'])\n",
    "                            break\n",
    "                #aqui otro manejo de errores\n",
    "                else:\n",
    "                    print ('otro error')\n",
    "                user_list.append(user_dictionary_new)\n",
    "\n",
    "            tweet_list.append(tweet_dictionary_new)\n",
    "\n",
    "        if ('next_token' in json_obj['meta']):\n",
    "            total = (int(json_obj['meta']['result_count']), json_obj['meta']['next_token'], tweet_list, user_list)\n",
    "\n",
    "        else:\n",
    "            total = (int(json_obj['meta']['result_count']), '', tweet_list, user_list)\n",
    "\n",
    "        print(\"     N'umero de peticiones enviadas: \" + str(PETITIONS_LIMIT))\n",
    "        print(\"     N'umero de peticiones recibidas: \" + str(json_obj['meta']['result_count']))\n",
    "        print(\"     \" + str(total[1]))\n",
    "        return total\n",
    "\n",
    "    # caso en el que no hay respuestas para una peticion\n",
    "    #elif ('meta' in  json_obj) and (int(json_obj['meta']['result_count']) == 0):\n",
    "        # datetime object containing current date and time\n",
    "        #now = datetime.datetime.now()\n",
    "        # dd/mm/YY H:M:S\n",
    "        #dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "        #errorlog.write(\"Error, no hay tweets para el Hashtag: \" + str(hashtag) + \" para el día \" + start +  dt_string + '\\n')\n",
    "        #print(\"No hay tweets para el Hashtag: \" + str(hashtag) + \" para el día \" + start)\n",
    "    # Caso en el que la respuesta es un error y hay que manejarlo\n",
    "    else:\n",
    "        strerror = '    '\n",
    "        #print(\"Error en la petición: \")\n",
    "        strerror = strerror + str(params)\n",
    "        #print(entrada.split(' -H')[0])\n",
    "        strerror = strerror + \"Error en la petición: \"\n",
    "        # si el error es por cuestión de peticiones esperar para hacer la siguiente peticion\n",
    "        if ('title' in json_obj):\n",
    "            #print(\"  Título del error: \" + str(json_obj['title']))\n",
    "            strerror = strerror + \"  Título del error: \" + str(json_obj['title'])\n",
    "            if ('status' in json_obj):\n",
    "                strerror = strerror + \" Código de error: \" + str(json_obj['status'])\n",
    "                #print(\"  Código de error: \" + str(json_obj['status']))\n",
    "            if ('detail' in json_obj):\n",
    "                strerror = strerror + \"  Descripción del error: \" + str(json_obj['detail'])\n",
    "                #print(\"  Descripción del error: \" + str(json_obj['detail']))\n",
    "                \n",
    "        errorlog.write(strerror + \" \" + dt_string + '\\n')\n",
    "        total = (0, next_token, [], [])\n",
    "    return total\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Hashtag: nombre del hashtag que se va a buscar\n",
    "# start: fecha de inicio\n",
    "# end: fecha de respuesta\n",
    "# number: n'umero de tweets que queremos obtener\n",
    "# bearer: bearer id\n",
    "# return devuelve dos diccionarios (users-tweet, tweet-tweet_items)\n",
    "def TweetList(hashtag, start, end, bearer, token):\n",
    "    global tiempo\n",
    "    global TIMER\n",
    "    global TIMER_LOG\n",
    "    global tweet_count\n",
    "    global hashtag_ini_log\n",
    "    global hashtag_last_log\n",
    "    global start_log_timer\n",
    "    \n",
    "\n",
    "    #aqui deberia de hacer dos variables de incio y fin de log para saber con cual hashtag empiezo y termino y con cuantos valores totales de cada uno.\n",
    "    user_list = []\n",
    "    tweet_list = []\n",
    "    total = 0\n",
    "    aux = 0\n",
    "    startTime = 0\n",
    "    endTime = 0\n",
    "    response = (0, token, [], [])\n",
    "\n",
    "    startTime = time.time()\n",
    "\n",
    "    response =  PetitionsLessEqualPETITIONS_LIMIT(hashtag, start, end, bearer, response[1])\n",
    "    # insercion de usuarios nuevos y de tweets nuevos de usuarios ya insertados\n",
    "    for user in response[3]:\n",
    "        unknown = True\n",
    "        \n",
    "        for u in user_list:\n",
    "            if (user['_id'] == u['_id']):\n",
    "                unknown = False\n",
    "                break\n",
    "        if (unknown == True):\n",
    "            user_list.append(user)\n",
    "    #inserci'on de tweets nuevos a la lista de tweets\n",
    "    tweet_list.extend(response[2])\n",
    "    total = response[0]\n",
    "    tweet_count += response[0]\n",
    "    #tweet_list.extend(total[2])\n",
    "\n",
    "    endTime = time.time()\n",
    "\n",
    "    aux = round(math.floor(endTime - startTime))\n",
    "    if (aux < TIMER):\n",
    "        number = TIMER - aux\n",
    "        time.sleep(number)\n",
    "        print('     sleep number: ' + str(number) + ', aux: ' + str(aux) + '\\n', flush=True)\n",
    "        tiempo -= TIMER\n",
    "    else:\n",
    "        tiempo -= aux\n",
    "        print('     aux: ' + str(aux) + '\\n', flush=True)\n",
    "    \n",
    "    if (tiempo <= 0):\n",
    "        #aqui se imprime en el log los hashtags que se han escrito y c'uantos valores se han obtenido de estos\n",
    "        tiempo = TIMER_LOG\n",
    "        # datetime object containing current date and time\n",
    "        now = datetime.datetime.now()\n",
    "        # dd/mm/YY H:M:S\n",
    "        dt_string = now.strftime(\"%H:%M:%S\")\n",
    "        hashtag_last_log = hashtag\n",
    "        log.write(hashtag_ini_log + ' ' + start_log_timer + ' ' + hashtag + ' ' + start + ' ' + dt_string + '\\n')\n",
    "        start_log_timer = dt_string\n",
    "        tweet_count = 0\n",
    "        hashtag_ini_log = hashtag_last_log\n",
    "    \n",
    "    print (\"            Tweets totales: \" + str(total) + '\\n')\n",
    "\n",
    "    return (total, response[1], tweet_list, user_list)\n",
    "\n",
    "\n",
    "#hacer un archivo donde guardo hastag y next_token\n",
    "#consultar dicho archivo al iniciar el programa para poner el next token en la lista de hashtags\n",
    "def GetTweets(start_date, end_date):\n",
    "\n",
    "\n",
    "    global tiempo\n",
    "    global TIMER\n",
    "    global TIMER_LOG\n",
    "    global tweet_count\n",
    "\n",
    "    \n",
    "    last_date = date(2021, 5, 4)\n",
    "    last_date = last_date.strftime(\"%d/%m/%Y\")\n",
    "    hashtagsList = []\n",
    "\n",
    "    #####Uso de Hashtag\n",
    "    f =  open(\"./hashtags.txt\", \"r\")\n",
    "    hashtag = None\n",
    "    resultado = (0, '', [], [])\n",
    "    dat = date(2021, 2, 28)\n",
    "    first_day = dat\n",
    "    dat += datetime.timedelta(days=1)\n",
    "    next_day = dat\n",
    "    str_first_day = first_day.strftime(\"%d/%m/%Y\")\n",
    "    str_next_day = next_day.strftime(\"%d/%m/%Y\")\n",
    "    while True:\n",
    "        # read line\n",
    "        try:\n",
    "            hashtag = f.readline()\n",
    "            if (hashtag == \"\") :\n",
    "                break\n",
    "        except:\n",
    "            # datetime object containing current date and time\n",
    "            now = datetime.datetime.now()\n",
    "            # dd/mm/YY H:M:S\n",
    "            dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "            errorlog.write(\"    Fallo al leer el fichero hashtags.txt \" + dt_string + \"\\n\")\n",
    "        \n",
    "        hashtag = hashtag.rstrip('\\n')\n",
    "        hashtag = hashtag.replace('#', '')\n",
    "        \n",
    "        node_aux = node.copy()\n",
    "        node_aux[\"hashtag\"] = hashtag\n",
    "        node_aux[\"current_date\"] = str_first_day     \n",
    "        node_aux[\"next_date\"] = str_next_day    \n",
    "        hashtagsList.append(node_aux)\n",
    "        # check if line is not empty\n",
    "        \n",
    "    f.close()\n",
    "\n",
    "    \n",
    "\n",
    "    if os.path.exists(\"./lasttoken.txt\") and os.path.getsize(\"./lasttoken.txt\") > 0:\n",
    "        f =  open(\"./lasttoken.txt\", \"r\")\n",
    "        while True:\n",
    "            # read line\n",
    "            try:\n",
    "                hashtag = f.readline()\n",
    "                if (hashtag == \"\") :\n",
    "                    break\n",
    "            except:\n",
    "                # datetime object containing current date and time\n",
    "                now = datetime.datetime.now()\n",
    "                # dd/mm/YY H:M:S\n",
    "                dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "                errorlog.write(\"Fallo al leer el fichero hashtags.txt \" + dt_string + \"\\n\")\n",
    "\n",
    "            hashtag = hashtag.rstrip('\\n')\n",
    "            hashtag = hashtag.split(' ')\n",
    "            for h in hashtagsList:\n",
    "                if (h['hashtag'] == hashtag[0]):\n",
    "                    h['next_token'] = hashtag[1]\n",
    "                    h['current_date'] = hashtag[2]\n",
    "                    h[\"next_date\"] = hashtag[3]  \n",
    "        f.close()\n",
    "\n",
    "    for h in hashtagsList:\n",
    "        print(str(h))\n",
    "        \n",
    "\n",
    "\n",
    "    if (len(hashtagsList) != 0):\n",
    "        hashtag_ini_log = hashtagsList[0]\n",
    "        # dd/mm/YY H:M:S\n",
    "        now = datetime.datetime.now()\n",
    "        dt_string = now.strftime(\"%H:%M:%S\")\n",
    "        start_log_timer = dt_string\n",
    "        \n",
    "    else:\n",
    "        # datetime object containing current date and time\n",
    "        now = datetime.datetime.now()\n",
    "        # dd/mm/YY H:M:S\n",
    "        dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "        errorlog.write(\"    Error: lista de hashtags vacía\" + \" dt_string\\n\")\n",
    "\n",
    "    count = 0\n",
    "    temporalTokens = ''\n",
    "    tweet_list = []\n",
    "    user_list = []\n",
    "    start = 0\n",
    "    end = 0\n",
    "    \n",
    "    while (l[\"current_date\"] != last_date):\n",
    "        tweet_list = []\n",
    "        user_list = []\n",
    "        for l in hashtagsList:\n",
    "            # response[1] is '' so it doesn't get a next token\n",
    "            #caso en el que es primera iteraci'on o hay siguiente p'agina\n",
    "            bucle_timer = 0\n",
    "            start = 0\n",
    "            end = 0\n",
    "            aux = 0\n",
    "            if (l[\"next_token\"] != ''):\n",
    "                if l[\"next_token\"] == '-1':\n",
    "                    resultado = TweetList(l[\"hashtag\"], l[\"current_date\"], l[\"next_date\"], Bearer, '')\n",
    "                else:\n",
    "                    resultado = TweetList(l[\"hashtag\"], l[\"current_date\"], l[\"next_date\"], Bearer, l[\"next_token\"])\n",
    "                start = time.time()\n",
    "                tweet_list.extend(resultado[2])\n",
    "                user_list.extend(resultado[3])\n",
    "                l[\"next_token\"] = resultado[1]\n",
    "                end = time.time()\n",
    "            else:\n",
    "                start = time.time()\n",
    "                # Substring de % para insertar en la base de datos\n",
    "                count = 0\n",
    "                count = round(math.ceil(len(tweet_list) * PERCENT))\n",
    "                #primero comprobamos si no hemos insertado inicialmente en la base de datos tantos tweets como pone en count\n",
    "                search = list(mytweets.find( {\"hashtag\" : l[\"hashtag\"]} ))\n",
    "                count -= len(search)\n",
    "                if count > 0:\n",
    "                    #buscamos los tweets que estan en la base  de datos y los borramos de nuestra lista de tweets\n",
    "                    for t in search:\n",
    "                        if t in tweet_list:\n",
    "                            tweet_list.remove(t)\n",
    "                    # caso en el que count es menor que lo que podemos insertar\n",
    "                    if count < len(tweet_list):\n",
    "                        tweet_list = tweet_list[0:(count - 1)]\n",
    "\n",
    "                    aux_list = []\n",
    "                    # Ahora buscamos los users relacionados con los tweets de la lista\n",
    "                    for u in user_list:\n",
    "                        for t in tweet_list:\n",
    "                            if str(t['author_id']) == str(u['_id']):\n",
    "                                aux_list.append(u)\n",
    "                                break\n",
    "                    #Aqui se inserta en la base de datos\n",
    "                    #alomejor aqui ponemos la cantidad de valores que se insertan en la lista, para los casos en los que los tweets coinciden con otros tweets\n",
    "                    MongoExecute(tweet_list, aux_list)\n",
    "                \n",
    "                #ahora cambiamos de d'ia y quitamos la lista\n",
    "                tweet_list = []\n",
    "                user_list = []\n",
    "                print('     Cambio de día ' + l['current_date'])\n",
    "                l['current_date'] = l['next_date']\n",
    "                dat = datetime.datetime.strptime(l['current_date'], \"%d/%m/%Y\")\n",
    "                dat += datetime.timedelta(days=1)\n",
    "                l['next_date'] = dat.strftime(\"%d/%m/%Y\").split(' ')[0]\n",
    "                l['next_token'] = '-1'\n",
    "                #borramos la 'ultima linea de fichero de lasttoken\n",
    "                if os.path.exists(\"./lasttoken.txt\") and os.path.getsize(\"./lasttoken.txt\") > 0:\n",
    "                    d = ''\n",
    "                    f =  open(\"./lasttoken.txt\", \"r\")\n",
    "                    #remove last line from a text line in python\n",
    "                    d = f.readlines()\n",
    "                    f.close()\n",
    "\n",
    "                    f = open(\"./lasttoken.txt\",\"w+\")\n",
    "                    for i in range(len(d)):\n",
    "                        if len(d) > 1:\n",
    "                            f.write(d[0:(len(d) - 1)])\n",
    "                        else:\n",
    "                            f.write('')\n",
    "                    f.close()\n",
    "\n",
    "                if (l[\"current_date\"] != last_date):\n",
    "                    f = open(\"./lasttoken.txt\",\"a+\")\n",
    "                    str_write = l['hashtag'] + ' ' + l['next_token'] + ' ' + l['current_date'] + ' ' + l[\"next_date\"] + '\\n'\n",
    "                    f.write(str_write)\n",
    "                    f.close()\n",
    "                end = time.time()\n",
    "                \n",
    "            tiempo -= round(math.floor(start - end))\n",
    "            if (tiempo <= 0):\n",
    "                # datetime object containing current date and time\n",
    "                tiempo = TIMER_LOG\n",
    "                now = datetime.datetime.now()\n",
    "                # dd/mm/YY H:M:S\n",
    "                dt_string = now.strftime(\"%H:%M:%S\")\n",
    "                log.write(hashtag_ini_log + ' ' + start_log_timer + ' ' + l['hashtag'] + ' ' + l['current_date'] + ' ' + dt_string + '\\n')\n",
    "                hashtag_ini_log = l['hashtag']\n",
    "\n",
    "        print(\"Fin Hashtag: \" + str(l['hashtag']) + \"\\\\\\\\\\\\\\\\\\\\\\\\ \\n\\n\")        \n",
    "        # datetime object containing current date and time\n",
    "        tiempo = TIMER_LOG\n",
    "        now = datetime.datetime.now()\n",
    "        # dd/mm/YY H:M:S\n",
    "        dt_string = now.strftime(\"%H:%M:%S\")\n",
    "        hashtag_last_log = hashtagsList[len(hashtagsList) - 1]\n",
    "        log.write(str(hashtag_ini_log) + ' ' + start_log_timer + ' ' + str(hashtag_last_log) + ' ' + str(start) + ' ' + str(dt_string) + ' ' + str(total) +'\\n')\n",
    "\n",
    "    log.close()\n",
    "    errorlog.close()\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "source": [
    "## Main code"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#Tendría que saber por qué tweet me he quedado, si los totales de tweets son menos que la cantidad media de tweets por hastag significa que ya no hay más tweets que buscar Un algoritmo que sepa cuando lo que estás buscando se ha buscado con anterioridad en la lista \n",
    "# Si ya se ha buscado anteriormente entonces deberías de comprobar si la búsqueda y lo que se pide de base (n_teets no se que es igual al número de tweets del hashtag)\n",
    "\n",
    "myclient = pymongo.MongoClient('localhost', 27017)\n",
    "mydb = myclient[\"mydatabase\"]\n",
    "myusers = mydb[\"users\"]\n",
    "mytweets = mydb[\"tweets\"]\n",
    "\n",
    "f = open(\"./accountV2.txt\", \"r\")\n",
    "Bearer = f.readline().rstrip('\\n')\n",
    "f.close()\n",
    "headers = create_headers(Bearer)\n",
    "\n",
    "fileObj = Path(\"./log\" + d1 + \".txt\")\n",
    "if (fileObj.is_file()):\n",
    "    os.remove(\"./log\" + d1 + \".txt\")\n",
    "\n",
    "fileObj = Path(\"./errorlog\" + d1 + \".txt\")\n",
    "if (fileObj.is_file()):\n",
    "    os.remove(\"./errorlog\" + d1 + \".txt\")\n",
    "\n",
    "log = open(\"./log\" + d1 + \".txt\", \"a\")\n",
    "log.write(\"Primer log\\n\")\n",
    "#Crear ficheros de log\n",
    "errorlog = open(\"./errorlog\" + d1 + \".txt\", \"a\")\n",
    "\n",
    "\n",
    "GetTweets(\"18-03-2021\", \"04-05-2021\")\n"
   ],
   "cell_type": "code",
   "metadata": {
    "tags": []
   },
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'hashtag': 'DemocraciaOFascismo4M', 'current_date': '28/02/2021', 'next_date': '01/03/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'SosoSerioYFormal', 'current_date': '28/02/2021', 'next_date': '01/03/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'ColetasRata', 'current_date': '28/02/2021', 'next_date': '01/03/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'RataSinColeta', 'current_date': '28/02/2021', 'next_date': '01/03/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'PodemosAtacaAPodemos', 'current_date': '28/02/2021', 'next_date': '01/03/2021', 'next_token': '-1'}\n",
      "{'hashtag': '4MConPabloIglesias', 'current_date': '28/02/2021', 'next_date': '01/03/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'semarlaskalatragedia', 'current_date': '28/02/2021', 'next_date': '01/03/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'IreneMonteroDimision', 'current_date': '28/02/2021', 'next_date': '01/03/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'TeamVox', 'current_date': '10/04/2021', 'next_date': '11/04/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'SoloQuedaVox', 'current_date': '28/02/2021', 'next_date': '01/03/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'VoxLivesMatter', 'current_date': '28/02/2021', 'next_date': '01/03/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'Elecciones4M', 'current_date': '28/02/2021', 'next_date': '01/03/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'NazisYCorruptos', 'current_date': '28/02/2021', 'next_date': '01/03/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'Pucherazo', 'current_date': '28/02/2021', 'next_date': '01/03/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'RompeTuVoto', 'current_date': '28/02/2021', 'next_date': '01/03/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'IlegalizacionDeVoxYa', 'current_date': '28/02/2021', 'next_date': '01/03/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'DebateSER', 'current_date': '28/02/2021', 'next_date': '01/03/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'VotaLIBERTAD', 'current_date': '28/02/2021', 'next_date': '01/03/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'DebateTelemadrid', 'current_date': '28/02/2021', 'next_date': '01/03/2021', 'next_token': '-1'}\n",
      "{'hashtag': 'eleccionesMadrid2021', 'current_date': '28/02/2021', 'next_date': '01/03/2021', 'next_token': '-1'}\n",
      "Inicio Hashtag: DemocraciaOFascismo4M\\\\\\\\\\\\ \n",
      "\n",
      "     sleep number: 4.0, aux: 0\n",
      "\n",
      "            Tweets totales: 0\n",
      "\n",
      "     Cambio de día 28/02/2021\n",
      "     sleep number: 4.0, aux: 0\n",
      "\n",
      "            Tweets totales: 0\n",
      "\n",
      "     Cambio de día 01/03/2021\n",
      "     sleep number: 4.0, aux: 0\n",
      "\n",
      "            Tweets totales: 0\n",
      "\n",
      "     Cambio de día 02/03/2021\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-e4933e4553de>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0mGetTweets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"18-03-2021\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"04-05-2021\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-c2e37edce60b>\u001b[0m in \u001b[0;36mGetTweets\u001b[1;34m(start_date, end_date)\u001b[0m\n\u001b[0;32m    451\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"next_token\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    452\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"next_token\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'-1'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 453\u001b[1;33m                     \u001b[0mresultado\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTweetList\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"hashtag\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"current_date\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"next_date\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBearer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    454\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m                     \u001b[0mresultado\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTweetList\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"hashtag\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"current_date\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"next_date\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBearer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"next_token\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-c2e37edce60b>\u001b[0m in \u001b[0;36mTweetList\u001b[1;34m(hashtag, start, end, bearer, token)\u001b[0m\n\u001b[0;32m    312\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0maux\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mTIMER\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[0mnumber\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTIMER\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0maux\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'     sleep number: '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m', aux: '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maux\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'\\n'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflush\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m         \u001b[0mtiempo\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mTIMER\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ]
  }
 ]
}